{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FinalYearProject G8.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KXmxByMz21zk",
        "XdJ5DVXkUvsu",
        "zANCTGAqy_In",
        "c4OarE3DxDOn",
        "Kg5XcOKNgjPB",
        "ZDhdMNB7rTc7",
        "MSO77t4PFz2f",
        "OW-TVHKD84HE",
        "EsQ7IkvL8_i3",
        "91NRPYHT9Gpd",
        "k7f-xGwP9Nno",
        "4awhb8q0jluX",
        "wMvxgF8jmI4A",
        "hMtL6w5nLCQa",
        "WASyyb_fOd34",
        "orC98mD2A6ER",
        "jHYAHmshmJ0Y",
        "CFZ-pPRpmhXy",
        "GEh7Og-wem_U",
        "WOVzQxKRerj2",
        "UQjhcvZCfLfd"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXmxByMz21zk"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDCNZFcwsjLZ"
      },
      "source": [
        "import numpy as np \n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from collections import defaultdict\n",
        "import random\n",
        "from PIL import Image , ImageOps , ImageDraw\n",
        "from keras.preprocessing.image import array_to_img\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import ZeroPadding2D\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import ZeroPadding2D , GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers.merge import add, Concatenate\n",
        "from keras.models import Model\n",
        "import cv2\n",
        "from numpy import expand_dims\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.layers import AveragePooling2D,Dropout,Flatten, Dense,MaxPooling2D,BatchNormalization,Activation,Conv2D,Input\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "import skimage.transform\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras import regularizers\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activation\n",
        "from keras.regularizers import l2\n",
        "from keras.models import Model\n",
        "import tensorflow as tk\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdJ5DVXkUvsu"
      },
      "source": [
        "# Perparing Datasets - \n",
        "\n",
        "\n",
        "*   Selecting the limited images (500 per label)\n",
        "*   Label count ( 10 ) \n",
        "*   Normalizing the data\n",
        "*   Plotting the graph (with images count vs label)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9Vo9q6ZpjUI",
        "outputId": "6a6ad4a9-eb93-44bb-ffce-6fb0fe99f71d"
      },
      "source": [
        "def custom_cifar10_data(img_rows, img_cols):\n",
        "\n",
        "    # Load cifar10 training and validation sets\n",
        "    (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
        "\n",
        "    # Resize training images\n",
        "    X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:,:,:,:]])\n",
        "    X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:,:,:,:]])\n",
        "\n",
        "    # Transform targets to keras compatible format\n",
        "    Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
        "    Y_valid = np_utils.to_categorical(Y_valid, num_classes)\n",
        "    \n",
        "    X_train = X_train.astype('float32')\n",
        "    X_valid = X_valid.astype('float32')\n",
        "\n",
        "    # preprocess data\n",
        "    X_train = X_train / 255.0\n",
        "    X_valid = X_valid / 255.0\n",
        "\n",
        "    return X_train, Y_train, X_valid, Y_valid\n",
        "\n",
        "(x_train , y_train) , (x_test , y_test) = cifar10.load_data() \n",
        "print('X Train Shape : ' , x_train.shape)\n",
        "print('Y Train Shape :' , y_train.shape)\n",
        "print('X Test Shape : ' , x_test.shape)\n",
        "print('Y Test Shape : ' , y_test.shape)\n",
        "\n",
        "### Normalize the dataset\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Train Shape :  (50000, 32, 32, 3)\n",
            "Y Train Shape : (50000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zANCTGAqy_In"
      },
      "source": [
        "# Modifing the Training Dataset - To reduce label Count\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWBaeMpx5o3c"
      },
      "source": [
        "def decreaseTrainData(x_train , y_train , count) : \n",
        "  unique_labels = np.unique(y_train)\n",
        "  d = defaultdict(list)\n",
        "  for i in range(x_train.shape[0]) : \n",
        "    key = y_train[i][0]\n",
        "    if key in d.keys() and len(d[key]) > count : \n",
        "      continue\n",
        "    d[y_train[i][0]].append(x_train[i])\n",
        "    new_x_train = []\n",
        "    new_y_train = []\n",
        "    for key in d.keys() : \n",
        "      random.shuffle(d[key])\n",
        "      d[key] = d[key][:count]\n",
        "      new_x_train.extend(d[key])\n",
        "      new_y_train.extend([key for i in range(count)])\n",
        "\n",
        "  dataset = list(zip(new_x_train , new_y_train))\n",
        "  random.shuffle(dataset)\n",
        "  new_x_train , new_y_train = zip(*dataset)\n",
        "  x_train = np.asarray(new_x_train , dtype = np.float32)\n",
        "  y_train = np.asarray(new_y_train , dtype = np.float32)\n",
        "  y_train = y_train.reshape(y_train.shape[0] , 1)\n",
        "\n",
        "  return x_train , y_train\n",
        "\n",
        "def getImages(x_train) : \n",
        "  fig, axes = plt.subplots(10,10, figsize=(8,8))\n",
        "  for i,ax in enumerate(axes.flat):\n",
        "      ax.imshow(array_to_img(x_train[i]))\n",
        "\n",
        "def resizeImage(img , new_size) : \n",
        "  newImage = img.resize(new_size)\n",
        "  return newImage\n",
        "\n",
        "### Considering only the 500 labels from each class \n",
        "x_train , y_train = decreaseTrainData(x_train , y_train , 500)\n",
        "### Get the shape of training labels\n",
        "print('X Train Shape : ' , x_train.shape)\n",
        "print('Y Train Shape :' , y_train.shape)\n",
        "print('X Test Shape : ' , x_test.shape)\n",
        "print('Y Test Shape : ' , y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4OarE3DxDOn"
      },
      "source": [
        "# Weakly Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av1vC5qfxIf0"
      },
      "source": [
        "def flipLeftRight(img) : \n",
        "  return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "def flipTopBottom(img) : \n",
        "  return img.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "\n",
        "def rotate90(img) :\n",
        "  return img.transpose(Image.ROTATE_90)\n",
        "\n",
        "def rotate180(img) : \n",
        "  return img.transpose(Image.ROTATE_180)\n",
        "\n",
        "def rotate270(img) : \n",
        "  return img.transpose(Image.ROTATE_270)\n",
        "\n",
        "def weak_augment_list() : \n",
        "  l = [(flipLeftRight) , (flipTopBottom) , (rotate90) , (rotate180) , (rotate270) ]\n",
        "  return l\n",
        "\n",
        "\n",
        "class WeakAugment : \n",
        "  def __init__(self , n = 3)  :\n",
        "    self.n = n  \n",
        "    self.augment_list = weak_augment_list()\n",
        "  def __call__(self , img) : \n",
        "    ops = random.choices( self.augment_list , k = self.n)\n",
        "    for op in ops : \n",
        "      img = op(img)\n",
        "    return img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg5XcOKNgjPB"
      },
      "source": [
        "# Random Augmentation\n",
        "\n",
        "\n",
        "*   ShearX , ShearY\n",
        "*   TranslateX , TranslateXabs , TranslateY , TranslateYabs\n",
        "*   Rotate , AutoContrast , Invert , Equilize , Flip\n",
        "*   Solarize , SolarizeAdd , Polarize ,Contrast\n",
        "*   Color , Brightness , Sharpness , Cutout , CutoutAbs\n",
        "*   Sample Pairing , Identity\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y6NQrrI6Nji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a31f068-b09e-439f-a705-ab904301753b"
      },
      "source": [
        "def ShearX(img, v):  # [-0.3, 0.3]\n",
        "    assert -0.3 <= v <= 0.3\n",
        "    if random.random() > 0.5:\n",
        "        v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, v, 0, 0, 1, 0))\n",
        "\n",
        "\n",
        "def ShearY(img, v):  # [-0.3, 0.3]\n",
        "    assert -0.3 <= v <= 0.3\n",
        "    if random.random() > 0.5:\n",
        "        v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, v, 1, 0))\n",
        "\n",
        "\n",
        "def TranslateX(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
        "    assert -0.45 <= v <= 0.45\n",
        "    if random.random() > 0.5:\n",
        "        v = -v\n",
        "    v = v * img.size[0]\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
        "\n",
        "\n",
        "def TranslateXabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
        "    assert 0 <= v\n",
        "    if random.random() > 0.5:\n",
        "        v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, v, 0, 1, 0))\n",
        "\n",
        "\n",
        "def TranslateY(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
        "    assert -0.45 <= v <= 0.45\n",
        "    if random.random() > 0.5:\n",
        "        v = -v\n",
        "    v = v * img.size[1]\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
        "\n",
        "\n",
        "def TranslateYabs(img, v):  # [-150, 150] => percentage: [-0.45, 0.45]\n",
        "    assert 0 <= v\n",
        "    if random.random() > 0.5:\n",
        "        v = -v\n",
        "    return img.transform(img.size, PIL.Image.AFFINE, (1, 0, 0, 0, 1, v))\n",
        "\n",
        "\n",
        "def Rotate(img, v):  # [-30, 30]\n",
        "    assert -30 <= v <= 30\n",
        "    if random.random() > 0.5:\n",
        "        v = -v\n",
        "    return img.rotate(v)\n",
        "\n",
        "\n",
        "def AutoContrast(img, _):\n",
        "    return PIL.ImageOps.autocontrast(img)\n",
        "\n",
        "\n",
        "def Invert(img, _):\n",
        "    return PIL.ImageOps.invert(img)\n",
        "\n",
        "\n",
        "def Equalize(img, _):\n",
        "    return PIL.ImageOps.equalize(img)\n",
        "\n",
        "\n",
        "def Flip(img, _):  # not from the paper\n",
        "    return PIL.ImageOps.mirror(img)\n",
        "\n",
        "\n",
        "def Solarize(img, v):  # [0, 256]\n",
        "    assert 0 <= v <= 256\n",
        "    return PIL.ImageOps.solarize(img, v)\n",
        "\n",
        "\n",
        "def SolarizeAdd(img, addition=0, threshold=128):\n",
        "    img_np = np.array(img).astype(np.int)\n",
        "    img_np = img_np + addition\n",
        "    img_np = np.clip(img_np, 0, 255)\n",
        "    img_np = img_np.astype(np.uint8)\n",
        "    img = Image.fromarray(img_np)\n",
        "    return PIL.ImageOps.solarize(img, threshold)\n",
        "\n",
        "\n",
        "def Posterize(img, v):  # [4, 8]\n",
        "    v = int(v)\n",
        "    v = max(1, v)\n",
        "    return PIL.ImageOps.posterize(img, v)\n",
        "\n",
        "\n",
        "def Contrast(img, v):  # [0.1,1.9]\n",
        "    assert 0.1 <= v <= 1.9\n",
        "    return PIL.ImageEnhance.Contrast(img).enhance(v)\n",
        "\n",
        "\n",
        "def Color(img, v):  # [0.1,1.9]\n",
        "    assert 0.1 <= v <= 1.9\n",
        "    return PIL.ImageEnhance.Color(img).enhance(v)\n",
        "\n",
        "\n",
        "def Brightness(img, v):  # [0.1,1.9]\n",
        "    assert 0.1 <= v <= 1.9\n",
        "    return PIL.ImageEnhance.Brightness(img).enhance(v)\n",
        "\n",
        "\n",
        "def Sharpness(img, v):  # [0.1,1.9]\n",
        "    assert 0.1 <= v <= 1.9\n",
        "    return PIL.ImageEnhance.Sharpness(img).enhance(v)\n",
        "\n",
        "\n",
        "def Cutout(img, v):  # [0, 60] => percentage: [0, 0.2]\n",
        "    assert 0.0 <= v <= 0.2\n",
        "    if v <= 0.:\n",
        "        return img\n",
        "\n",
        "    v = v * img.size[0]\n",
        "    return CutoutAbs(img, v)\n",
        "\n",
        "\n",
        "def CutoutAbs(img, v):  # [0, 60] => percentage: [0, 0.2]\n",
        "    # assert 0 <= v <= 20\n",
        "    if v < 0:\n",
        "        return img\n",
        "    w, h = img.size\n",
        "    x0 = np.random.uniform(w)\n",
        "    y0 = np.random.uniform(h)\n",
        "\n",
        "    x0 = int(max(0, x0 - v / 2.))\n",
        "    y0 = int(max(0, y0 - v / 2.))\n",
        "    x1 = min(w, x0 + v)\n",
        "    y1 = min(h, y0 + v)\n",
        "\n",
        "    xy = (x0, y0, x1, y1)\n",
        "    color = (125, 123, 114)\n",
        "    # color = (0, 0, 0)\n",
        "    img = img.copy()\n",
        "    PIL.ImageDraw.Draw(img).rectangle(xy, color)\n",
        "    return img\n",
        "\n",
        "\n",
        "def SamplePairing(imgs):  # [0, 0.4]\n",
        "    def f(img1, v):\n",
        "        i = np.random.choice(len(imgs))\n",
        "        img2 = PIL.Image.fromarray(imgs[i])\n",
        "        return PIL.Image.blend(img1, img2, v)\n",
        "\n",
        "    return f\n",
        "\n",
        "\n",
        "def Identity(img, v):\n",
        "    return img\n",
        "\n",
        "\n",
        "def augment_list():  # 16 oeprations and their ranges\n",
        "    l = [\n",
        "        (AutoContrast, 0, 1),\n",
        "        (Equalize, 0, 1),\n",
        "        (Invert, 0, 1),\n",
        "        (Rotate, 0, 30),\n",
        "        (Posterize, 0, 4),\n",
        "        (Solarize, 0, 256),\n",
        "        (SolarizeAdd, 0, 110),\n",
        "        (Color, 0.1, 1.9),\n",
        "        (Contrast, 0.1, 1.9),\n",
        "        (Brightness, 0.1, 1.9),\n",
        "        (Sharpness, 0.1, 1.9),\n",
        "        (ShearX, 0., 0.3),\n",
        "        (ShearY, 0., 0.3),\n",
        "        (CutoutAbs, 0, 40),\n",
        "        (TranslateXabs, 0., 100),\n",
        "        (TranslateYabs, 0., 100),\n",
        "    ]\n",
        "\n",
        "    return l\n",
        "\n",
        "\n",
        "class Lighting(object):\n",
        "    \"\"\"Lighting noise(AlexNet - style PCA - based noise)\"\"\"\n",
        "\n",
        "    def __init__(self, alphastd, eigval, eigvec):\n",
        "        self.alphastd = alphastd\n",
        "        self.eigval = torch.Tensor(eigval)\n",
        "        self.eigvec = torch.Tensor(eigvec)\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if self.alphastd == 0:\n",
        "            return img\n",
        "\n",
        "        alpha = img.new().resize_(3).normal_(0, self.alphastd)\n",
        "        rgb = self.eigvec.type_as(img).clone() \\\n",
        "            .mul(alpha.view(1, 3).expand(3, 3)) \\\n",
        "            .mul(self.eigval.view(1, 3).expand(3, 3)) \\\n",
        "            .sum(1).squeeze()\n",
        "\n",
        "        return img.add(rgb.view(3, 1, 1).expand_as(img))\n",
        "\n",
        "\n",
        "class CutoutDefault(object):\n",
        "    \n",
        "    def __init__(self, length):\n",
        "        self.length = length\n",
        "\n",
        "    def __call__(self, img):\n",
        "        h, w = img.size(1), img.size(2)\n",
        "        mask = np.ones((h, w), np.float32)\n",
        "        y = np.random.randint(h)\n",
        "        x = np.random.randint(w)\n",
        "\n",
        "        y1 = np.clip(y - self.length // 2, 0, h)\n",
        "        y2 = np.clip(y + self.length // 2, 0, h)\n",
        "        x1 = np.clip(x - self.length // 2, 0, w)\n",
        "        x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "        mask[y1: y2, x1: x2] = 0.\n",
        "        mask = torch.from_numpy(mask)\n",
        "        mask = mask.expand_as(img)\n",
        "        img *= mask\n",
        "        return img\n",
        "\n",
        "\n",
        "class RandAugment:\n",
        "    def __init__(self, n, m):\n",
        "        self.n = n      # 16 Operations & their range values is defined\n",
        "        self.m = m      # [0, 30]\n",
        "        self.augment_list = augment_list()\n",
        "\n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_list, k=self.n)\n",
        "        for op, minval, maxval in ops:\n",
        "            val = (float(self.m) / 30) * float(maxval - minval) + minval\n",
        "            img = op(img, val)\n",
        "\n",
        "        return img\n",
        "\n",
        "\n",
        "randAug = RandAugment(2 , 5 )\n",
        "img = randAug.__call__(array_to_img(x_train[0]))\n",
        "img  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAEtUlEQVR4nLXWy44UVRgH8HOtOnXv6u7qbubCAAMzUcIlIIaAEQkb3LD1PXwPH8M9MW7cuWJhNGoiGIcZcGAYpqdv1V3VVXXuvkMlnv2XX/755zv5APifH2wx8/DLR3k+d5HpOvZiz8+6Qb8TOpgS1wOYzBe5UDbtJN9+931LoNPv59Npl4HLPXZtFF3aGTAXWW0tdKpGVDWX2hAM9z+9wzknLQCPQOCCnR67NEwGWdfzAwhhzZtGcguh43lAWWv48cFvSpk2AIMqisjeZtrzMDVNORfaoLpSyAFxJySOmy8LQkCSREraNkDqEs91k8DLYqqN1gBgggFC3EhCCLFG89pi1I38YrVuA2QdFlHMGEbYep4nlTYAWiuEslpIY6XVwhLn/DzXUrcBNrIgdlToO9BKACy0htcVArAXJUHAVstpEsdFIwux1hq3AbqRR0TuUuK7Pq+lNKrTSa21QiMpGz8MTyf86HjJAlnyVsCg26vnDYKkrGQtFIG4khoBUEvRSWOh7ZuT0/lK60JVCrQquZ+loYcQzVcLuS6R1gYYS0kYMgnY328O1nzNmFsqB2PUBgCIQkoBAC6jPggIQAghCYzrJdOzopournQZb8BUYC/w2wB1I6GsAVDr9UpIpBArq2JVFZvbxKpipw93N2jVwINzd393sw2gobZaWWs95oWRfzqp355MCLXO+LQZT64N6JOvrh19mG/yq45t2gCdTqiIKsvGSr0slsfvxmVZegx9fLsaMmdzc6ezcZkWZivK+r0RagEU+UxWOYWCYEAwrsplGvmjTick7mCjv3nz0V8nycGhAIxu3fq8DYAh0HVpmgLIlYbNQoLxyi7mIo2De48fb+3f//OXw5SEIenmuWgDQAu0lFYrYoGtJTSg2/FHPXzn/t4nD+6v6tJVyytbGRb1hzdHbQCjdM2NQr4mCUbB1VE6itGl3e1bXzy+sH/z+OjVxe10dP2GgWY0yNqUTDFZFJVuoOd7GNlBz3//Md+983TrxlMAUlmskyjJ9m47i4L4SZsEvG58l8Q+9pFyDI9C/OybZw++fhJnw9m7I4xUvl5O/v2HZDsvD163SWCsAEZDZZSVEFrmxrfv3nUpffXH74vTI86bYjF/f/gKF/rn589bfRXAGCUI9bXSAqhhkv70w4/d4cvBhW1RLSl1wyAmCOdn76hutWjGQIdgRgxA0OLACDmdnpWTM0+uDMDdtNfZyJTmgdKjQa8NgKDLXM8CFXh+EPUr2fQihwAllmODnIqa4fCyEeL89UsLbJuSHYIE58Y6BruVrDE2PvOCKHP8ZDjoF4tJJWS2fXX/5meGeG0SDDMkZ7Nam/UaWKQJIXHccyit1yuPEiDIry9eXNkfRxt71+89bANc3HYSyA7fV+OJFdoNQ7KultqUGKD5ZFaUqpFLbJf45Awh2AaIU1pPqnSAQeBPx7wRgjixEMBILTVf1ovAc5uqycJ6fDZvAxBGWOx0Q0RqTj2zWhCgkccGmhrNc8cnlDgY++fTqWh3tpQlBTgMg4Z6NnBZkphyVZercVlp2ejI6TFKFefaoUKKNsDJMeA5izLFPJmEoNsl5brK82oxcxYzgA021mqtiUEOAv8BoXaMyk7bl8sAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F557DB59BD0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDhdMNB7rTc7"
      },
      "source": [
        "# Visulaization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "KMmzIslTrWeG",
        "outputId": "45c90d7d-e0f2-47cc-9e31-004143d8aabc"
      },
      "source": [
        "no_image = 5\n",
        "f, axarr = plt.subplots(no_image,3,figsize=(25, 15))\n",
        "for i in range(no_image):\n",
        "\n",
        "  randAug = RandAugment(2 , 5)\n",
        "  img_strong = randAug.__call__(array_to_img(x_train[i]))\n",
        "\n",
        "  weak_aug = WeakAugment(5)\n",
        "  img_weak = weak_aug.__call__(array_to_img(x_train[i]))\n",
        "\n",
        "  axarr[i,0].imshow(x_train[i])\n",
        "  axarr[i,1].imshow(img_weak)\n",
        "  axarr[i,2].imshow(img_strong)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x1080 with 15 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSO77t4PFz2f"
      },
      "source": [
        "# Supervised Learning Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW-TVHKD84HE"
      },
      "source": [
        "## VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4duhJ71HF7fM"
      },
      "source": [
        "def vgg(output_label_cnt) :\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(4096 , activation = 'relu'))\n",
        "  model.add(Dense(4096 , activation = 'relu'))\n",
        "  model.add(Dense(output_label_cnt , activation = 'softmax'))\n",
        "\n",
        "  print(model.summary())\n",
        "  return model\n",
        "\n",
        "### For 10 labels class\n",
        "vgg(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsQ7IkvL8_i3"
      },
      "source": [
        "## Google Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqYrWzQWHY-C",
        "outputId": "ffc9e89f-a23d-4f32-b5aa-764d9a97dcb0"
      },
      "source": [
        "def get_GoogLeNet( weights=None, include_top=False ):\n",
        "  \n",
        "  def conv2d_bn(x,filters,num_row,num_col,padding='same',\n",
        "                strides=(1, 1),normalizer=True,activation='relu',name=None):\n",
        "      if name is not None:\n",
        "          conv_name = name + '_conv'\n",
        "          bn_name = name + '_bn'\n",
        "          act_name = name + '_act'\n",
        "      else:\n",
        "          conv_name = None\n",
        "          bn_name = None\n",
        "          act_name = None\n",
        "      if K.image_data_format() == 'channels_first':\n",
        "          bn_axis = 1\n",
        "      else:\n",
        "          bn_axis = 3\n",
        "      x = Conv2D(\n",
        "              filters, (num_row, num_col),\n",
        "              strides=strides, padding=padding,\n",
        "              use_bias=False, name=conv_name)(x)\n",
        "      if normalizer:\n",
        "          x = BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
        "      if activation:\n",
        "          x = Activation(activation, name=act_name)(x)\n",
        "      return x\n",
        "  def concatenated_block(x, specs, channel_axis, name):\n",
        "      (br0, br1, br2, br3) = specs   # ((64,), (96,128), (16,32), (32,))\n",
        "\n",
        "      branch_0 = conv2d_bn(x, br0[0], 1, 1, name=name+\"_Branch_0_a_1x1\")\n",
        "\n",
        "      branch_1 = conv2d_bn(x, br1[0], 1, 1, name=name+\"_Branch_1_a_1x1\")\n",
        "      branch_1 = conv2d_bn(branch_1, br1[1], 3, 3, name=name+\"_Branch_1_b_3x3\")\n",
        "\n",
        "      branch_2 = conv2d_bn(x, br2[0], 1, 1, name=name+\"_Branch_2_a_1x1\")\n",
        "      branch_2 = conv2d_bn(branch_2, br2[1], 3, 3, name=name+\"_Branch_2_b_3x3\")\n",
        "\n",
        "      branch_3 = MaxPooling2D( (3, 3), strides=(1, 1), padding='same', name=name+\"_Branch_3_a_max\")(x)  \n",
        "      branch_3 = conv2d_bn(branch_3, br3[0], 1, 1, name=name+\"_Branch_3_b_1x1\")\n",
        "\n",
        "      x = layers.concatenate(\n",
        "          [branch_0, branch_1, branch_2, branch_3],\n",
        "          axis=channel_axis,\n",
        "          name=name+\"_Concatenated\")\n",
        "      return x\n",
        "  def InceptionV1(include_top=True,\n",
        "                  weights='imagenet',\n",
        "                  input_tensor=None,\n",
        "                  input_shape=None,\n",
        "                  pooling=None,\n",
        "                  classes=1001):\n",
        "      if weights not in {'imagenet', None}:\n",
        "          raise ValueError('The `weights` argument should be either '\n",
        "                           '`None` (random initialization) or `imagenet` '\n",
        "                           '(pre-training on ImageNet).')\n",
        "\n",
        "      if weights == 'imagenet' and include_top and classes != 1001:\n",
        "          raise ValueError('If using `weights` as imagenet with `include_top`'\n",
        "                           ' as true, `classes` should be 1001')\n",
        "      input_shape = (224,224,3)\n",
        "      img_input = Input(shape=input_shape)\n",
        "      if K.image_data_format() == 'channels_first':\n",
        "          channel_axis = 1\n",
        "      else:\n",
        "          channel_axis = 3\n",
        "\n",
        "      x = img_input\n",
        "      x = conv2d_bn(x,  64, 7, 7, strides=(2, 2), padding='same',  name='Conv2d_1a_7x7')  \n",
        "      x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='MaxPool_2a_3x3')(x)  \n",
        "      x = conv2d_bn(x,  64, 1, 1, strides=(1, 1), padding='same', name='Conv2d_2b_1x1')  \n",
        "      x = conv2d_bn(x, 192, 3, 3, strides=(1, 1), padding='same', name='Conv2d_2c_3x3')  \n",
        "      x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='MaxPool_3a_3x3')(x)  \n",
        "      x = concatenated_block(x, (( 64,), ( 96,128), (16, 32), ( 32,)), channel_axis, 'Mixed_3b')\n",
        "      x = concatenated_block(x, ((128,), (128,192), (32, 96), ( 64,)), channel_axis, 'Mixed_3c')\n",
        "      x = MaxPooling2D((3, 3), strides=(2, 2), padding='same', name='MaxPool_4a_3x3')(x)  \n",
        "      x = concatenated_block(x, ((192,), ( 96,208), (16, 48), ( 64,)), channel_axis, 'Mixed_4b')\n",
        "      x = concatenated_block(x, ((160,), (112,224), (24, 64), ( 64,)), channel_axis, 'Mixed_4c')\n",
        "      x = concatenated_block(x, ((128,), (128,256), (24, 64), ( 64,)), channel_axis, 'Mixed_4d')\n",
        "      x = concatenated_block(x, ((112,), (144,288), (32, 64), ( 64,)), channel_axis, 'Mixed_4e')\n",
        "      x = concatenated_block(x, ((256,), (160,320), (32,128), (128,)), channel_axis, 'Mixed_4f')\n",
        "      x = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='MaxPool_5a_2x2')(x)  \n",
        "      x = concatenated_block(x, ((256,), (160,320), (32,128), (128,)), channel_axis, 'Mixed_5b')\n",
        "      x = concatenated_block(x, ((384,), (192,384), (48,128), (128,)), channel_axis, 'Mixed_5c')\n",
        "      if include_top:\n",
        "          x = AveragePooling2D((7, 7), strides=(1, 1), padding='valid')(x)  \n",
        "          x = Dropout(0.2)(x)  # slim has keep_prob (@0.8), keras uses drop_fraction\n",
        "          x = Conv2D(classes, (1, 1), strides=(1,1), padding='valid', use_bias=True, name='Logits')(x)\n",
        "          x = Flatten(name='Logits_flat')(x)\n",
        "          x = Activation('softmax', name='Predictions')(x)\n",
        "      else:\n",
        "          if pooling == 'avg':\n",
        "              x = GlobalAveragePooling2D(name='global_pooling')(x)\n",
        "          elif pooling == 'max':\n",
        "              x = GlobalMaxPooling2D(    name='global_pooling')(x)\n",
        "      if input_tensor is not None:\n",
        "          inputs = get_source_inputs(input_tensor)\n",
        "      else:\n",
        "          inputs = img_input\n",
        "      model = Model(inputs, x, name='inception_v1')\n",
        "      # LOAD model weights\n",
        "      if weights == 'imagenet':\n",
        "          if K.image_data_format() == 'channels_first':\n",
        "              if K.backend() == 'tensorflow':\n",
        "                  warnings.warn('You are using the TensorFlow backend, yet you '\n",
        "                                'are using the Theano '\n",
        "                                'image data format convention '\n",
        "                                '(`image_data_format=\"channels_first\"`). '\n",
        "                                'For best performance, set '\n",
        "                                '`image_data_format=\"channels_last\"` in '\n",
        "                                'your Keras config '\n",
        "                                'at ~/.keras/keras.json.')\n",
        "          if include_top:\n",
        "              weights_path = get_file(\n",
        "                  'inception_v1_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                  WEIGHTS_PATH,\n",
        "                  cache_subdir='models',\n",
        "                  md5_hash='723bf2f662a5c07db50d28c8d35b626d')\n",
        "          else:\n",
        "              weights_path = get_file(\n",
        "                  'inception_v1_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                  WEIGHTS_PATH_NO_TOP,\n",
        "                  cache_subdir='models',\n",
        "                  md5_hash='6fa8ecdc5f6c402a59909437f0f5c975')\n",
        "          model.load_weights(weights_path)\n",
        "          if K.backend() == 'theano':\n",
        "              convert_all_kernels_in_model(model)    \n",
        "      return model\n",
        "  inception_v1 = InceptionV1(include_top=False, weights=weights)\n",
        "  \n",
        "  return inception_v1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def googleNetModel() : \n",
        "  dropout_rate = 0.2\n",
        "  nCluster = 10\n",
        "  activation = 'relu'\n",
        "  googlenet = get_GoogLeNet( weights = None, include_top=False )\n",
        "  x = googlenet.output\n",
        "  x = BatchNormalization()(x)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dropout(dropout_rate)(x)\n",
        "  x = Dense(nCluster, activation=activation)(x)\n",
        "  model = Model(inputs=googlenet.input, outputs=x)\n",
        "  return model\n",
        "\n",
        "model = googleNetModel()\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_1a_7x7_conv (Conv2D)     (None, 112, 112, 64) 9408        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_1a_7x7_bn (BatchNormaliz (None, 112, 112, 64) 192         Conv2d_1a_7x7_conv[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_1a_7x7_act (Activation)  (None, 112, 112, 64) 0           Conv2d_1a_7x7_bn[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool_2a_3x3 (MaxPooling2D)   (None, 56, 56, 64)   0           Conv2d_1a_7x7_act[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2b_1x1_conv (Conv2D)     (None, 56, 56, 64)   4096        MaxPool_2a_3x3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2b_1x1_bn (BatchNormaliz (None, 56, 56, 64)   192         Conv2d_2b_1x1_conv[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2b_1x1_act (Activation)  (None, 56, 56, 64)   0           Conv2d_2b_1x1_bn[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2c_3x3_conv (Conv2D)     (None, 56, 56, 192)  110592      Conv2d_2b_1x1_act[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2c_3x3_bn (BatchNormaliz (None, 56, 56, 192)  576         Conv2d_2c_3x3_conv[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2c_3x3_act (Activation)  (None, 56, 56, 192)  0           Conv2d_2c_3x3_bn[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool_3a_3x3 (MaxPooling2D)   (None, 28, 28, 192)  0           Conv2d_2c_3x3_act[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_1_a_1x1_conv (C (None, 28, 28, 96)   18432       MaxPool_3a_3x3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_2_a_1x1_conv (C (None, 28, 28, 16)   3072        MaxPool_3a_3x3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_1_a_1x1_bn (Bat (None, 28, 28, 96)   288         Mixed_3b_Branch_1_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_2_a_1x1_bn (Bat (None, 28, 28, 16)   48          Mixed_3b_Branch_2_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_1_a_1x1_act (Ac (None, 28, 28, 96)   0           Mixed_3b_Branch_1_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_2_a_1x1_act (Ac (None, 28, 28, 16)   0           Mixed_3b_Branch_2_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_3_a_max (MaxPoo (None, 28, 28, 192)  0           MaxPool_3a_3x3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_0_a_1x1_conv (C (None, 28, 28, 64)   12288       MaxPool_3a_3x3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_1_b_3x3_conv (C (None, 28, 28, 128)  110592      Mixed_3b_Branch_1_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_2_b_3x3_conv (C (None, 28, 28, 32)   4608        Mixed_3b_Branch_2_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_3_b_1x1_conv (C (None, 28, 28, 32)   6144        Mixed_3b_Branch_3_a_max[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_0_a_1x1_bn (Bat (None, 28, 28, 64)   192         Mixed_3b_Branch_0_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_1_b_3x3_bn (Bat (None, 28, 28, 128)  384         Mixed_3b_Branch_1_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_2_b_3x3_bn (Bat (None, 28, 28, 32)   96          Mixed_3b_Branch_2_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_3_b_1x1_bn (Bat (None, 28, 28, 32)   96          Mixed_3b_Branch_3_b_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_0_a_1x1_act (Ac (None, 28, 28, 64)   0           Mixed_3b_Branch_0_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_1_b_3x3_act (Ac (None, 28, 28, 128)  0           Mixed_3b_Branch_1_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_2_b_3x3_act (Ac (None, 28, 28, 32)   0           Mixed_3b_Branch_2_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Branch_3_b_1x1_act (Ac (None, 28, 28, 32)   0           Mixed_3b_Branch_3_b_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3b_Concatenated (Concaten (None, 28, 28, 256)  0           Mixed_3b_Branch_0_a_1x1_act[0][0]\n",
            "                                                                 Mixed_3b_Branch_1_b_3x3_act[0][0]\n",
            "                                                                 Mixed_3b_Branch_2_b_3x3_act[0][0]\n",
            "                                                                 Mixed_3b_Branch_3_b_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_1_a_1x1_conv (C (None, 28, 28, 128)  32768       Mixed_3b_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_2_a_1x1_conv (C (None, 28, 28, 32)   8192        Mixed_3b_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_1_a_1x1_bn (Bat (None, 28, 28, 128)  384         Mixed_3c_Branch_1_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_2_a_1x1_bn (Bat (None, 28, 28, 32)   96          Mixed_3c_Branch_2_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_1_a_1x1_act (Ac (None, 28, 28, 128)  0           Mixed_3c_Branch_1_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_2_a_1x1_act (Ac (None, 28, 28, 32)   0           Mixed_3c_Branch_2_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_3_a_max (MaxPoo (None, 28, 28, 256)  0           Mixed_3b_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_0_a_1x1_conv (C (None, 28, 28, 128)  32768       Mixed_3b_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_1_b_3x3_conv (C (None, 28, 28, 192)  221184      Mixed_3c_Branch_1_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_2_b_3x3_conv (C (None, 28, 28, 96)   27648       Mixed_3c_Branch_2_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_3_b_1x1_conv (C (None, 28, 28, 64)   16384       Mixed_3c_Branch_3_a_max[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_0_a_1x1_bn (Bat (None, 28, 28, 128)  384         Mixed_3c_Branch_0_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_1_b_3x3_bn (Bat (None, 28, 28, 192)  576         Mixed_3c_Branch_1_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_2_b_3x3_bn (Bat (None, 28, 28, 96)   288         Mixed_3c_Branch_2_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_3_b_1x1_bn (Bat (None, 28, 28, 64)   192         Mixed_3c_Branch_3_b_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_0_a_1x1_act (Ac (None, 28, 28, 128)  0           Mixed_3c_Branch_0_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_1_b_3x3_act (Ac (None, 28, 28, 192)  0           Mixed_3c_Branch_1_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_2_b_3x3_act (Ac (None, 28, 28, 96)   0           Mixed_3c_Branch_2_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Branch_3_b_1x1_act (Ac (None, 28, 28, 64)   0           Mixed_3c_Branch_3_b_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_3c_Concatenated (Concaten (None, 28, 28, 480)  0           Mixed_3c_Branch_0_a_1x1_act[0][0]\n",
            "                                                                 Mixed_3c_Branch_1_b_3x3_act[0][0]\n",
            "                                                                 Mixed_3c_Branch_2_b_3x3_act[0][0]\n",
            "                                                                 Mixed_3c_Branch_3_b_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "MaxPool_4a_3x3 (MaxPooling2D)   (None, 14, 14, 480)  0           Mixed_3c_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_1_a_1x1_conv (C (None, 14, 14, 96)   46080       MaxPool_4a_3x3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_2_a_1x1_conv (C (None, 14, 14, 16)   7680        MaxPool_4a_3x3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_1_a_1x1_bn (Bat (None, 14, 14, 96)   288         Mixed_4b_Branch_1_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_2_a_1x1_bn (Bat (None, 14, 14, 16)   48          Mixed_4b_Branch_2_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_1_a_1x1_act (Ac (None, 14, 14, 96)   0           Mixed_4b_Branch_1_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_2_a_1x1_act (Ac (None, 14, 14, 16)   0           Mixed_4b_Branch_2_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_3_a_max (MaxPoo (None, 14, 14, 480)  0           MaxPool_4a_3x3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_0_a_1x1_conv (C (None, 14, 14, 192)  92160       MaxPool_4a_3x3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_1_b_3x3_conv (C (None, 14, 14, 208)  179712      Mixed_4b_Branch_1_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_2_b_3x3_conv (C (None, 14, 14, 48)   6912        Mixed_4b_Branch_2_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_3_b_1x1_conv (C (None, 14, 14, 64)   30720       Mixed_4b_Branch_3_a_max[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_0_a_1x1_bn (Bat (None, 14, 14, 192)  576         Mixed_4b_Branch_0_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_1_b_3x3_bn (Bat (None, 14, 14, 208)  624         Mixed_4b_Branch_1_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_2_b_3x3_bn (Bat (None, 14, 14, 48)   144         Mixed_4b_Branch_2_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_3_b_1x1_bn (Bat (None, 14, 14, 64)   192         Mixed_4b_Branch_3_b_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_0_a_1x1_act (Ac (None, 14, 14, 192)  0           Mixed_4b_Branch_0_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_1_b_3x3_act (Ac (None, 14, 14, 208)  0           Mixed_4b_Branch_1_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_2_b_3x3_act (Ac (None, 14, 14, 48)   0           Mixed_4b_Branch_2_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Branch_3_b_1x1_act (Ac (None, 14, 14, 64)   0           Mixed_4b_Branch_3_b_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4b_Concatenated (Concaten (None, 14, 14, 512)  0           Mixed_4b_Branch_0_a_1x1_act[0][0]\n",
            "                                                                 Mixed_4b_Branch_1_b_3x3_act[0][0]\n",
            "                                                                 Mixed_4b_Branch_2_b_3x3_act[0][0]\n",
            "                                                                 Mixed_4b_Branch_3_b_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_1_a_1x1_conv (C (None, 14, 14, 112)  57344       Mixed_4b_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_2_a_1x1_conv (C (None, 14, 14, 24)   12288       Mixed_4b_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_1_a_1x1_bn (Bat (None, 14, 14, 112)  336         Mixed_4c_Branch_1_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_2_a_1x1_bn (Bat (None, 14, 14, 24)   72          Mixed_4c_Branch_2_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_1_a_1x1_act (Ac (None, 14, 14, 112)  0           Mixed_4c_Branch_1_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_2_a_1x1_act (Ac (None, 14, 14, 24)   0           Mixed_4c_Branch_2_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_3_a_max (MaxPoo (None, 14, 14, 512)  0           Mixed_4b_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_0_a_1x1_conv (C (None, 14, 14, 160)  81920       Mixed_4b_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_1_b_3x3_conv (C (None, 14, 14, 224)  225792      Mixed_4c_Branch_1_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_2_b_3x3_conv (C (None, 14, 14, 64)   13824       Mixed_4c_Branch_2_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_3_b_1x1_conv (C (None, 14, 14, 64)   32768       Mixed_4c_Branch_3_a_max[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_0_a_1x1_bn (Bat (None, 14, 14, 160)  480         Mixed_4c_Branch_0_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_1_b_3x3_bn (Bat (None, 14, 14, 224)  672         Mixed_4c_Branch_1_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_2_b_3x3_bn (Bat (None, 14, 14, 64)   192         Mixed_4c_Branch_2_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_3_b_1x1_bn (Bat (None, 14, 14, 64)   192         Mixed_4c_Branch_3_b_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_0_a_1x1_act (Ac (None, 14, 14, 160)  0           Mixed_4c_Branch_0_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_1_b_3x3_act (Ac (None, 14, 14, 224)  0           Mixed_4c_Branch_1_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_2_b_3x3_act (Ac (None, 14, 14, 64)   0           Mixed_4c_Branch_2_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Branch_3_b_1x1_act (Ac (None, 14, 14, 64)   0           Mixed_4c_Branch_3_b_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4c_Concatenated (Concaten (None, 14, 14, 512)  0           Mixed_4c_Branch_0_a_1x1_act[0][0]\n",
            "                                                                 Mixed_4c_Branch_1_b_3x3_act[0][0]\n",
            "                                                                 Mixed_4c_Branch_2_b_3x3_act[0][0]\n",
            "                                                                 Mixed_4c_Branch_3_b_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_1_a_1x1_conv (C (None, 14, 14, 128)  65536       Mixed_4c_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_2_a_1x1_conv (C (None, 14, 14, 24)   12288       Mixed_4c_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_1_a_1x1_bn (Bat (None, 14, 14, 128)  384         Mixed_4d_Branch_1_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_2_a_1x1_bn (Bat (None, 14, 14, 24)   72          Mixed_4d_Branch_2_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_1_a_1x1_act (Ac (None, 14, 14, 128)  0           Mixed_4d_Branch_1_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_2_a_1x1_act (Ac (None, 14, 14, 24)   0           Mixed_4d_Branch_2_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_3_a_max (MaxPoo (None, 14, 14, 512)  0           Mixed_4c_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_0_a_1x1_conv (C (None, 14, 14, 128)  65536       Mixed_4c_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_1_b_3x3_conv (C (None, 14, 14, 256)  294912      Mixed_4d_Branch_1_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_2_b_3x3_conv (C (None, 14, 14, 64)   13824       Mixed_4d_Branch_2_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_3_b_1x1_conv (C (None, 14, 14, 64)   32768       Mixed_4d_Branch_3_a_max[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_0_a_1x1_bn (Bat (None, 14, 14, 128)  384         Mixed_4d_Branch_0_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_1_b_3x3_bn (Bat (None, 14, 14, 256)  768         Mixed_4d_Branch_1_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_2_b_3x3_bn (Bat (None, 14, 14, 64)   192         Mixed_4d_Branch_2_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_3_b_1x1_bn (Bat (None, 14, 14, 64)   192         Mixed_4d_Branch_3_b_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_0_a_1x1_act (Ac (None, 14, 14, 128)  0           Mixed_4d_Branch_0_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_1_b_3x3_act (Ac (None, 14, 14, 256)  0           Mixed_4d_Branch_1_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_2_b_3x3_act (Ac (None, 14, 14, 64)   0           Mixed_4d_Branch_2_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Branch_3_b_1x1_act (Ac (None, 14, 14, 64)   0           Mixed_4d_Branch_3_b_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4d_Concatenated (Concaten (None, 14, 14, 512)  0           Mixed_4d_Branch_0_a_1x1_act[0][0]\n",
            "                                                                 Mixed_4d_Branch_1_b_3x3_act[0][0]\n",
            "                                                                 Mixed_4d_Branch_2_b_3x3_act[0][0]\n",
            "                                                                 Mixed_4d_Branch_3_b_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_1_a_1x1_conv (C (None, 14, 14, 144)  73728       Mixed_4d_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_2_a_1x1_conv (C (None, 14, 14, 32)   16384       Mixed_4d_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_1_a_1x1_bn (Bat (None, 14, 14, 144)  432         Mixed_4e_Branch_1_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_2_a_1x1_bn (Bat (None, 14, 14, 32)   96          Mixed_4e_Branch_2_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_1_a_1x1_act (Ac (None, 14, 14, 144)  0           Mixed_4e_Branch_1_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_2_a_1x1_act (Ac (None, 14, 14, 32)   0           Mixed_4e_Branch_2_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_3_a_max (MaxPoo (None, 14, 14, 512)  0           Mixed_4d_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_0_a_1x1_conv (C (None, 14, 14, 112)  57344       Mixed_4d_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_1_b_3x3_conv (C (None, 14, 14, 288)  373248      Mixed_4e_Branch_1_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_2_b_3x3_conv (C (None, 14, 14, 64)   18432       Mixed_4e_Branch_2_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_3_b_1x1_conv (C (None, 14, 14, 64)   32768       Mixed_4e_Branch_3_a_max[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_0_a_1x1_bn (Bat (None, 14, 14, 112)  336         Mixed_4e_Branch_0_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_1_b_3x3_bn (Bat (None, 14, 14, 288)  864         Mixed_4e_Branch_1_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_2_b_3x3_bn (Bat (None, 14, 14, 64)   192         Mixed_4e_Branch_2_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_3_b_1x1_bn (Bat (None, 14, 14, 64)   192         Mixed_4e_Branch_3_b_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_0_a_1x1_act (Ac (None, 14, 14, 112)  0           Mixed_4e_Branch_0_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_1_b_3x3_act (Ac (None, 14, 14, 288)  0           Mixed_4e_Branch_1_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_2_b_3x3_act (Ac (None, 14, 14, 64)   0           Mixed_4e_Branch_2_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Branch_3_b_1x1_act (Ac (None, 14, 14, 64)   0           Mixed_4e_Branch_3_b_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4e_Concatenated (Concaten (None, 14, 14, 528)  0           Mixed_4e_Branch_0_a_1x1_act[0][0]\n",
            "                                                                 Mixed_4e_Branch_1_b_3x3_act[0][0]\n",
            "                                                                 Mixed_4e_Branch_2_b_3x3_act[0][0]\n",
            "                                                                 Mixed_4e_Branch_3_b_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_1_a_1x1_conv (C (None, 14, 14, 160)  84480       Mixed_4e_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_2_a_1x1_conv (C (None, 14, 14, 32)   16896       Mixed_4e_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_1_a_1x1_bn (Bat (None, 14, 14, 160)  480         Mixed_4f_Branch_1_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_2_a_1x1_bn (Bat (None, 14, 14, 32)   96          Mixed_4f_Branch_2_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_1_a_1x1_act (Ac (None, 14, 14, 160)  0           Mixed_4f_Branch_1_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_2_a_1x1_act (Ac (None, 14, 14, 32)   0           Mixed_4f_Branch_2_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_3_a_max (MaxPoo (None, 14, 14, 528)  0           Mixed_4e_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_0_a_1x1_conv (C (None, 14, 14, 256)  135168      Mixed_4e_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_1_b_3x3_conv (C (None, 14, 14, 320)  460800      Mixed_4f_Branch_1_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_2_b_3x3_conv (C (None, 14, 14, 128)  36864       Mixed_4f_Branch_2_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_3_b_1x1_conv (C (None, 14, 14, 128)  67584       Mixed_4f_Branch_3_a_max[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_0_a_1x1_bn (Bat (None, 14, 14, 256)  768         Mixed_4f_Branch_0_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_1_b_3x3_bn (Bat (None, 14, 14, 320)  960         Mixed_4f_Branch_1_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_2_b_3x3_bn (Bat (None, 14, 14, 128)  384         Mixed_4f_Branch_2_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_3_b_1x1_bn (Bat (None, 14, 14, 128)  384         Mixed_4f_Branch_3_b_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_0_a_1x1_act (Ac (None, 14, 14, 256)  0           Mixed_4f_Branch_0_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_1_b_3x3_act (Ac (None, 14, 14, 320)  0           Mixed_4f_Branch_1_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_2_b_3x3_act (Ac (None, 14, 14, 128)  0           Mixed_4f_Branch_2_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Branch_3_b_1x1_act (Ac (None, 14, 14, 128)  0           Mixed_4f_Branch_3_b_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_4f_Concatenated (Concaten (None, 14, 14, 832)  0           Mixed_4f_Branch_0_a_1x1_act[0][0]\n",
            "                                                                 Mixed_4f_Branch_1_b_3x3_act[0][0]\n",
            "                                                                 Mixed_4f_Branch_2_b_3x3_act[0][0]\n",
            "                                                                 Mixed_4f_Branch_3_b_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "MaxPool_5a_2x2 (MaxPooling2D)   (None, 7, 7, 832)    0           Mixed_4f_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_1_a_1x1_conv (C (None, 7, 7, 160)    133120      MaxPool_5a_2x2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_2_a_1x1_conv (C (None, 7, 7, 32)     26624       MaxPool_5a_2x2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_1_a_1x1_bn (Bat (None, 7, 7, 160)    480         Mixed_5b_Branch_1_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_2_a_1x1_bn (Bat (None, 7, 7, 32)     96          Mixed_5b_Branch_2_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_1_a_1x1_act (Ac (None, 7, 7, 160)    0           Mixed_5b_Branch_1_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_2_a_1x1_act (Ac (None, 7, 7, 32)     0           Mixed_5b_Branch_2_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_3_a_max (MaxPoo (None, 7, 7, 832)    0           MaxPool_5a_2x2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_0_a_1x1_conv (C (None, 7, 7, 256)    212992      MaxPool_5a_2x2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_1_b_3x3_conv (C (None, 7, 7, 320)    460800      Mixed_5b_Branch_1_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_2_b_3x3_conv (C (None, 7, 7, 128)    36864       Mixed_5b_Branch_2_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_3_b_1x1_conv (C (None, 7, 7, 128)    106496      Mixed_5b_Branch_3_a_max[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_0_a_1x1_bn (Bat (None, 7, 7, 256)    768         Mixed_5b_Branch_0_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_1_b_3x3_bn (Bat (None, 7, 7, 320)    960         Mixed_5b_Branch_1_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_2_b_3x3_bn (Bat (None, 7, 7, 128)    384         Mixed_5b_Branch_2_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_3_b_1x1_bn (Bat (None, 7, 7, 128)    384         Mixed_5b_Branch_3_b_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_0_a_1x1_act (Ac (None, 7, 7, 256)    0           Mixed_5b_Branch_0_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_1_b_3x3_act (Ac (None, 7, 7, 320)    0           Mixed_5b_Branch_1_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_2_b_3x3_act (Ac (None, 7, 7, 128)    0           Mixed_5b_Branch_2_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Branch_3_b_1x1_act (Ac (None, 7, 7, 128)    0           Mixed_5b_Branch_3_b_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5b_Concatenated (Concaten (None, 7, 7, 832)    0           Mixed_5b_Branch_0_a_1x1_act[0][0]\n",
            "                                                                 Mixed_5b_Branch_1_b_3x3_act[0][0]\n",
            "                                                                 Mixed_5b_Branch_2_b_3x3_act[0][0]\n",
            "                                                                 Mixed_5b_Branch_3_b_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_1_a_1x1_conv (C (None, 7, 7, 192)    159744      Mixed_5b_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_2_a_1x1_conv (C (None, 7, 7, 48)     39936       Mixed_5b_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_1_a_1x1_bn (Bat (None, 7, 7, 192)    576         Mixed_5c_Branch_1_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_2_a_1x1_bn (Bat (None, 7, 7, 48)     144         Mixed_5c_Branch_2_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_1_a_1x1_act (Ac (None, 7, 7, 192)    0           Mixed_5c_Branch_1_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_2_a_1x1_act (Ac (None, 7, 7, 48)     0           Mixed_5c_Branch_2_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_3_a_max (MaxPoo (None, 7, 7, 832)    0           Mixed_5b_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_0_a_1x1_conv (C (None, 7, 7, 384)    319488      Mixed_5b_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_1_b_3x3_conv (C (None, 7, 7, 384)    663552      Mixed_5c_Branch_1_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_2_b_3x3_conv (C (None, 7, 7, 128)    55296       Mixed_5c_Branch_2_a_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_3_b_1x1_conv (C (None, 7, 7, 128)    106496      Mixed_5c_Branch_3_a_max[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_0_a_1x1_bn (Bat (None, 7, 7, 384)    1152        Mixed_5c_Branch_0_a_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_1_b_3x3_bn (Bat (None, 7, 7, 384)    1152        Mixed_5c_Branch_1_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_2_b_3x3_bn (Bat (None, 7, 7, 128)    384         Mixed_5c_Branch_2_b_3x3_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_3_b_1x1_bn (Bat (None, 7, 7, 128)    384         Mixed_5c_Branch_3_b_1x1_conv[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_0_a_1x1_act (Ac (None, 7, 7, 384)    0           Mixed_5c_Branch_0_a_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_1_b_3x3_act (Ac (None, 7, 7, 384)    0           Mixed_5c_Branch_1_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_2_b_3x3_act (Ac (None, 7, 7, 128)    0           Mixed_5c_Branch_2_b_3x3_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Branch_3_b_1x1_act (Ac (None, 7, 7, 128)    0           Mixed_5c_Branch_3_b_1x1_bn[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_5c_Concatenated (Concaten (None, 7, 7, 1024)   0           Mixed_5c_Branch_0_a_1x1_act[0][0]\n",
            "                                                                 Mixed_5c_Branch_1_b_3x3_act[0][0]\n",
            "                                                                 Mixed_5c_Branch_2_b_3x3_act[0][0]\n",
            "                                                                 Mixed_5c_Branch_3_b_1x1_act[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 7, 7, 1024)   4096        Mixed_5c_Concatenated[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1024)         0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           10250       dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 5,621,530\n",
            "Trainable params: 5,604,922\n",
            "Non-trainable params: 16,608\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91NRPYHT9Gpd"
      },
      "source": [
        "## ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPZRAbDrQ1vv",
        "outputId": "8af7ada0-b9d9-45a1-ab37-accdac846af2"
      },
      "source": [
        "def resNet50(output_lables) : \n",
        "\n",
        "  def convBlock(x , filters_1 , filters_2 , filters_3 ) : \n",
        "    x = Conv2D( filters_1 , (1,1) , padding = 'same' , activation = 'relu' )(x)\n",
        "    x = Conv2D( filters_2 , (3,3) , padding = 'same' , activation = 'relu' )(x)\n",
        "    x = Conv2D( filters_3 , (1,1) , padding = 'same' , activation = 'relu' )(x)\n",
        "    return x \n",
        "\n",
        "  def combineConvBlock(x , n , filters_1 , filters_2 , filters_3) :\n",
        "    for i in range(n) : \n",
        "      y = convBlock(x , filters_1 , filters_2 , filters_3)\n",
        "      x = Concatenate(axis = -1)([x , y])\n",
        "\n",
        "    return x \n",
        "\n",
        "\n",
        "  input_img = Input((224,224,3))\n",
        "  x = ZeroPadding2D(padding = (3,3))(input_img)\n",
        "  x = Conv2D(64 , (7,7) , strides = (2,2))(x)\n",
        "  x = ZeroPadding2D(padding = (1,1))(input_img)\n",
        "  x = MaxPooling2D(pool_size=(3,3) , strides=(2,2) , padding = 'valid' , data_format=None)(x)\n",
        "\n",
        "  x = combineConvBlock(x , 3 , 64 , 64 , 256)\n",
        "  x = ZeroPadding2D(padding = (1,1))(x)\n",
        "  x = MaxPooling2D(pool_size=(3,3) , strides=(2,2) , padding = 'valid' , data_format=None)(x)\n",
        "\n",
        "  x = combineConvBlock(x , 4 , 128 , 128 , 512)\n",
        "  x = ZeroPadding2D(padding = (1,1))(x)\n",
        "  x = MaxPooling2D(pool_size=(3,3) , strides=(2,2) , padding = 'valid' , data_format=None)(x)\n",
        "\n",
        "  x = combineConvBlock(x , 6 , 256 , 256 , 1024)\n",
        "  x = ZeroPadding2D(padding = (1,1))(x)\n",
        "  x = MaxPooling2D(pool_size=(3,3) , strides=(2,2) , padding = 'valid' , data_format=None)(x)\n",
        "\n",
        "  x = combineConvBlock(x , 3 , 512 , 512 , 2048)\n",
        "  x = ZeroPadding2D(padding = (1,1))(x)\n",
        "  x = MaxPooling2D(pool_size=(3,3) , strides=(2,2) , padding = 'valid' , data_format=None)(x)\n",
        "\n",
        "  x = AveragePooling2D(pool_size=(7,7))(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(output_lables , activation = 'softmax')(x)\n",
        "\n",
        "\n",
        "  model = Model(input_img , x)\n",
        "  return model\n",
        "\n",
        "model = resNet50(10)\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 226, 226, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 112, 112, 3)  0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 112, 112, 64) 256         max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 112, 112, 64) 36928       conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 112, 112, 256 16640       conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 112, 112, 259 0           max_pooling2d_5[0][0]            \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 112, 112, 64) 16640       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 112, 112, 64) 36928       conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 112, 112, 256 16640       conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 112, 112, 515 0           concatenate[0][0]                \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 112, 112, 64) 33024       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 112, 112, 64) 36928       conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 112, 112, 256 16640       conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 112, 112, 771 0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 114, 114, 771 0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 56, 56, 771)  0           zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 56, 56, 128)  98816       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 56, 56, 128)  147584      conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 56, 56, 512)  66048       conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 56, 56, 1283) 0           max_pooling2d_6[0][0]            \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 56, 56, 128)  164352      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 56, 56, 128)  147584      conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 56, 56, 512)  66048       conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 56, 56, 1795) 0           concatenate_3[0][0]              \n",
            "                                                                 conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 56, 56, 128)  229888      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 56, 56, 128)  147584      conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 56, 56, 512)  66048       conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 56, 56, 2307) 0           concatenate_4[0][0]              \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 56, 56, 128)  295424      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 56, 56, 128)  147584      conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 56, 56, 512)  66048       conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 56, 56, 2819) 0           concatenate_5[0][0]              \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, 58, 58, 2819) 0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 28, 28, 2819) 0           zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 28, 28, 256)  721920      max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 28, 28, 256)  590080      conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 28, 28, 1024) 263168      conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 28, 28, 3843) 0           max_pooling2d_7[0][0]            \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 28, 28, 256)  984064      concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 28, 28, 256)  590080      conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 28, 28, 1024) 263168      conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 28, 28, 4867) 0           concatenate_7[0][0]              \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 28, 28, 256)  1246208     concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 28, 28, 256)  590080      conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 28, 28, 1024) 263168      conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 28, 28, 5891) 0           concatenate_8[0][0]              \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 28, 28, 256)  1508352     concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 28, 28, 256)  590080      conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 28, 28, 1024) 263168      conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 28, 28, 6915) 0           concatenate_9[0][0]              \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 28, 28, 256)  1770496     concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 28, 28, 256)  590080      conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 28, 28, 1024) 263168      conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 28, 28, 7939) 0           concatenate_10[0][0]             \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 28, 28, 256)  2032640     concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 28, 28, 256)  590080      conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 28, 28, 1024) 263168      conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 28, 28, 8963) 0           concatenate_11[0][0]             \n",
            "                                                                 conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 30, 30, 8963) 0           concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 14, 14, 8963) 0           zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 14, 14, 512)  4589568     max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 14, 14, 512)  2359808     conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 14, 14, 2048) 1050624     conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 14, 14, 11011 0           max_pooling2d_8[0][0]            \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 14, 14, 512)  5638144     concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 14, 14, 512)  2359808     conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 14, 14, 2048) 1050624     conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 14, 14, 13059 0           concatenate_13[0][0]             \n",
            "                                                                 conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 14, 14, 512)  6686720     concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 14, 14, 512)  2359808     conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 14, 14, 2048) 1050624     conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 14, 14, 15107 0           concatenate_14[0][0]             \n",
            "                                                                 conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, 16, 16, 15107 0           concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 7, 7, 15107)  0           zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 15107)  0           max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 15107)        0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 10)           151080      flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 42,533,608\n",
            "Trainable params: 42,533,608\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7f-xGwP9Nno"
      },
      "source": [
        "## ResNet34"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8w3ORcz6TAP",
        "outputId": "788e8a75-332d-4bba-8dea-8e52aedd9d74"
      },
      "source": [
        "def resNet34(output_lables) : \n",
        "\n",
        "  def convBlock(x , filters_1 , filters_2  ) : \n",
        "    x = Conv2D( filters_1 , (3,3) , padding = 'same' , activation = 'relu' )(x)\n",
        "    x = Conv2D( filters_2 , (3,3) , padding = 'same' , activation = 'relu' )(x)\n",
        "    return x \n",
        "\n",
        "  def combineConvBlock(x , n , filters_1 , filters_2 ) :\n",
        "    for i in range(n) : \n",
        "      y = convBlock(x , filters_1 , filters_2 )\n",
        "      x = Concatenate(axis = -1)([x , y])\n",
        "\n",
        "    return x \n",
        "\n",
        "\n",
        "  input_img = Input((224,224,3))\n",
        "  x = ZeroPadding2D(padding = (3,3))(input_img)\n",
        "  x = Conv2D(64 , (7,7) , strides = (2,2))(x)\n",
        "  x = ZeroPadding2D(padding = (1,1))(input_img)\n",
        "  x = MaxPooling2D(pool_size=(3,3) , strides=(2,2) , padding = 'valid' , data_format=None)(x)\n",
        "\n",
        "  x = combineConvBlock(x , 3 , 64 , 64 )\n",
        "  x = ZeroPadding2D(padding = (1,1))(x)\n",
        "  x = MaxPooling2D(pool_size=(3,3) , strides=(2,2) , padding = 'valid' , data_format=None)(x)\n",
        "\n",
        "  x = combineConvBlock(x , 4 , 128 , 128 )\n",
        "  x = ZeroPadding2D(padding = (1,1))(x)\n",
        "  x = MaxPooling2D(pool_size=(3,3) , strides=(2,2) , padding = 'valid' , data_format=None)(x)\n",
        "\n",
        "  x = combineConvBlock(x , 6 , 256 , 256 )\n",
        "  x = ZeroPadding2D(padding = (1,1))(x)\n",
        "  x = MaxPooling2D(pool_size=(3,3) , strides=(2,2) , padding = 'valid' , data_format=None)(x)\n",
        "\n",
        "  x = combineConvBlock(x , 3 , 512 , 512 )\n",
        "  x = ZeroPadding2D(padding = (1,1))(x)\n",
        "  x = MaxPooling2D(pool_size=(3,3) , strides=(2,2) , padding = 'valid' , data_format=None)(x)\n",
        "\n",
        "  x = AveragePooling2D(pool_size=(7,7))(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(output_lables , activation = 'softmax')(x)\n",
        "\n",
        "\n",
        "  model = Model(input_img , x)\n",
        "  return model\n",
        "\n",
        "model = resNet34(10)\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_7 (ZeroPadding2D (None, 226, 226, 3)  0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 112, 112, 3)  0           zero_padding2d_7[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 112, 112, 64) 1792        max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 112, 112, 64) 36928       conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 112, 112, 67) 0           max_pooling2d_10[0][0]           \n",
            "                                                                 conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 112, 112, 64) 38656       concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 112, 112, 64) 36928       conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 112, 112, 131 0           concatenate_16[0][0]             \n",
            "                                                                 conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 112, 112, 64) 75520       concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 112, 112, 64) 36928       conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 112, 112, 195 0           concatenate_17[0][0]             \n",
            "                                                                 conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_8 (ZeroPadding2D (None, 114, 114, 195 0           concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 56, 56, 195)  0           zero_padding2d_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 56, 56, 128)  224768      max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 56, 56, 128)  147584      conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 56, 56, 323)  0           max_pooling2d_11[0][0]           \n",
            "                                                                 conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 56, 56, 128)  372224      concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 56, 56, 128)  147584      conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 56, 56, 451)  0           concatenate_19[0][0]             \n",
            "                                                                 conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 56, 56, 128)  519680      concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 56, 56, 128)  147584      conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 56, 56, 579)  0           concatenate_20[0][0]             \n",
            "                                                                 conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 56, 56, 128)  667136      concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 56, 56, 128)  147584      conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 56, 56, 707)  0           concatenate_21[0][0]             \n",
            "                                                                 conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_9 (ZeroPadding2D (None, 58, 58, 707)  0           concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 28, 28, 707)  0           zero_padding2d_9[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 28, 28, 256)  1629184     max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 28, 28, 256)  590080      conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 28, 28, 963)  0           max_pooling2d_12[0][0]           \n",
            "                                                                 conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 28, 28, 256)  2219008     concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 28, 28, 256)  590080      conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 28, 28, 1219) 0           concatenate_23[0][0]             \n",
            "                                                                 conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 28, 28, 256)  2808832     concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 28, 28, 256)  590080      conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 28, 28, 1475) 0           concatenate_24[0][0]             \n",
            "                                                                 conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 28, 28, 256)  3398656     concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 28, 28, 256)  590080      conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 28, 28, 1731) 0           concatenate_25[0][0]             \n",
            "                                                                 conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 28, 28, 256)  3988480     concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 28, 28, 256)  590080      conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 28, 28, 1987) 0           concatenate_26[0][0]             \n",
            "                                                                 conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 28, 28, 256)  4578304     concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 28, 28, 256)  590080      conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 28, 28, 2243) 0           concatenate_27[0][0]             \n",
            "                                                                 conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_10 (ZeroPadding2 (None, 30, 30, 2243) 0           concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 14, 14, 2243) 0           zero_padding2d_10[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 14, 14, 512)  10336256    max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 14, 14, 512)  2359808     conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 14, 14, 2755) 0           max_pooling2d_13[0][0]           \n",
            "                                                                 conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 14, 14, 512)  12695552    concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 14, 14, 512)  2359808     conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 14, 14, 3267) 0           concatenate_29[0][0]             \n",
            "                                                                 conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 14, 14, 512)  15054848    concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 14, 14, 512)  2359808     conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 14, 14, 3779) 0           concatenate_30[0][0]             \n",
            "                                                                 conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_11 (ZeroPadding2 (None, 16, 16, 3779) 0           concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 7, 7, 3779)   0           zero_padding2d_11[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 3779)   0           max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 3779)         0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10)           37800       flatten_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 69,967,720\n",
            "Trainable params: 69,967,720\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4awhb8q0jluX"
      },
      "source": [
        "## VGG - CIFAR 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPQcSj7v_DE7",
        "outputId": "695de74c-38b6-48e6-a20a-7d4ed0e5f67a"
      },
      "source": [
        "def small_vgg(num_classes):\n",
        "        # Build the network of vgg for 10 classes with massive dropout and weight decay as described in the paper.\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                         input_shape= (32 , 32 , 3)))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.3))\n",
        "\n",
        "        model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Dropout(0.4))\n",
        "\n",
        "        model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(Dropout(0.5))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(512))\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(BatchNormalization())\n",
        "\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(Dense(num_classes))\n",
        "        model.add(Activation('softmax'))\n",
        "        return model\n",
        "\n",
        "### For 10 labels class\n",
        "model = small_vgg(10)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_229 (Conv2D)          (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "activation_57 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_221 (Bat (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_230 (Conv2D)          (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_58 (Activation)   (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_222 (Bat (None, 32, 32, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_231 (Conv2D)          (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_59 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_223 (Bat (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_232 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_60 (Activation)   (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_224 (Bat (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_233 (Conv2D)          (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "activation_61 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_225 (Bat (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_234 (Conv2D)          (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "activation_62 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_226 (Bat (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_235 (Conv2D)          (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "activation_63 (Activation)   (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_227 (Bat (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_236 (Conv2D)          (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "activation_64 (Activation)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_228 (Bat (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_237 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_65 (Activation)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_229 (Bat (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_238 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_66 (Activation)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_230 (Bat (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_239 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_67 (Activation)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_231 (Bat (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_240 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_68 (Activation)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_232 (Bat (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_241 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_69 (Activation)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_233 (Bat (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_70 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_234 (Bat (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_71 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 15,001,418\n",
            "Trainable params: 14,991,946\n",
            "Non-trainable params: 9,472\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMvxgF8jmI4A"
      },
      "source": [
        "## GoogleNet - CIFAR 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN9KqQjnqVfe",
        "outputId": "dc600ee1-efed-42c4-8544-9ed574096772"
      },
      "source": [
        "def small_googlenet(output_label_cnt):\n",
        "    \n",
        "    input_img = Input(shape = (32, 32, 3))\n",
        "\n",
        "    tower_1 = Conv2D(64, (1,1), padding='same', activation='relu')(input_img)\n",
        "    tower_1 = Conv2D(64, (3,3), padding='same', activation='relu')(tower_1)\n",
        "\n",
        "    tower_2 = Conv2D(64, (1,1), padding='same', activation='relu')(input_img)\n",
        "    tower_2 = Conv2D(64, (5,5), padding='same', activation='relu')(tower_2)\n",
        "\n",
        "    tower_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img)\n",
        "    tower_3 = Conv2D(64, (1,1), padding='same', activation='relu')(tower_3)\n",
        "\n",
        "    output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis = 3)\n",
        "    \n",
        "    output = Flatten()(output)\n",
        "    out    = Dense( output_label_cnt, activation='softmax')(output)\n",
        "\n",
        "    model = Model(inputs = input_img, outputs = out)\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "small_googlenet(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 32, 32, 64)   256         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 32, 32, 64)   256         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 32, 32, 3)    0           input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 32, 32, 64)   36928       conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 32, 32, 64)   102464      conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 32, 32, 64)   256         max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 192)  0           conv2d_116[0][0]                 \n",
            "                                                                 conv2d_118[0][0]                 \n",
            "                                                                 conv2d_119[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 196608)       0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 10)           1966090     flatten_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,106,250\n",
            "Trainable params: 2,106,250\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.functional.Functional at 0x7f87a91e6a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMtL6w5nLCQa"
      },
      "source": [
        "## Resnet - 34 - CIFAR 10 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T16D8JoGLGJV",
        "outputId": "471bfdbf-40c2-4d8b-ef54-c4a81f7d4b3d"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, Add, Dense\n",
        "from tensorflow.keras.layers import AveragePooling2D, Flatten\n",
        "\n",
        "def stem(inputs):\n",
        "    ''' Construct the Stem Convolutional Group \n",
        "        inputs : the input vector\n",
        "    '''\n",
        "    x = Conv2D(16, (3, 3), strides=(1, 1), padding='same', kernel_initializer='he_normal')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "    \n",
        "def learner(x, n_blocks):\n",
        "    \"\"\" Construct the Learner\n",
        "        x          : input to the learner\n",
        "        n_blocks   : number of blocks in a group\n",
        "    \"\"\"\n",
        "    # First Residual Block Group of 16 filters (Stage 1)\n",
        "    # Quadruple (4X) the size of filters to fit the next Residual Group\n",
        "    x = residual_group(x, 16, n_blocks, strides=(1, 1), n=4)\n",
        "\n",
        "    # Second Residual Block Group of 64 filters (Stage 2)\n",
        "    # Double (2X) the size of filters and reduce feature maps by 75% (strides=2) to fit the next Residual Group\n",
        "    x = residual_group(x, 64, n_blocks, n=2)\n",
        "\n",
        "    # Third Residual Block Group of 64 filters (Stage 3)\n",
        "    # Double (2X) the size of filters and reduce feature maps by 75% (strides=2) to fit the next Residual Group\n",
        "    x = residual_group(x, 128, n_blocks, n=2)\n",
        "    return x\n",
        "\n",
        "def residual_group(x, n_filters, n_blocks, strides=(2, 2), n=2):\n",
        "    \"\"\" Construct a Residual Group\n",
        "        x         : input into the group\n",
        "        n_filters : number of filters for the group\n",
        "        n_blocks  : number of residual blocks with identity link\n",
        "        strides   : whether the projection block is a strided convolution\n",
        "        n         : multiplier for the number of filters out\n",
        "    \"\"\"\n",
        "    # Double the size of filters to fit the first Residual Group\n",
        "    x = projection_block(x, n_filters, strides=strides, n=n)\n",
        "\n",
        "    # Identity residual blocks\n",
        "    for _ in range(n_blocks):\n",
        "        x = identity_block(x, n_filters, n)\n",
        "    return x\n",
        "    \n",
        "def identity_block(x, n_filters, n=2):\n",
        "    \"\"\" Construct a Bottleneck Residual Block of Convolutions with Identity Shortcut\n",
        "        x        : input into the block\n",
        "        n_filters: number of filters\n",
        "        n        : multiplier for filters out\n",
        "    \"\"\"\n",
        "    # Save input vector (feature maps) for the identity link\n",
        "    shortcut = x\n",
        "    \n",
        "    ## Construct the 1x1, 3x3, 1x1 residual block (fig 3c)\n",
        "\n",
        "    # Dimensionality reduction\n",
        "    x = Conv2D(n_filters, (1, 1), strides=(1, 1), kernel_initializer='he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Bottleneck layer\n",
        "    x = Conv2D(n_filters, (3, 3), strides=(1, 1), padding=\"same\", kernel_initializer='he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    # Dimensionality restoration - increase the number of output filters by 2X or 4X\n",
        "    x = Conv2D(n_filters * n, (1, 1), strides=(1, 1), kernel_initializer='he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Add the identity link (input) to the output of the residual block\n",
        "    x = Add()([x, shortcut])\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "\n",
        "def projection_block(x, n_filters, strides=(2,2), n=2):\n",
        "    \"\"\" Construct Bottleneck Residual Block with Projection Shortcut\n",
        "        Increase the number of filters by 2X (or 4X on first stage)\n",
        "        x        : input into the block\n",
        "        n_filters: number of filters\n",
        "        strides  : whether the first convolution is strided\n",
        "        n        : multiplier for number of filters out\n",
        "    \"\"\"\n",
        "    # Construct the projection shortcut\n",
        "    # Increase filters by 2X (or 4X) to match shape when added to output of block\n",
        "    shortcut = Conv2D(n_filters * n, (1, 1), strides=strides, kernel_initializer='he_normal')(x)\n",
        "\n",
        "    ## Construct the 1x1, 3x3, 1x1 convolution block\n",
        "\n",
        "    # Dimensionality reduction\n",
        "    x = Conv2D(n_filters, (1, 1), strides=(1,1), kernel_initializer='he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    \n",
        "    # Bottleneck layer - feature pooling when strides=(2, 2)\n",
        "    x = Conv2D(n_filters, (3, 3), strides=strides, padding='same', kernel_initializer='he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)  \n",
        "    \n",
        "    # Dimensionality restoration - increase the number of filters by 2X (or 4X)\n",
        "    x = Conv2D(n_filters * n, (1, 1), strides=(1, 1), kernel_initializer='he_normal')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Add the projection shortcut to the output of the residual block\n",
        "    x = Add()([shortcut, x])\n",
        "    x = ReLU()(x)\n",
        "    return x\n",
        "    \n",
        "def classifier(x, n_classes):\n",
        "    ''' Construct the Classifier\n",
        "        x         : input into the classifier\n",
        "        n_classes : number of classes\n",
        "    '''\n",
        "    # Pool the feature maps after the end of all the residual blocks\n",
        "    x = BatchNormalization()(x)\n",
        "    x = ReLU()(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    \n",
        "    # Flatten into 1D vector\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Final Dense Outputting Layer \n",
        "    outputs = Dense(n_classes, activation='softmax', kernel_initializer='he_normal')(x)\n",
        "    return outputs\n",
        "\n",
        "#-------------------\n",
        "# Model      | n   |\n",
        "# ResNet20   | 2   |\n",
        "# ResNet56   | 6   |\n",
        "# ResNet110  | 12  |\n",
        "# ResNet164  | 18  |\n",
        "# ResNet1001 | 111 |\n",
        "#\n",
        "n = 18\n",
        "depth =  n * 9 + 2\n",
        "n_blocks = ((depth - 2) // 9) - 1\n",
        "\n",
        "# The input tensor\n",
        "inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "# The Stem Convolution Group\n",
        "x = stem(inputs)\n",
        "   \n",
        "# The learner\n",
        "x = learner(x, n_blocks)\n",
        "\n",
        "# The Classifier for 10 classes\n",
        "outputs = classifier(x, 10)\n",
        "\n",
        "# Instantiate the Model\n",
        "resnet = Model(inputs, outputs)\n",
        "resnet.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 32, 32, 16)   448         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 32, 32, 16)   64          conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu (ReLU)                    (None, 32, 32, 16)   0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 32, 32, 16)   272         re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 32, 32, 16)   64          conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 32, 32, 16)   0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 32, 32, 16)   2320        re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 32, 32, 16)   64          conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 32, 32, 16)   0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 32, 32, 64)   1088        re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 32, 32, 64)   1088        re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 32, 32, 64)   256         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 32, 32, 64)   0           conv2d_64[0][0]                  \n",
            "                                                                 batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, 32, 32, 64)   0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 32, 32, 16)   1040        re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 32, 32, 16)   64          conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, 32, 32, 16)   0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 32, 32, 16)   2320        re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 32, 32, 16)   64          conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, 32, 32, 16)   0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 32, 32, 64)   1088        re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 32, 32, 64)   256         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 32, 32, 64)   0           batch_normalization_63[0][0]     \n",
            "                                                                 re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_6 (ReLU)                  (None, 32, 32, 64)   0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 32, 32, 16)   1040        re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 32, 32, 16)   64          conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_7 (ReLU)                  (None, 32, 32, 16)   0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 32, 32, 16)   2320        re_lu_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 32, 32, 16)   64          conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_8 (ReLU)                  (None, 32, 32, 16)   0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 32, 32, 64)   1088        re_lu_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 32, 32, 64)   256         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 32, 32, 64)   0           batch_normalization_66[0][0]     \n",
            "                                                                 re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_9 (ReLU)                  (None, 32, 32, 64)   0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 32, 32, 16)   1040        re_lu_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 32, 32, 16)   64          conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_10 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 32, 32, 16)   2320        re_lu_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 32, 32, 16)   64          conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_11 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 32, 32, 64)   1088        re_lu_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 32, 32, 64)   256         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 32, 32, 64)   0           batch_normalization_69[0][0]     \n",
            "                                                                 re_lu_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_12 (ReLU)                 (None, 32, 32, 64)   0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 32, 32, 16)   1040        re_lu_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 32, 32, 16)   64          conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_13 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 32, 32, 16)   2320        re_lu_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 32, 32, 16)   64          conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_14 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 32, 32, 64)   1088        re_lu_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 32, 32, 64)   256         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 32, 32, 64)   0           batch_normalization_72[0][0]     \n",
            "                                                                 re_lu_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_15 (ReLU)                 (None, 32, 32, 64)   0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 32, 32, 16)   1040        re_lu_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 32, 32, 16)   64          conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_16 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 32, 32, 16)   2320        re_lu_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 32, 32, 16)   64          conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_17 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 32, 32, 64)   1088        re_lu_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 32, 32, 64)   256         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 32, 32, 64)   0           batch_normalization_75[0][0]     \n",
            "                                                                 re_lu_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_18 (ReLU)                 (None, 32, 32, 64)   0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 32, 32, 16)   1040        re_lu_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 32, 32, 16)   64          conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_19 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 32, 32, 16)   2320        re_lu_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 32, 32, 16)   64          conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_20 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 32, 32, 64)   1088        re_lu_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 32, 32, 64)   256         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 32, 32, 64)   0           batch_normalization_78[0][0]     \n",
            "                                                                 re_lu_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_21 (ReLU)                 (None, 32, 32, 64)   0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 32, 32, 16)   1040        re_lu_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 32, 32, 16)   64          conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_22 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 32, 32, 16)   2320        re_lu_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 32, 32, 16)   64          conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_23 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 32, 32, 64)   1088        re_lu_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 32, 32, 64)   256         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 32, 32, 64)   0           batch_normalization_81[0][0]     \n",
            "                                                                 re_lu_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_24 (ReLU)                 (None, 32, 32, 64)   0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 32, 32, 16)   1040        re_lu_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 32, 32, 16)   64          conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_25 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 32, 32, 16)   2320        re_lu_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 32, 32, 16)   64          conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_26 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 32, 32, 64)   1088        re_lu_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 32, 32, 64)   256         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 32, 32, 64)   0           batch_normalization_84[0][0]     \n",
            "                                                                 re_lu_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_27 (ReLU)                 (None, 32, 32, 64)   0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 32, 32, 16)   1040        re_lu_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 32, 32, 16)   64          conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_28 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 32, 32, 16)   2320        re_lu_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 32, 32, 16)   64          conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_29 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 32, 32, 64)   1088        re_lu_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 32, 32, 64)   256         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 32, 32, 64)   0           batch_normalization_87[0][0]     \n",
            "                                                                 re_lu_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_30 (ReLU)                 (None, 32, 32, 64)   0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 32, 32, 16)   1040        re_lu_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 32, 32, 16)   64          conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_31 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 32, 32, 16)   2320        re_lu_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 32, 32, 16)   64          conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_32 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 32, 32, 64)   1088        re_lu_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 32, 32, 64)   256         conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 32, 32, 64)   0           batch_normalization_90[0][0]     \n",
            "                                                                 re_lu_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_33 (ReLU)                 (None, 32, 32, 64)   0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 32, 32, 16)   1040        re_lu_33[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 32, 32, 16)   64          conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_34 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 32, 32, 16)   2320        re_lu_34[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 32, 32, 16)   64          conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_35 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 32, 32, 64)   256         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 32, 32, 64)   0           batch_normalization_93[0][0]     \n",
            "                                                                 re_lu_33[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_36 (ReLU)                 (None, 32, 32, 64)   0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 32, 32, 16)   1040        re_lu_36[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 32, 32, 16)   64          conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_37 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 32, 32, 16)   2320        re_lu_37[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 32, 32, 16)   64          conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_38 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 32, 32, 64)   256         conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 32, 32, 64)   0           batch_normalization_96[0][0]     \n",
            "                                                                 re_lu_36[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_39 (ReLU)                 (None, 32, 32, 64)   0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 32, 32, 16)   1040        re_lu_39[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 32, 32, 16)   64          conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_40 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 32, 32, 16)   2320        re_lu_40[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 32, 32, 16)   64          conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_41 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 32, 32, 64)   256         conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 32, 32, 64)   0           batch_normalization_99[0][0]     \n",
            "                                                                 re_lu_39[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_42 (ReLU)                 (None, 32, 32, 64)   0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 32, 32, 16)   1040        re_lu_42[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 32, 32, 16)   64          conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_43 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 32, 32, 16)   2320        re_lu_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 32, 32, 16)   64          conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_44 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_109 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 32, 32, 64)   256         conv2d_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 32, 32, 64)   0           batch_normalization_102[0][0]    \n",
            "                                                                 re_lu_42[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_45 (ReLU)                 (None, 32, 32, 64)   0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_110 (Conv2D)             (None, 32, 32, 16)   1040        re_lu_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 32, 32, 16)   64          conv2d_110[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_46 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_111 (Conv2D)             (None, 32, 32, 16)   2320        re_lu_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 32, 32, 16)   64          conv2d_111[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_47 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_112 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 32, 32, 64)   256         conv2d_112[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 32, 32, 64)   0           batch_normalization_105[0][0]    \n",
            "                                                                 re_lu_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_48 (ReLU)                 (None, 32, 32, 64)   0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_113 (Conv2D)             (None, 32, 32, 16)   1040        re_lu_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 32, 32, 16)   64          conv2d_113[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_49 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_114 (Conv2D)             (None, 32, 32, 16)   2320        re_lu_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 32, 32, 16)   64          conv2d_114[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_50 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_115 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 32, 32, 64)   256         conv2d_115[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 32, 32, 64)   0           batch_normalization_108[0][0]    \n",
            "                                                                 re_lu_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_51 (ReLU)                 (None, 32, 32, 64)   0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_116 (Conv2D)             (None, 32, 32, 16)   1040        re_lu_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 32, 32, 16)   64          conv2d_116[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_52 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_117 (Conv2D)             (None, 32, 32, 16)   2320        re_lu_52[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 32, 32, 16)   64          conv2d_117[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_53 (ReLU)                 (None, 32, 32, 16)   0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_118 (Conv2D)             (None, 32, 32, 64)   1088        re_lu_53[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 32, 32, 64)   256         conv2d_118[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 32, 32, 64)   0           batch_normalization_111[0][0]    \n",
            "                                                                 re_lu_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_54 (ReLU)                 (None, 32, 32, 64)   0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_120 (Conv2D)             (None, 32, 32, 64)   4160        re_lu_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 32, 32, 64)   256         conv2d_120[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_55 (ReLU)                 (None, 32, 32, 64)   0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_121 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_55[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 16, 16, 64)   256         conv2d_121[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_56 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_122 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_56[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_119 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 16, 16, 128)  512         conv2d_122[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 16, 16, 128)  0           conv2d_119[0][0]                 \n",
            "                                                                 batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_57 (ReLU)                 (None, 16, 16, 128)  0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_123 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_57[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 16, 16, 64)   256         conv2d_123[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_58 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_124 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_58[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 16, 16, 64)   256         conv2d_124[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_59 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_125 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_59[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 16, 16, 128)  512         conv2d_125[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 16, 16, 128)  0           batch_normalization_117[0][0]    \n",
            "                                                                 re_lu_57[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_60 (ReLU)                 (None, 16, 16, 128)  0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_126 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_60[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 16, 16, 64)   256         conv2d_126[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_61 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_127 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_61[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 16, 16, 64)   256         conv2d_127[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_62 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_128 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_62[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 16, 16, 128)  512         conv2d_128[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 16, 16, 128)  0           batch_normalization_120[0][0]    \n",
            "                                                                 re_lu_60[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_63 (ReLU)                 (None, 16, 16, 128)  0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_129 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_63[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 16, 16, 64)   256         conv2d_129[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_64 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_130 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_64[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 16, 16, 64)   256         conv2d_130[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_65 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_131 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_65[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 16, 16, 128)  512         conv2d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_48 (Add)                    (None, 16, 16, 128)  0           batch_normalization_123[0][0]    \n",
            "                                                                 re_lu_63[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_66 (ReLU)                 (None, 16, 16, 128)  0           add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_132 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_66[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 16, 16, 64)   256         conv2d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_67 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_133 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_67[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 16, 16, 64)   256         conv2d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_68 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_134 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_68[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 16, 16, 128)  512         conv2d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 16, 16, 128)  0           batch_normalization_126[0][0]    \n",
            "                                                                 re_lu_66[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_69 (ReLU)                 (None, 16, 16, 128)  0           add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_135 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_69[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 16, 16, 64)   256         conv2d_135[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_70 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_136 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_70[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 16, 16, 64)   256         conv2d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_71 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_137 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_71[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 16, 16, 128)  512         conv2d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 16, 16, 128)  0           batch_normalization_129[0][0]    \n",
            "                                                                 re_lu_69[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_72 (ReLU)                 (None, 16, 16, 128)  0           add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_138 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_72[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 16, 16, 64)   256         conv2d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_73 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_139 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_73[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 16, 16, 64)   256         conv2d_139[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_74 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_140 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_74[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 16, 16, 128)  512         conv2d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 16, 16, 128)  0           batch_normalization_132[0][0]    \n",
            "                                                                 re_lu_72[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_75 (ReLU)                 (None, 16, 16, 128)  0           add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_141 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_75[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 16, 16, 64)   256         conv2d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_76 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_142 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_76[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 16, 16, 64)   256         conv2d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_77 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_143 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_77[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 16, 16, 128)  512         conv2d_143[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 16, 16, 128)  0           batch_normalization_135[0][0]    \n",
            "                                                                 re_lu_75[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_78 (ReLU)                 (None, 16, 16, 128)  0           add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_144 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_78[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 16, 16, 64)   256         conv2d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_79 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_145 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_79[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 16, 16, 64)   256         conv2d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_80 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_146 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_80[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 16, 16, 128)  512         conv2d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 16, 16, 128)  0           batch_normalization_138[0][0]    \n",
            "                                                                 re_lu_78[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_81 (ReLU)                 (None, 16, 16, 128)  0           add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_147 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_81[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 16, 16, 64)   256         conv2d_147[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_82 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_148 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_82[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 16, 16, 64)   256         conv2d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_83 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_149 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_83[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 16, 16, 128)  512         conv2d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 16, 16, 128)  0           batch_normalization_141[0][0]    \n",
            "                                                                 re_lu_81[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_84 (ReLU)                 (None, 16, 16, 128)  0           add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_150 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_84[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 16, 16, 64)   256         conv2d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_85 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_151 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_85[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 16, 16, 64)   256         conv2d_151[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_86 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_86[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 16, 16, 128)  512         conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_55 (Add)                    (None, 16, 16, 128)  0           batch_normalization_144[0][0]    \n",
            "                                                                 re_lu_84[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_87 (ReLU)                 (None, 16, 16, 128)  0           add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_87[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 16, 16, 64)   256         conv2d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_88 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_88[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 16, 16, 64)   256         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_89 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_89[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 16, 16, 128)  512         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_56 (Add)                    (None, 16, 16, 128)  0           batch_normalization_147[0][0]    \n",
            "                                                                 re_lu_87[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_90 (ReLU)                 (None, 16, 16, 128)  0           add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_90[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 16, 16, 64)   256         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_91 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_91[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 16, 16, 64)   256         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_92 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_92[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 16, 16, 128)  512         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_57 (Add)                    (None, 16, 16, 128)  0           batch_normalization_150[0][0]    \n",
            "                                                                 re_lu_90[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_93 (ReLU)                 (None, 16, 16, 128)  0           add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_93[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 16, 16, 64)   256         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_94 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_94[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 16, 16, 64)   256         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_95 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_95[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 16, 16, 128)  512         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_58 (Add)                    (None, 16, 16, 128)  0           batch_normalization_153[0][0]    \n",
            "                                                                 re_lu_93[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_96 (ReLU)                 (None, 16, 16, 128)  0           add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_96[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 16, 16, 64)   256         conv2d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_97 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_97[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 16, 16, 64)   256         conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_98 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_98[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 16, 16, 128)  512         conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_59 (Add)                    (None, 16, 16, 128)  0           batch_normalization_156[0][0]    \n",
            "                                                                 re_lu_96[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_99 (ReLU)                 (None, 16, 16, 128)  0           add_59[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_99[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 16, 16, 64)   256         conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_100 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_100[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 16, 16, 64)   256         conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_101 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_101[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 16, 16, 128)  512         conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_60 (Add)                    (None, 16, 16, 128)  0           batch_normalization_159[0][0]    \n",
            "                                                                 re_lu_99[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_102 (ReLU)                (None, 16, 16, 128)  0           add_60[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_102[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 16, 16, 64)   256         conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_103 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_103[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_161 (BatchN (None, 16, 16, 64)   256         conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_104 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_161[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_104[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_162 (BatchN (None, 16, 16, 128)  512         conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_61 (Add)                    (None, 16, 16, 128)  0           batch_normalization_162[0][0]    \n",
            "                                                                 re_lu_102[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_105 (ReLU)                (None, 16, 16, 128)  0           add_61[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 16, 16, 64)   8256        re_lu_105[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_163 (BatchN (None, 16, 16, 64)   256         conv2d_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_106 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_163[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 16, 16, 64)   36928       re_lu_106[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_164 (BatchN (None, 16, 16, 64)   256         conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_107 (ReLU)                (None, 16, 16, 64)   0           batch_normalization_164[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 16, 16, 128)  8320        re_lu_107[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_165 (BatchN (None, 16, 16, 128)  512         conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_62 (Add)                    (None, 16, 16, 128)  0           batch_normalization_165[0][0]    \n",
            "                                                                 re_lu_105[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_108 (ReLU)                (None, 16, 16, 128)  0           add_62[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 16, 16, 128)  16512       re_lu_108[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_166 (BatchN (None, 16, 16, 128)  512         conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_109 (ReLU)                (None, 16, 16, 128)  0           batch_normalization_166[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_109[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_167 (BatchN (None, 8, 8, 128)    512         conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_110 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_167[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_110[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_108[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_168 (BatchN (None, 8, 8, 256)    1024        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_63 (Add)                    (None, 8, 8, 256)    0           conv2d_174[0][0]                 \n",
            "                                                                 batch_normalization_168[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_111 (ReLU)                (None, 8, 8, 256)    0           add_63[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_111[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_169 (BatchN (None, 8, 8, 128)    512         conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_112 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_169[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_112[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_170 (BatchN (None, 8, 8, 128)    512         conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_113 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_170[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_180 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_113[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_171 (BatchN (None, 8, 8, 256)    1024        conv2d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 8, 8, 256)    0           batch_normalization_171[0][0]    \n",
            "                                                                 re_lu_111[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_114 (ReLU)                (None, 8, 8, 256)    0           add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_181 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_114[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_172 (BatchN (None, 8, 8, 128)    512         conv2d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_115 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_172[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_182 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_115[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_173 (BatchN (None, 8, 8, 128)    512         conv2d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_116 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_173[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_183 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_116[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_174 (BatchN (None, 8, 8, 256)    1024        conv2d_183[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_65 (Add)                    (None, 8, 8, 256)    0           batch_normalization_174[0][0]    \n",
            "                                                                 re_lu_114[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_117 (ReLU)                (None, 8, 8, 256)    0           add_65[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_184 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_117[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_175 (BatchN (None, 8, 8, 128)    512         conv2d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_118 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_175[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_185 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_118[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_176 (BatchN (None, 8, 8, 128)    512         conv2d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_119 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_176[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_186 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_119[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_177 (BatchN (None, 8, 8, 256)    1024        conv2d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_66 (Add)                    (None, 8, 8, 256)    0           batch_normalization_177[0][0]    \n",
            "                                                                 re_lu_117[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_120 (ReLU)                (None, 8, 8, 256)    0           add_66[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_187 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_120[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_178 (BatchN (None, 8, 8, 128)    512         conv2d_187[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_121 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_178[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_188 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_121[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_179 (BatchN (None, 8, 8, 128)    512         conv2d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_122 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_179[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_189 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_122[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_180 (BatchN (None, 8, 8, 256)    1024        conv2d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_67 (Add)                    (None, 8, 8, 256)    0           batch_normalization_180[0][0]    \n",
            "                                                                 re_lu_120[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_123 (ReLU)                (None, 8, 8, 256)    0           add_67[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_190 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_123[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_181 (BatchN (None, 8, 8, 128)    512         conv2d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_124 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_181[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_191 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_124[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_182 (BatchN (None, 8, 8, 128)    512         conv2d_191[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_125 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_182[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_192 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_125[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_183 (BatchN (None, 8, 8, 256)    1024        conv2d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_68 (Add)                    (None, 8, 8, 256)    0           batch_normalization_183[0][0]    \n",
            "                                                                 re_lu_123[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_126 (ReLU)                (None, 8, 8, 256)    0           add_68[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_193 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_126[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_184 (BatchN (None, 8, 8, 128)    512         conv2d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_127 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_184[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_194 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_127[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_185 (BatchN (None, 8, 8, 128)    512         conv2d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_128 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_185[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_195 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_128[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_186 (BatchN (None, 8, 8, 256)    1024        conv2d_195[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_69 (Add)                    (None, 8, 8, 256)    0           batch_normalization_186[0][0]    \n",
            "                                                                 re_lu_126[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_129 (ReLU)                (None, 8, 8, 256)    0           add_69[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_196 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_129[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_187 (BatchN (None, 8, 8, 128)    512         conv2d_196[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_130 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_187[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_197 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_130[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_188 (BatchN (None, 8, 8, 128)    512         conv2d_197[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_131 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_188[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_198 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_131[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_189 (BatchN (None, 8, 8, 256)    1024        conv2d_198[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_70 (Add)                    (None, 8, 8, 256)    0           batch_normalization_189[0][0]    \n",
            "                                                                 re_lu_129[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_132 (ReLU)                (None, 8, 8, 256)    0           add_70[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_199 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_132[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_190 (BatchN (None, 8, 8, 128)    512         conv2d_199[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_133 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_190[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_200 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_133[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_191 (BatchN (None, 8, 8, 128)    512         conv2d_200[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_134 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_191[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_201 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_134[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_192 (BatchN (None, 8, 8, 256)    1024        conv2d_201[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_71 (Add)                    (None, 8, 8, 256)    0           batch_normalization_192[0][0]    \n",
            "                                                                 re_lu_132[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_135 (ReLU)                (None, 8, 8, 256)    0           add_71[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_202 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_135[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_193 (BatchN (None, 8, 8, 128)    512         conv2d_202[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_136 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_193[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_203 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_136[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_194 (BatchN (None, 8, 8, 128)    512         conv2d_203[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_137 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_194[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_137[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_195 (BatchN (None, 8, 8, 256)    1024        conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_72 (Add)                    (None, 8, 8, 256)    0           batch_normalization_195[0][0]    \n",
            "                                                                 re_lu_135[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_138 (ReLU)                (None, 8, 8, 256)    0           add_72[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_138[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_196 (BatchN (None, 8, 8, 128)    512         conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_139 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_196[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_139[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_197 (BatchN (None, 8, 8, 128)    512         conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_140 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_197[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_140[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_198 (BatchN (None, 8, 8, 256)    1024        conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_73 (Add)                    (None, 8, 8, 256)    0           batch_normalization_198[0][0]    \n",
            "                                                                 re_lu_138[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_141 (ReLU)                (None, 8, 8, 256)    0           add_73[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_141[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_199 (BatchN (None, 8, 8, 128)    512         conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_142 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_199[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_142[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_200 (BatchN (None, 8, 8, 128)    512         conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_143 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_200[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_143[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_201 (BatchN (None, 8, 8, 256)    1024        conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_74 (Add)                    (None, 8, 8, 256)    0           batch_normalization_201[0][0]    \n",
            "                                                                 re_lu_141[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_144 (ReLU)                (None, 8, 8, 256)    0           add_74[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_144[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_202 (BatchN (None, 8, 8, 128)    512         conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_145 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_202[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_145[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_203 (BatchN (None, 8, 8, 128)    512         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_146 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_203[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_146[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, 8, 8, 256)    1024        conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_75 (Add)                    (None, 8, 8, 256)    0           batch_normalization_204[0][0]    \n",
            "                                                                 re_lu_144[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_147 (ReLU)                (None, 8, 8, 256)    0           add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_147[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, 8, 8, 128)    512         conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_148 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_148[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, 8, 8, 128)    512         conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_149 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_149[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, 8, 8, 256)    1024        conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_76 (Add)                    (None, 8, 8, 256)    0           batch_normalization_207[0][0]    \n",
            "                                                                 re_lu_147[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_150 (ReLU)                (None, 8, 8, 256)    0           add_76[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_150[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, 8, 8, 128)    512         conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_151 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_151[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, 8, 8, 128)    512         conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_152 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_152[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 8, 8, 256)    1024        conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_77 (Add)                    (None, 8, 8, 256)    0           batch_normalization_210[0][0]    \n",
            "                                                                 re_lu_150[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_153 (ReLU)                (None, 8, 8, 256)    0           add_77[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_153[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 8, 8, 128)    512         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_154 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_154[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 8, 8, 128)    512         conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_155 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_155[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 8, 8, 256)    1024        conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_78 (Add)                    (None, 8, 8, 256)    0           batch_normalization_213[0][0]    \n",
            "                                                                 re_lu_153[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_156 (ReLU)                (None, 8, 8, 256)    0           add_78[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_156[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 8, 8, 128)    512         conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_157 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_157[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 8, 8, 128)    512         conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_158 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_158[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 8, 8, 256)    1024        conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_79 (Add)                    (None, 8, 8, 256)    0           batch_normalization_216[0][0]    \n",
            "                                                                 re_lu_156[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_159 (ReLU)                (None, 8, 8, 256)    0           add_79[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 8, 8, 128)    32896       re_lu_159[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 8, 8, 128)    512         conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_160 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 8, 8, 128)    147584      re_lu_160[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 8, 8, 128)    512         conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_161 (ReLU)                (None, 8, 8, 128)    0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 8, 8, 256)    33024       re_lu_161[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 8, 8, 256)    1024        conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_80 (Add)                    (None, 8, 8, 256)    0           batch_normalization_219[0][0]    \n",
            "                                                                 re_lu_159[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_162 (ReLU)                (None, 8, 8, 256)    0           add_80[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 8, 8, 256)    1024        re_lu_162[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_163 (ReLU)                (None, 8, 8, 256)    0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 1, 1, 256)    0           re_lu_163[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 256)          0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           2570        flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 4,973,706\n",
            "Trainable params: 4,942,058\n",
            "Non-trainable params: 31,648\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WASyyb_fOd34"
      },
      "source": [
        "# Shortcut to SSL Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GT15kfytOlXR",
        "outputId": "69f1b0f2-a1d9-4b1c-ab73-cf2f6540a254"
      },
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "'''\n",
        "input_img = Input(shape = (32, 32, 3))\n",
        "\n",
        "vgg = tf.keras.applications.VGG16(weights = None, input_tensor = input_img , classes = 10 , include_top = False)\n",
        "for layer in vgg.layers :\n",
        "  layer.trainable = True\n",
        "x = Flatten()(vgg.output)\n",
        "x = Dense(512 , activation= 'relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "outputs = Dense(10 , activation = 'softmax')(x)\n",
        "vgg_model = Model(inputs = input_img , outputs = outputs)\n",
        "vgg_model.summary()\n",
        "'''\n",
        "\n",
        "'''\n",
        "input_img = Input(shape = (32, 32, 3))\n",
        "resnet = tf.keras.applications.ResNet101V2(weights = None, input_tensor = input_img , classes = 10 , include_top = False)\n",
        "for layer in resnet.layers :\n",
        "  layer.trainable = True\n",
        "x = Flatten()(resnet.output)\n",
        "x = Dense(512 , activation= 'relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "outputs = Dense(10 , activation = 'softmax')(x)\n",
        "resnet_model = Model(inputs = input_img , outputs = outputs)\n",
        "resnet_model.summary()\n",
        "'''\n",
        "\n",
        "'''\n",
        "input_img = Input(shape = (32, 32, 3))\n",
        "vgg_19 = tf.keras.applications.VGG19(weights = None , input_tensor = input_img , classes = 10 , include_top = False)\n",
        "for layer in vgg_19.layers :\n",
        "  layer.trainable = True\n",
        "x = Flatten()(vgg_19.output)\n",
        "x = Dense(1024 , activation= 'relu')(x)\n",
        "x = Dense(512 , activation= 'relu')(x)\n",
        "x = Dense(256 , activation= 'relu')(x)\n",
        "x = Dense(128 , activation= 'relu')(x)\n",
        "outputs = Dense(10 , activation = 'softmax')(x)\n",
        "\n",
        "vgg_model = Model(inputs = input_img , outputs = outputs)\n",
        "vgg_model.summary()\n",
        "'''\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "    \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "    \n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "   \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "    \n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 552,874\n",
            "Trainable params: 551,722\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orC98mD2A6ER"
      },
      "source": [
        "# Resnet 18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvLXtrtFA9rr",
        "outputId": "9a49db59-cad6-4005-c2e5-b0a94413588d"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class ResnetBlock(Model):\n",
        "    \"\"\"\n",
        "    A standard resnet block.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels: int, down_sample=False):\n",
        "        \"\"\"\n",
        "        channels: same as number of convolution kernels\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.__channels = channels\n",
        "        self.__down_sample = down_sample\n",
        "        self.__strides = [2, 1] if down_sample else [1, 1]\n",
        "\n",
        "        KERNEL_SIZE = (3, 3)\n",
        "        # use He initialization, instead of Xavier (a.k.a 'glorot_uniform' in Keras), as suggested in [2]\n",
        "        INIT_SCHEME = \"he_normal\"\n",
        "\n",
        "        self.conv_1 = Conv2D(self.__channels, strides=self.__strides[0],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_1 = BatchNormalization()\n",
        "        self.conv_2 = Conv2D(self.__channels, strides=self.__strides[1],\n",
        "                             kernel_size=KERNEL_SIZE, padding=\"same\", kernel_initializer=INIT_SCHEME)\n",
        "        self.bn_2 = BatchNormalization()\n",
        "        self.merge = Add()\n",
        "\n",
        "        if self.__down_sample:\n",
        "            # perform down sampling using stride of 2, according to [1].\n",
        "            self.res_conv = Conv2D(\n",
        "                self.__channels, strides=2, kernel_size=(1, 1), kernel_initializer=INIT_SCHEME, padding=\"same\")\n",
        "            self.res_bn = BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        res = inputs\n",
        "\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.bn_1(x)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.bn_2(x)\n",
        "\n",
        "        if self.__down_sample:\n",
        "            res = self.res_conv(res)\n",
        "            res = self.res_bn(res)\n",
        "\n",
        "        # if not perform down sample, then add a shortcut directly\n",
        "        x = self.merge([x, res])\n",
        "        out = tf.nn.relu(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet18(Model):\n",
        "\n",
        "    def __init__(self, num_classes, **kwargs):\n",
        "        \"\"\"\n",
        "            num_classes: number of classes in specific classification task.\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv_1 = Conv2D(64, (7, 7), strides=2,\n",
        "                             padding=\"same\", kernel_initializer=\"he_normal\")\n",
        "        self.init_bn = BatchNormalization()\n",
        "        self.pool_2 = MaxPool2D(pool_size=(2, 2), strides=2, padding=\"same\")\n",
        "        self.res_1_1 = ResnetBlock(64)\n",
        "        self.res_1_2 = ResnetBlock(64)\n",
        "        self.res_2_1 = ResnetBlock(128, down_sample=True)\n",
        "        self.res_2_2 = ResnetBlock(128)\n",
        "        self.res_3_1 = ResnetBlock(256, down_sample=True)\n",
        "        self.res_3_2 = ResnetBlock(256)\n",
        "        self.res_4_1 = ResnetBlock(512, down_sample=True)\n",
        "        self.res_4_2 = ResnetBlock(512)\n",
        "        self.avg_pool = GlobalAveragePooling2D()\n",
        "        self.flat = Flatten()\n",
        "        self.fc = Dense(num_classes, activation=\"softmax\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        out = self.conv_1(inputs)\n",
        "        out = self.init_bn(out)\n",
        "        out = tf.nn.relu(out)\n",
        "        out = self.pool_2(out)\n",
        "        for res_block in [self.res_1_1, self.res_1_2, self.res_2_1, self.res_2_2, self.res_3_1, self.res_3_2, self.res_4_1, self.res_4_2]:\n",
        "            out = res_block(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = self.flat(out)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "resnet_model = ResNet18(10)\n",
        "resnet_model.build(input_shape = (None,32,32,3))\n",
        "resnet_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method ResnetBlock.call of <__main__.ResnetBlock object at 0x7f607e5e59d0>> and will run it as-is.\n",
            "Cause: mangled names are not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method ResnetBlock.call of <__main__.ResnetBlock object at 0x7f607e5e59d0>> and will run it as-is.\n",
            "Cause: mangled names are not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Model: \"res_net18_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_40 (Conv2D)           multiple                  9472      \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc multiple                  256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "resnet_block_16 (ResnetBlock multiple                  74368     \n",
            "_________________________________________________________________\n",
            "resnet_block_17 (ResnetBlock multiple                  74368     \n",
            "_________________________________________________________________\n",
            "resnet_block_18 (ResnetBlock multiple                  231296    \n",
            "_________________________________________________________________\n",
            "resnet_block_19 (ResnetBlock multiple                  296192    \n",
            "_________________________________________________________________\n",
            "resnet_block_20 (ResnetBlock multiple                  921344    \n",
            "_________________________________________________________________\n",
            "resnet_block_21 (ResnetBlock multiple                  1182208   \n",
            "_________________________________________________________________\n",
            "resnet_block_22 (ResnetBlock multiple                  3677696   \n",
            "_________________________________________________________________\n",
            "resnet_block_23 (ResnetBlock multiple                  4723712   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( multiple                  0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  5130      \n",
            "=================================================================\n",
            "Total params: 11,196,042\n",
            "Trainable params: 11,186,442\n",
            "Non-trainable params: 9,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OslqlQ_3S1Wq"
      },
      "source": [
        "# Distributing Training Dataset\n",
        "\n",
        "*   Divide into two categories - Label , Unlabel\n",
        "*   **Converting Label Encoding - One Hot Encoding**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKttanHNRZsb",
        "outputId": "840641cb-24e7-4c71-a275-f744d269c921"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "x_train , y_train = shuffle(x_train , y_train)\n",
        "x_test , y_test = shuffle(x_test , y_test)\n",
        "x_label , x_unlabel , y_label , y_unlabel = train_test_split(x_train , y_train , test_size = 0.1 , random_state = 42)\n",
        "print(\"X Train Shape : \" , x_train.shape)\n",
        "print(\"Y Train Shape : \" , y_train.shape)\n",
        "print(\"X Label Shape : \" , x_label.shape)\n",
        "print(\"Y Label Shape : \" , y_label.shape)\n",
        "print(\"X UnLabel Shape : \" , x_unlabel.shape)\n",
        "print(\"Y UnLabel Shape : \" , y_unlabel.shape)\n",
        "print(\"X Test Shape : \"  , x_test.shape)\n",
        "print(\"Y Test Shape : \" , y_test.shape)\n",
        "\n",
        "### Label Enocding to One - Hot Encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder_obj = OneHotEncoder(handle_unknown = 'ignore')\n",
        "y_label = encoder_obj.fit_transform(y_label).toarray()\n",
        "print(\"Y_Label Shape : \" , y_label.shape)\n",
        "y_test = encoder_obj.fit_transform(y_test).toarray()\n",
        "print(\"Y_Test Shape : \" , y_test.shape)\n",
        "y_train = encoder_obj.fit_transform(y_train).toarray()\n",
        "print(\"Y Train Shape : \" , y_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Train Shape :  (50000, 32, 32, 3)\n",
            "Y Train Shape :  (50000, 1)\n",
            "X Label Shape :  (45000, 32, 32, 3)\n",
            "Y Label Shape :  (45000, 1)\n",
            "X UnLabel Shape :  (5000, 32, 32, 3)\n",
            "Y UnLabel Shape :  (5000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 1)\n",
            "Y_Label Shape :  (45000, 10)\n",
            "Y_Test Shape :  (10000, 10)\n",
            "Y Train Shape :  (50000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXdFTv0KDQon"
      },
      "source": [
        "print(\"X Train : \" , x_train[0])\n",
        "print(\"X Label : \" , x_label[0])\n",
        "print(\"X Unlabel : \" , x_unlabel[0])\n",
        "print(\"X Test : \" , x_test[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHYAHmshmJ0Y"
      },
      "source": [
        "# Supervised Model Training\n",
        "Train the model using VGG - CIFAR 10 and mapping the accuracy and test accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJm8QYX0vNVd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "15f72bb0-d2a4-4e02-c089-f5b195529947"
      },
      "source": [
        "model = model\n",
        "def custom_loss(y_true , y_pred) :\n",
        "  global loss_unsupervised \n",
        "  ### Supervised Loss\n",
        "  loss_supervised = tf.keras.losses.CategoricalCrossentropy()\n",
        "  loss_supervised = loss_supervised(y_true, y_pred)\n",
        "  ### Unsupervised Loss \n",
        "  return loss_supervised\n",
        "\n",
        "\n",
        "          \n",
        "### Saving the best model\n",
        "model_weight_file_path = 'small_vgg.hdf5'\n",
        "model_check_point = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = model_weight_file_path , \n",
        "    save_weights_only = True , \n",
        "    monitor = 'val_accuracy' , \n",
        "    mode = 'max' , \n",
        "    save_best_only = True \n",
        ")\n",
        "\n",
        "### Training the model \n",
        "\n",
        "\n",
        "model.compile(optimizer='Adam' , loss = custom_loss , metrics = ['accuracy'])\n",
        "history = model.fit(x_label , y_label ,  epochs = 100 , batch_size = 128 , \n",
        "          validation_data = (x_test , y_test) , \n",
        "          callbacks = [model_check_point ], \n",
        "          verbose =1  )\n",
        "\n",
        "'''\n",
        "print(\"X Train Shape : \" , x_train.shape)\n",
        "print(\"Y Train Shape : \" , y_train.shape)\n",
        "model.compile(optimizer='Adam' , loss = custom_loss , metrics = ['accuracy'])\n",
        "history = model.fit(x_train , y_train , batch_size = 50 , epochs = 100 , \n",
        "          validation_data = (x_test , y_test) , \n",
        "          callbacks = [model_check_point ], \n",
        "          verbose =1  )\n",
        "'''\n",
        "\n",
        "### Loading the best validation_accuracy weights \n",
        "model.load_weights(model_weight_file_path)\n",
        "\n",
        "### Prediction\n",
        "\n",
        "predict_y = model.predict(x = x_test , batch_size = 32 , verbose = 1)\n",
        "test_accuracy = 0\n",
        "for i in range(len(x_test)):\n",
        "    if (np.argmax(predict_y[i]) == np.argmax(y_test[i])):\n",
        "        test_accuracy += 1\n",
        "test_accuracy = test_accuracy / len(x_test)*100\n",
        "\n",
        "print(\"Test Accuracy: \", test_accuracy)\n",
        "\n",
        "def plot_metric(history, metric):\n",
        "    train_metrics = history.history[metric]\n",
        "    val_metrics = history.history['val_'+metric]\n",
        "    epochs = range(1, len(train_metrics) + 1)\n",
        "    plt.plot(epochs, train_metrics)\n",
        "    plt.plot(epochs, val_metrics)\n",
        "    plt.title('Training and validation '+ metric)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
        "    plt.show()\n",
        "\n",
        "## Mapping Accuracy\n",
        "plot_metric(history , 'accuracy')\n",
        "## Loss \n",
        "plot_metric(history , 'loss')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "387/387 [==============================] - 9s 18ms/step - loss: 3.2837 - accuracy: 0.3236 - val_loss: 2.5517 - val_accuracy: 0.4580\n",
            "Epoch 2/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 2.2380 - accuracy: 0.5583 - val_loss: 1.9516 - val_accuracy: 0.6095\n",
            "Epoch 3/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 1.8065 - accuracy: 0.6473 - val_loss: 1.5807 - val_accuracy: 0.6912\n",
            "Epoch 4/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 1.5222 - accuracy: 0.6956 - val_loss: 1.3501 - val_accuracy: 0.7270\n",
            "Epoch 5/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 1.3393 - accuracy: 0.7240 - val_loss: 1.4250 - val_accuracy: 0.6858\n",
            "Epoch 6/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 1.2351 - accuracy: 0.7428 - val_loss: 1.1478 - val_accuracy: 0.7608\n",
            "Epoch 7/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 1.1245 - accuracy: 0.7648 - val_loss: 1.0970 - val_accuracy: 0.7699\n",
            "Epoch 8/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 1.0558 - accuracy: 0.7843 - val_loss: 1.0346 - val_accuracy: 0.7921\n",
            "Epoch 9/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 1.0261 - accuracy: 0.7941 - val_loss: 1.0545 - val_accuracy: 0.7794\n",
            "Epoch 10/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.9981 - accuracy: 0.8019 - val_loss: 1.0263 - val_accuracy: 0.7965\n",
            "Epoch 11/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.9705 - accuracy: 0.8146 - val_loss: 0.9933 - val_accuracy: 0.8013\n",
            "Epoch 12/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.9486 - accuracy: 0.8204 - val_loss: 1.0656 - val_accuracy: 0.7818\n",
            "Epoch 13/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.9376 - accuracy: 0.8209 - val_loss: 0.9544 - val_accuracy: 0.8094\n",
            "Epoch 14/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.9122 - accuracy: 0.8303 - val_loss: 0.9573 - val_accuracy: 0.8159\n",
            "Epoch 15/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.9154 - accuracy: 0.8266 - val_loss: 1.0386 - val_accuracy: 0.7916\n",
            "Epoch 16/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.9080 - accuracy: 0.8336 - val_loss: 0.9689 - val_accuracy: 0.8150\n",
            "Epoch 17/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8947 - accuracy: 0.8348 - val_loss: 1.0937 - val_accuracy: 0.7714\n",
            "Epoch 18/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8982 - accuracy: 0.8352 - val_loss: 1.0674 - val_accuracy: 0.7825\n",
            "Epoch 19/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8821 - accuracy: 0.8406 - val_loss: 0.9349 - val_accuracy: 0.8243\n",
            "Epoch 20/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8737 - accuracy: 0.8444 - val_loss: 1.0518 - val_accuracy: 0.7977\n",
            "Epoch 21/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8704 - accuracy: 0.8442 - val_loss: 1.0196 - val_accuracy: 0.7970\n",
            "Epoch 22/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8692 - accuracy: 0.8444 - val_loss: 0.9229 - val_accuracy: 0.8246\n",
            "Epoch 23/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8614 - accuracy: 0.8476 - val_loss: 0.9646 - val_accuracy: 0.8200\n",
            "Epoch 24/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8506 - accuracy: 0.8509 - val_loss: 1.0051 - val_accuracy: 0.8059\n",
            "Epoch 25/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8669 - accuracy: 0.8459 - val_loss: 0.8935 - val_accuracy: 0.8406\n",
            "Epoch 26/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8419 - accuracy: 0.8532 - val_loss: 0.9072 - val_accuracy: 0.8375\n",
            "Epoch 27/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8512 - accuracy: 0.8517 - val_loss: 0.8751 - val_accuracy: 0.8445\n",
            "Epoch 28/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8349 - accuracy: 0.8573 - val_loss: 0.9627 - val_accuracy: 0.8153\n",
            "Epoch 29/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8381 - accuracy: 0.8569 - val_loss: 0.9135 - val_accuracy: 0.8274\n",
            "Epoch 30/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8342 - accuracy: 0.8586 - val_loss: 0.9236 - val_accuracy: 0.8259\n",
            "Epoch 31/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8368 - accuracy: 0.8579 - val_loss: 0.9121 - val_accuracy: 0.8338\n",
            "Epoch 32/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8280 - accuracy: 0.8588 - val_loss: 0.8971 - val_accuracy: 0.8350\n",
            "Epoch 33/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8289 - accuracy: 0.8575 - val_loss: 0.9936 - val_accuracy: 0.8066\n",
            "Epoch 34/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8309 - accuracy: 0.8605 - val_loss: 0.9361 - val_accuracy: 0.8241\n",
            "Epoch 35/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8326 - accuracy: 0.8571 - val_loss: 0.9278 - val_accuracy: 0.8312\n",
            "Epoch 36/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8090 - accuracy: 0.8662 - val_loss: 0.9106 - val_accuracy: 0.8328\n",
            "Epoch 37/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8157 - accuracy: 0.8632 - val_loss: 0.9505 - val_accuracy: 0.8234\n",
            "Epoch 38/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8187 - accuracy: 0.8629 - val_loss: 0.8495 - val_accuracy: 0.8518\n",
            "Epoch 39/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8181 - accuracy: 0.8611 - val_loss: 0.8909 - val_accuracy: 0.8359\n",
            "Epoch 40/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8102 - accuracy: 0.8647 - val_loss: 0.9095 - val_accuracy: 0.8366\n",
            "Epoch 41/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8204 - accuracy: 0.8621 - val_loss: 0.8530 - val_accuracy: 0.8494\n",
            "Epoch 42/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8066 - accuracy: 0.8633 - val_loss: 0.9160 - val_accuracy: 0.8315\n",
            "Epoch 43/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8078 - accuracy: 0.8681 - val_loss: 0.9618 - val_accuracy: 0.8139\n",
            "Epoch 44/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.7950 - accuracy: 0.8682 - val_loss: 0.9273 - val_accuracy: 0.8226\n",
            "Epoch 45/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.8005 - accuracy: 0.8685 - val_loss: 0.9147 - val_accuracy: 0.8308\n",
            "Epoch 46/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.7903 - accuracy: 0.8694 - val_loss: 0.8897 - val_accuracy: 0.8428\n",
            "Epoch 47/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.7875 - accuracy: 0.8715 - val_loss: 0.8435 - val_accuracy: 0.8526\n",
            "Epoch 48/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.7910 - accuracy: 0.8718 - val_loss: 0.9028 - val_accuracy: 0.8387\n",
            "Epoch 49/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.7949 - accuracy: 0.8694 - val_loss: 0.9348 - val_accuracy: 0.8235\n",
            "Epoch 50/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.7930 - accuracy: 0.8668 - val_loss: 0.8845 - val_accuracy: 0.8426\n",
            "Epoch 51/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.7914 - accuracy: 0.8711 - val_loss: 0.8647 - val_accuracy: 0.8459\n",
            "Epoch 52/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.7888 - accuracy: 0.8705 - val_loss: 0.8680 - val_accuracy: 0.8452\n",
            "Epoch 53/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.7892 - accuracy: 0.8695 - val_loss: 0.8550 - val_accuracy: 0.8498\n",
            "Epoch 54/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.7869 - accuracy: 0.8699 - val_loss: 0.9139 - val_accuracy: 0.8293\n",
            "Epoch 55/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.7816 - accuracy: 0.8709 - val_loss: 0.9093 - val_accuracy: 0.8309\n",
            "Epoch 56/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.7877 - accuracy: 0.8708 - val_loss: 0.9248 - val_accuracy: 0.8288\n",
            "Epoch 57/100\n",
            "387/387 [==============================] - 6s 16ms/step - loss: 0.7722 - accuracy: 0.8759 - val_loss: 0.9221 - val_accuracy: 0.8302\n",
            "Epoch 58/100\n",
            "  1/387 [..............................] - ETA: 6s - loss: 0.7820 - accuracy: 0.8750"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-ce90a9511df3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m           \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_check_point\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m           verbose =1  )\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m '''\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFZ-pPRpmhXy"
      },
      "source": [
        "## Custom Callbacks for the SSL\n",
        "\n",
        "1.   **Custom Loss -**\n",
        "Here we will combine the loss by both the models of supervised as well as unsupervised model. i.e. that the supervised loss will be (Cross - Entropy) and unlablled sample (Cross Entropy with the psudeo label only)\n",
        "2.   Mapping Training / Validation Accuracy\n",
        "3.   Mapping Training / Validation Loss\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TEPeSuUpfVW"
      },
      "source": [
        "# Semi - Supervised Model Training\n",
        "Adam , Threshold 0.9 ,  VGG Modified , 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD63q1DDM1Em",
        "outputId": "ad68f998-a9cb-4f8f-f904-c36062927262"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "### Random augmentation wrapper\n",
        "def random_rotate_image_strong(image):\n",
        "  randAug = RandAugment(2 , 6)\n",
        "  image = randAug.__call__(array_to_img(image))\n",
        "  image = img_to_array(image)\n",
        "  return image\n",
        "def tf_random_rotate_image_strong(image):\n",
        "  im_shape = image.shape\n",
        "  [image,] = tf.py_function(random_rotate_image_strong, [image], [tf.float32])\n",
        "  image.set_shape(im_shape)\n",
        "  return image/255.0\n",
        "### Weak augmentation wrapper\n",
        "def random_rotate_image_weak(image):\n",
        "  #image = ndimage.rotate(image, np.random.uniform(-30, 30), reshape=False)\n",
        "  weak_aug = WeakAugment(3)\n",
        "  image = weak_aug.__call__(array_to_img(image))\n",
        "  image = img_to_array(image)\n",
        "  return image\n",
        "def tf_random_rotate_image_weak(image):\n",
        "  im_shape = image.shape\n",
        "  [image,] = tf.py_function(random_rotate_image_weak, [image], [tf.float32])\n",
        "  image.set_shape(im_shape)\n",
        "  return image/255.0  \n",
        "\n",
        "model = model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "test_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "### Getting the shape\n",
        "print(\"X Label Shape : \" , x_label.shape)\n",
        "print(\"Y Label Shape : \" , y_label.shape)\n",
        "print(\"X Unlabel Shape : \", x_unlabel.shape)\n",
        "print(\"Y Unlable Shape : \", y_unlabel.shape)\n",
        "print(\"X Test Shape : \", x_test.shape)\n",
        "print(\"Y Test Shape : \", y_test.shape)\n",
        "\n",
        "def custom_loss(y_true , y_pred , y_weak , y_strong) : \n",
        "  alpha = 1 \n",
        "  threshold = 0.9\n",
        "  y_weak_new = []\n",
        "  y_strong_new = []\n",
        "  ### Now getting only the y_weak with greater than threshold \n",
        "  for i in range(len(y_weak)) : \n",
        "    val = np.argmax(y_weak[i])\n",
        "    if  y_weak[i][val] >= threshold :\n",
        "      ### Creating Pseudo Label\n",
        "      val = np.argmax(y_weak[i])\n",
        "      y_pseudo = np.array([0 for j in range(len(y_weak[i]))])\n",
        "      y_pseudo[val] = 1 \n",
        "      ### Appending data to y_weak\n",
        "      y_weak_new.append(y_pseudo)\n",
        "      y_strong_new.append(y_strong[i])\n",
        "\n",
        "  y_weak = np.array(y_weak_new)\n",
        "  y_strong = np.array(y_strong_new)\n",
        "        \n",
        "  cateogrical_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  supervised_loss = cateogrical_cross_entropy(y_true , y_pred)\n",
        "\n",
        "  if y_weak.size !=  0 : \n",
        "    unsupervised_loss = cateogrical_cross_entropy(y_weak , y_strong)\n",
        "    custom_loss = alpha * unsupervised_loss + supervised_loss\n",
        "\n",
        "  else : \n",
        "    custom_loss = supervised_loss\n",
        "\n",
        "  return custom_loss\n",
        "\n",
        "def custom_loss_test(y_true , y_pred) : \n",
        "  cateogrical_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  loss = cateogrical_cross_entropy(y_true , y_pred)\n",
        "  return loss\n",
        "\n",
        "\n",
        "for epoch in range(epochs) : \n",
        "  print(\"Epoch : \" , epoch + 1 , end = \" \")\n",
        "  ### Time \n",
        "  start_time = time.time()\n",
        "  ### Dataset\n",
        "  x_label , y_label = shuffle(x_label , y_label)\n",
        "  x_unlabel = shuffle(x_unlabel)\n",
        "  x_unlabels =  tf.data.Dataset.from_tensor_slices(x_unlabel)\n",
        "  x_unlabels_weak = x_unlabels.map(tf_random_rotate_image_weak)\n",
        "  x_unlabels_strong = x_unlabels.map(tf_random_rotate_image_strong)\n",
        "  labels = tf.data.Dataset.from_tensor_slices((x_label , y_label))\n",
        "  unlabels = tf.data.Dataset.zip((x_unlabels_weak , x_unlabels_strong))\n",
        "  train_dataset = tf.data.Dataset.zip((labels , unlabels)).batch(500)\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices((x_test , y_test)).batch(500)\n",
        "  \n",
        "  for steps  , (labels , unlabels) in enumerate(train_dataset) : \n",
        "    batch_losses = []\n",
        "    with tf.GradientTape() as tape : \n",
        "      logs_labels = model(labels[0] , training = True )\n",
        "      logs_unlabels_weak = model(unlabels[0] , training = False )\n",
        "      logs_unlabels_strong = model(unlabels[1] , training = True )\n",
        "\n",
        "      loss = custom_loss(labels[1] , logs_labels , logs_unlabels_weak , logs_unlabels_strong)\n",
        "      batch_losses.append(loss.numpy())\n",
        "      train_acc_metric.update_state(labels[1] , logs_labels)\n",
        "\n",
        "    \n",
        "    grads = tape.gradient(loss , model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads , model.trainable_variables))\n",
        "    \n",
        "\n",
        "  test_batch_losses = []\n",
        "  for x_test_dash , y_test_dash in test_dataset : \n",
        "    y_predict = model(x_test_dash , training = False )\n",
        "    loss = custom_loss_test(y_test_dash , y_predict)\n",
        "    test_batch_losses.append(loss.numpy())\n",
        "    ### Testing Accuracy\n",
        "    test_acc_metric.update_state(y_test_dash , y_predict)\n",
        "\n",
        "  ### Time End for Epoch\n",
        "  end_time = time.time()\n",
        "  train_acc = train_acc_metric.result()\n",
        "  test_acc = test_acc_metric.result()\n",
        "  print(\"Training acc: %4.f\" % (float(train_acc),) , end = \" \")\n",
        "  print(\"Test acc: %.4f\" % (float(test_acc),) , end = \" \")\n",
        "  print(\"Training Loss : \" , np.mean(batch_losses) , end = \" \")\n",
        "  print(\"Test Loss : \" , np.mean(test_batch_losses) , end = \" \")\n",
        "  print(\"Time : \" , end_time - start_time )\n",
        "  train_acc_metric.reset_states()\n",
        "  test_acc_metric.reset_states()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Label Shape :  (45000, 32, 32, 3)\n",
            "Y Label Shape :  (45000, 10)\n",
            "X Unlabel Shape :  (5000, 32, 32, 3)\n",
            "Y Unlable Shape :  (5000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 10)\n",
            "Epoch :  1 Training acc:    0 Test acc: 0.1221 Training Loss :  2.4999669 Test Loss :  2.8400676 Time :  47.71237230300903\n",
            "Epoch :  2 Training acc:    0 Test acc: 0.1835 Training Loss :  2.3830605 Test Loss :  2.227315 Time :  17.86898112297058\n",
            "Epoch :  3 Training acc:    0 Test acc: 0.1883 Training Loss :  2.1112168 Test Loss :  2.2535567 Time :  17.240731954574585\n",
            "Epoch :  4 Training acc:    0 Test acc: 0.2277 Training Loss :  1.8027402 Test Loss :  2.0776296 Time :  17.16632390022278\n",
            "Epoch :  5 Training acc:    0 Test acc: 0.2214 Training Loss :  1.8936942 Test Loss :  2.0907345 Time :  17.100680589675903\n",
            "Epoch :  6 Training acc:    0 Test acc: 0.2508 Training Loss :  1.7974924 Test Loss :  2.0520706 Time :  16.888553380966187\n",
            "Epoch :  7 Training acc:    0 Test acc: 0.2494 Training Loss :  1.7160325 Test Loss :  2.1077685 Time :  16.95274591445923\n",
            "Epoch :  8 Training acc:    0 Test acc: 0.2601 Training Loss :  1.7142104 Test Loss :  2.1026137 Time :  16.956273078918457\n",
            "Epoch :  9 Training acc:    0 Test acc: 0.2071 Training Loss :  1.5694599 Test Loss :  2.3908534 Time :  17.176309823989868\n",
            "Epoch :  10 Training acc:    0 Test acc: 0.1781 Training Loss :  1.6159452 Test Loss :  2.4653347 Time :  16.975471258163452\n",
            "Epoch :  11 Training acc:    0 Test acc: 0.2309 Training Loss :  1.5502061 Test Loss :  2.3939412 Time :  17.030152797698975\n",
            "Epoch :  12 Training acc:    0 Test acc: 0.2760 Training Loss :  1.6253611 Test Loss :  2.2069259 Time :  17.0671865940094\n",
            "Epoch :  13 Training acc:    0 Test acc: 0.2339 Training Loss :  1.5625786 Test Loss :  2.3416324 Time :  16.99520969390869\n",
            "Epoch :  14 Training acc:    0 Test acc: 0.2561 Training Loss :  1.4292698 Test Loss :  2.411128 Time :  17.245080709457397\n",
            "Epoch :  15 Training acc:    0 Test acc: 0.2624 Training Loss :  1.404227 Test Loss :  2.2578495 Time :  16.926364183425903\n",
            "Epoch :  16 Training acc:    1 Test acc: 0.2572 Training Loss :  1.4119315 Test Loss :  2.1777203 Time :  17.008151292800903\n",
            "Epoch :  17 Training acc:    1 Test acc: 0.2327 Training Loss :  1.3827902 Test Loss :  2.4396806 Time :  17.132083892822266\n",
            "Epoch :  18 Training acc:    1 Test acc: 0.2403 Training Loss :  1.405052 Test Loss :  2.4632447 Time :  17.006290197372437\n",
            "Epoch :  19 Training acc:    1 Test acc: 0.2376 Training Loss :  3.4009502 Test Loss :  2.332017 Time :  17.13724660873413\n",
            "Epoch :  20 Training acc:    1 Test acc: 0.2588 Training Loss :  2.8823986 Test Loss :  2.31887 Time :  17.07315444946289\n",
            "Epoch :  21 Training acc:    1 Test acc: 0.2385 Training Loss :  3.0956893 Test Loss :  2.3662305 Time :  17.217782735824585\n",
            "Epoch :  22 Training acc:    1 Test acc: 0.2541 Training Loss :  2.9845924 Test Loss :  2.2884653 Time :  17.21695113182068\n",
            "Epoch :  23 Training acc:    1 Test acc: 0.2584 Training Loss :  3.372095 Test Loss :  2.472445 Time :  17.08000421524048\n",
            "Epoch :  24 Training acc:    1 Test acc: 0.2642 Training Loss :  3.2093115 Test Loss :  2.3279898 Time :  16.981558322906494\n",
            "Epoch :  25 Training acc:    1 Test acc: 0.2904 Training Loss :  3.2482705 Test Loss :  2.288094 Time :  17.007187366485596\n",
            "Epoch :  26 Training acc:    1 Test acc: 0.2897 Training Loss :  3.0906038 Test Loss :  2.3908617 Time :  17.02624487876892\n",
            "Epoch :  27 Training acc:    1 Test acc: 0.3291 Training Loss :  3.1509597 Test Loss :  2.1393728 Time :  17.14072060585022\n",
            "Epoch :  28 Training acc:    1 Test acc: 0.3655 Training Loss :  2.6890602 Test Loss :  1.9916391 Time :  17.03025984764099\n",
            "Epoch :  29 Training acc:    1 Test acc: 0.3399 Training Loss :  3.064106 Test Loss :  2.078567 Time :  17.164857864379883\n",
            "Epoch :  30 Training acc:    1 Test acc: 0.3383 Training Loss :  3.1694622 Test Loss :  2.2614636 Time :  16.99069881439209\n",
            "Epoch :  31 Training acc:    1 Test acc: 0.3295 Training Loss :  3.0489342 Test Loss :  2.311271 Time :  16.967023611068726\n",
            "Epoch :  32 Training acc:    1 Test acc: 0.3525 Training Loss :  2.8805852 Test Loss :  2.156334 Time :  17.259602785110474\n",
            "Epoch :  33 Training acc:    1 Test acc: 0.3984 Training Loss :  2.9113379 Test Loss :  1.9188658 Time :  16.892838954925537\n",
            "Epoch :  34 Training acc:    1 Test acc: 0.4451 Training Loss :  3.0659728 Test Loss :  1.7029016 Time :  17.036306619644165\n",
            "Epoch :  35 Training acc:    1 Test acc: 0.4309 Training Loss :  2.9553618 Test Loss :  1.7416794 Time :  16.995469093322754\n",
            "Epoch :  36 Training acc:    1 Test acc: 0.4421 Training Loss :  2.9467607 Test Loss :  1.7021061 Time :  17.090462684631348\n",
            "Epoch :  37 Training acc:    1 Test acc: 0.4561 Training Loss :  3.0107315 Test Loss :  1.645705 Time :  16.85865569114685\n",
            "Epoch :  38 Training acc:    1 Test acc: 0.4829 Training Loss :  2.9031568 Test Loss :  1.5332884 Time :  16.87896704673767\n",
            "Epoch :  39 Training acc:    1 Test acc: 0.4977 Training Loss :  3.0872684 Test Loss :  1.4950398 Time :  16.912174224853516\n",
            "Epoch :  40 Training acc:    1 Test acc: 0.5151 Training Loss :  3.0601368 Test Loss :  1.4235033 Time :  16.874348640441895\n",
            "Epoch :  41 Training acc:    1 Test acc: 0.5021 Training Loss :  2.9982905 Test Loss :  1.463062 Time :  16.851612091064453\n",
            "Epoch :  42 Training acc:    1 Test acc: 0.4733 Training Loss :  2.9883761 Test Loss :  1.5813549 Time :  16.863540172576904\n",
            "Epoch :  43 Training acc:    1 Test acc: 0.5281 Training Loss :  3.0164816 Test Loss :  1.3662853 Time :  17.00931715965271\n",
            "Epoch :  44 Training acc:    1 Test acc: 0.5571 Training Loss :  2.788425 Test Loss :  1.2619625 Time :  17.062936782836914\n",
            "Epoch :  45 Training acc:    1 Test acc: 0.5589 Training Loss :  2.954868 Test Loss :  1.2490522 Time :  17.11917209625244\n",
            "Epoch :  46 Training acc:    1 Test acc: 0.5567 Training Loss :  2.8337429 Test Loss :  1.3070244 Time :  17.10311532020569\n",
            "Epoch :  47 Training acc:    1 Test acc: 0.5868 Training Loss :  2.9685874 Test Loss :  1.202054 Time :  17.276091814041138\n",
            "Epoch :  48 Training acc:    1 Test acc: 0.6294 Training Loss :  2.898698 Test Loss :  1.0397296 Time :  17.551301956176758\n",
            "Epoch :  49 Training acc:    1 Test acc: 0.6119 Training Loss :  2.9684892 Test Loss :  1.0942891 Time :  17.444754123687744\n",
            "Epoch :  50 Training acc:    1 Test acc: 0.6289 Training Loss :  2.9496114 Test Loss :  1.0384303 Time :  17.71833062171936\n",
            "Epoch :  51 Training acc:    1 Test acc: 0.6318 Training Loss :  2.8506947 Test Loss :  1.0299354 Time :  17.67484998703003\n",
            "Epoch :  52 Training acc:    1 Test acc: 0.6452 Training Loss :  2.7756789 Test Loss :  0.9817146 Time :  17.491719245910645\n",
            "Epoch :  53 Training acc:    1 Test acc: 0.6779 Training Loss :  2.8225121 Test Loss :  0.8972955 Time :  17.592148780822754\n",
            "Epoch :  54 Training acc:    1 Test acc: 0.6286 Training Loss :  2.9445093 Test Loss :  1.0545794 Time :  17.370981216430664\n",
            "Epoch :  55 Training acc:    1 Test acc: 0.6805 Training Loss :  2.9033089 Test Loss :  0.8995994 Time :  17.459189653396606\n",
            "Epoch :  56 Training acc:    1 Test acc: 0.6926 Training Loss :  3.032081 Test Loss :  0.87465286 Time :  17.533602952957153\n",
            "Epoch :  57 Training acc:    1 Test acc: 0.7085 Training Loss :  2.9158587 Test Loss :  0.8223688 Time :  17.686753034591675\n",
            "Epoch :  58 Training acc:    1 Test acc: 0.6973 Training Loss :  2.916308 Test Loss :  0.8524542 Time :  17.581849098205566\n",
            "Epoch :  59 Training acc:    1 Test acc: 0.7020 Training Loss :  2.8253999 Test Loss :  0.8352896 Time :  17.522486686706543\n",
            "Epoch :  60 Training acc:    1 Test acc: 0.7099 Training Loss :  2.9675338 Test Loss :  0.82823336 Time :  17.61830163002014\n",
            "Epoch :  61 Training acc:    1 Test acc: 0.7098 Training Loss :  2.705608 Test Loss :  0.81881124 Time :  17.62539005279541\n",
            "Epoch :  62 Training acc:    1 Test acc: 0.7209 Training Loss :  2.8266282 Test Loss :  0.7982408 Time :  17.96178102493286\n",
            "Epoch :  63 Training acc:    1 Test acc: 0.7118 Training Loss :  2.8511932 Test Loss :  0.8242072 Time :  18.04288339614868\n",
            "Epoch :  64 Training acc:    1 Test acc: 0.7138 Training Loss :  2.792597 Test Loss :  0.8162966 Time :  17.813424587249756\n",
            "Epoch :  65 Training acc:    1 Test acc: 0.7172 Training Loss :  2.828406 Test Loss :  0.8052325 Time :  17.913783311843872\n",
            "Epoch :  66 Training acc:    1 Test acc: 0.6836 Training Loss :  2.9156737 Test Loss :  0.8874381 Time :  17.75312113761902\n",
            "Epoch :  67 Training acc:    1 Test acc: 0.7100 Training Loss :  2.755537 Test Loss :  0.82498294 Time :  17.853646516799927\n",
            "Epoch :  68 Training acc:    1 Test acc: 0.7326 Training Loss :  2.7345018 Test Loss :  0.7589365 Time :  18.06305956840515\n",
            "Epoch :  69 Training acc:    1 Test acc: 0.7345 Training Loss :  2.7183561 Test Loss :  0.75944346 Time :  17.750080585479736\n",
            "Epoch :  70 Training acc:    1 Test acc: 0.7308 Training Loss :  2.8637376 Test Loss :  0.7656542 Time :  17.900901079177856\n",
            "Epoch :  71 Training acc:    1 Test acc: 0.7337 Training Loss :  2.7408712 Test Loss :  0.7609259 Time :  17.901931524276733\n",
            "Epoch :  72 Training acc:    1 Test acc: 0.7416 Training Loss :  2.8155823 Test Loss :  0.7498161 Time :  17.782670259475708\n",
            "Epoch :  73 Training acc:    1 Test acc: 0.7322 Training Loss :  2.8273807 Test Loss :  0.7688057 Time :  17.84581971168518\n",
            "Epoch :  74 Training acc:    1 Test acc: 0.7331 Training Loss :  2.7608666 Test Loss :  0.766687 Time :  17.83669400215149\n",
            "Epoch :  75 Training acc:    1 Test acc: 0.7338 Training Loss :  2.7490716 Test Loss :  0.7527846 Time :  17.672004222869873\n",
            "Epoch :  76 Training acc:    1 Test acc: 0.7294 Training Loss :  2.664369 Test Loss :  0.7835876 Time :  17.493096351623535\n",
            "Epoch :  77 Training acc:    1 Test acc: 0.7526 Training Loss :  2.662487 Test Loss :  0.71615446 Time :  17.86688733100891\n",
            "Epoch :  78 Training acc:    1 Test acc: 0.7447 Training Loss :  2.722383 Test Loss :  0.7313344 Time :  18.077807903289795\n",
            "Epoch :  79 Training acc:    1 Test acc: 0.7463 Training Loss :  2.694226 Test Loss :  0.72048414 Time :  17.848853826522827\n",
            "Epoch :  80 Training acc:    1 Test acc: 0.7502 Training Loss :  2.696384 Test Loss :  0.71341574 Time :  17.931300401687622\n",
            "Epoch :  81 Training acc:    1 Test acc: 0.7511 Training Loss :  2.6561701 Test Loss :  0.70726764 Time :  17.86756944656372\n",
            "Epoch :  82 Training acc:    1 Test acc: 0.7398 Training Loss :  2.748935 Test Loss :  0.748707 Time :  17.8993022441864\n",
            "Epoch :  83 Training acc:    1 Test acc: 0.7605 Training Loss :  2.7225084 Test Loss :  0.68520254 Time :  17.74419617652893\n",
            "Epoch :  84 Training acc:    1 Test acc: 0.7536 Training Loss :  2.6447892 Test Loss :  0.714982 Time :  17.95392894744873\n",
            "Epoch :  85 Training acc:    1 Test acc: 0.7501 Training Loss :  2.653155 Test Loss :  0.7284931 Time :  17.954917907714844\n",
            "Epoch :  86 Training acc:    1 Test acc: 0.7494 Training Loss :  2.7320971 Test Loss :  0.7198657 Time :  18.081483602523804\n",
            "Epoch :  87 Training acc:    1 Test acc: 0.7482 Training Loss :  2.6511645 Test Loss :  0.72294533 Time :  18.012967348098755\n",
            "Epoch :  88 Training acc:    1 Test acc: 0.7501 Training Loss :  2.7738557 Test Loss :  0.74583465 Time :  17.74195170402527\n",
            "Epoch :  89 Training acc:    1 Test acc: 0.7584 Training Loss :  2.6214843 Test Loss :  0.6993052 Time :  17.7812659740448\n",
            "Epoch :  90 Training acc:    1 Test acc: 0.7570 Training Loss :  2.7265964 Test Loss :  0.6990944 Time :  17.674501419067383\n",
            "Epoch :  91 Training acc:    1 Test acc: 0.7614 Training Loss :  2.6078389 Test Loss :  0.68961734 Time :  17.926773071289062\n",
            "Epoch :  92 Training acc:    1 Test acc: 0.7613 Training Loss :  2.641711 Test Loss :  0.6891223 Time :  17.84304165840149\n",
            "Epoch :  93 Training acc:    1 Test acc: 0.7602 Training Loss :  2.7586553 Test Loss :  0.67748106 Time :  17.89061450958252\n",
            "Epoch :  94 Training acc:    1 Test acc: 0.7685 Training Loss :  2.578327 Test Loss :  0.68513787 Time :  17.8106689453125\n",
            "Epoch :  95 Training acc:    1 Test acc: 0.7664 Training Loss :  2.687775 Test Loss :  0.67556375 Time :  17.946820497512817\n",
            "Epoch :  96 Training acc:    1 Test acc: 0.7663 Training Loss :  2.7007012 Test Loss :  0.6669327 Time :  17.774054765701294\n",
            "Epoch :  97 Training acc:    1 Test acc: 0.7672 Training Loss :  2.6075099 Test Loss :  0.66675436 Time :  17.878681898117065\n",
            "Epoch :  98 Training acc:    1 Test acc: 0.7737 Training Loss :  2.6461844 Test Loss :  0.6578857 Time :  18.06680130958557\n",
            "Epoch :  99 Training acc:    1 Test acc: 0.7368 Training Loss :  2.7654696 Test Loss :  0.76014 Time :  17.688570261001587\n",
            "Epoch :  100 Training acc:    1 Test acc: 0.7622 Training Loss :  2.439519 Test Loss :  0.6776542 Time :  17.668285131454468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEh7Og-wem_U"
      },
      "source": [
        "# Model Training - 2nd\n",
        "Adam , Threshold 0.9 ,  VGG Modified , 0.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JM9K8jhevDT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0daae36c-ffc0-4779-d37a-7f2f33532b06"
      },
      "source": [
        "def custom_cifar10_data(img_rows, img_cols):\n",
        "\n",
        "    # Load cifar10 training and validation sets\n",
        "    (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
        "\n",
        "    # Resize training images\n",
        "    X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:,:,:,:]])\n",
        "    X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:,:,:,:]])\n",
        "\n",
        "    # Transform targets to keras compatible format\n",
        "    Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
        "    Y_valid = np_utils.to_categorical(Y_valid, num_classes)\n",
        "    \n",
        "    X_train = X_train.astype('float32')\n",
        "    X_valid = X_valid.astype('float32')\n",
        "\n",
        "    # preprocess data\n",
        "    X_train = X_train / 255.0\n",
        "    X_valid = X_valid / 255.0\n",
        "\n",
        "    return X_train, Y_train, X_valid, Y_valid\n",
        "\n",
        "(x_train , y_train) , (x_test , y_test) = cifar10.load_data() \n",
        "print('X Train Shape : ' , x_train.shape)\n",
        "print('Y Train Shape :' , y_train.shape)\n",
        "print('X Test Shape : ' , x_test.shape)\n",
        "print('Y Test Shape : ' , y_test.shape)\n",
        "\n",
        "### Normalize the dataset\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "    \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "    \n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "   \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "x_train , y_train = shuffle(x_train , y_train)\n",
        "x_test , y_test = shuffle(x_test , y_test)\n",
        "x_label , x_unlabel , y_label , y_unlabel = train_test_split(x_train , y_train , test_size = 0.2 , random_state = 42)\n",
        "print(\"X Train Shape : \" , x_train.shape)\n",
        "print(\"Y Train Shape : \" , y_train.shape)\n",
        "print(\"X Label Shape : \" , x_label.shape)\n",
        "print(\"Y Label Shape : \" , y_label.shape)\n",
        "print(\"X UnLabel Shape : \" , x_unlabel.shape)\n",
        "print(\"Y UnLabel Shape : \" , y_unlabel.shape)\n",
        "print(\"X Test Shape : \"  , x_test.shape)\n",
        "print(\"Y Test Shape : \" , y_test.shape)\n",
        "\n",
        "### Label Enocding to One - Hot Encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder_obj = OneHotEncoder(handle_unknown = 'ignore')\n",
        "y_label = encoder_obj.fit_transform(y_label).toarray()\n",
        "print(\"Y_Label Shape : \" , y_label.shape)\n",
        "y_test = encoder_obj.fit_transform(y_test).toarray()\n",
        "print(\"Y_Test Shape : \" , y_test.shape)\n",
        "y_train = encoder_obj.fit_transform(y_train).toarray()\n",
        "print(\"Y Train Shape : \" , y_train.shape)\n",
        "\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "### Random augmentation wrapper\n",
        "def random_rotate_image_strong(image):\n",
        "  randAug = RandAugment(2 , 6)\n",
        "  image = randAug.__call__(array_to_img(image))\n",
        "  image = img_to_array(image)\n",
        "  return image\n",
        "def tf_random_rotate_image_strong(image):\n",
        "  im_shape = image.shape\n",
        "  [image,] = tf.py_function(random_rotate_image_strong, [image], [tf.float32])\n",
        "  image.set_shape(im_shape)\n",
        "  return image/255.0\n",
        "### Weak augmentation wrapper\n",
        "def random_rotate_image_weak(image):\n",
        "  #image = ndimage.rotate(image, np.random.uniform(-30, 30), reshape=False)\n",
        "  weak_aug = WeakAugment(3)\n",
        "  image = weak_aug.__call__(array_to_img(image))\n",
        "  image = img_to_array(image)\n",
        "  return image\n",
        "def tf_random_rotate_image_weak(image):\n",
        "  im_shape = image.shape\n",
        "  [image,] = tf.py_function(random_rotate_image_weak, [image], [tf.float32])\n",
        "  image.set_shape(im_shape)\n",
        "  return image/255.0  \n",
        "\n",
        "model = model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "test_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "### Getting the shape\n",
        "print(\"X Label Shape : \" , x_label.shape)\n",
        "print(\"Y Label Shape : \" , y_label.shape)\n",
        "print(\"X Unlabel Shape : \", x_unlabel.shape)\n",
        "print(\"Y Unlable Shape : \", y_unlabel.shape)\n",
        "print(\"X Test Shape : \", x_test.shape)\n",
        "print(\"Y Test Shape : \", y_test.shape)\n",
        "\n",
        "def custom_loss(y_true , y_pred , y_weak , y_strong) : \n",
        "  alpha = 1 \n",
        "  threshold = 0.9\n",
        "  y_weak_new = []\n",
        "  y_strong_new = []\n",
        "  ### Now getting only the y_weak with greater than threshold \n",
        "  for i in range(len(y_weak)) : \n",
        "    val = np.argmax(y_weak[i])\n",
        "    if  y_weak[i][val] >= threshold :\n",
        "      ### Creating Pseudo Label\n",
        "      val = np.argmax(y_weak[i])\n",
        "      y_pseudo = np.array([0 for j in range(len(y_weak[i]))])\n",
        "      y_pseudo[val] = 1 \n",
        "      ### Appending data to y_weak\n",
        "      y_weak_new.append(y_pseudo)\n",
        "      y_strong_new.append(y_strong[i])\n",
        "\n",
        "  y_weak = np.array(y_weak_new)\n",
        "  y_strong = np.array(y_strong_new)\n",
        "        \n",
        "  cateogrical_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  supervised_loss = cateogrical_cross_entropy(y_true , y_pred)\n",
        "\n",
        "  if y_weak.size !=  0 : \n",
        "    unsupervised_loss = cateogrical_cross_entropy(y_weak , y_strong)\n",
        "    custom_loss = alpha * unsupervised_loss + supervised_loss\n",
        "\n",
        "  else : \n",
        "    custom_loss = supervised_loss\n",
        "\n",
        "  return custom_loss\n",
        "\n",
        "def custom_loss_test(y_true , y_pred) : \n",
        "  cateogrical_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  loss = cateogrical_cross_entropy(y_true , y_pred)\n",
        "  return loss\n",
        "\n",
        "\n",
        "for epoch in range(epochs) : \n",
        "  print(\"Epoch : \" , epoch + 1 , end = \" \")\n",
        "  ### Time \n",
        "  start_time = time.time()\n",
        "  ### Dataset\n",
        "  x_label , y_label = shuffle(x_label , y_label)\n",
        "  x_unlabel = shuffle(x_unlabel)\n",
        "  x_unlabels =  tf.data.Dataset.from_tensor_slices(x_unlabel)\n",
        "  x_unlabels_weak = x_unlabels.map(tf_random_rotate_image_weak)\n",
        "  x_unlabels_strong = x_unlabels.map(tf_random_rotate_image_strong)\n",
        "  labels = tf.data.Dataset.from_tensor_slices((x_label , y_label))\n",
        "  unlabels = tf.data.Dataset.zip((x_unlabels_weak , x_unlabels_strong))\n",
        "  train_dataset = tf.data.Dataset.zip((labels , unlabels)).batch(500)\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices((x_test , y_test)).batch(500)\n",
        "  \n",
        "  for steps  , (labels , unlabels) in enumerate(train_dataset) : \n",
        "    batch_losses = []\n",
        "    with tf.GradientTape() as tape : \n",
        "      logs_labels = model(labels[0] , training = True )\n",
        "      logs_unlabels_weak = model(unlabels[0] , training = False )\n",
        "      logs_unlabels_strong = model(unlabels[1] , training = False )\n",
        "\n",
        "      loss = custom_loss(labels[1] , logs_labels , logs_unlabels_weak , logs_unlabels_strong)\n",
        "      batch_losses.append(loss.numpy())\n",
        "      train_acc_metric.update_state(labels[1] , logs_labels)\n",
        "\n",
        "    \n",
        "    grads = tape.gradient(loss , model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads , model.trainable_variables))\n",
        "    \n",
        "\n",
        "  test_batch_losses = []\n",
        "  for x_test_dash , y_test_dash in test_dataset : \n",
        "    y_predict = model(x_test_dash , training = False )\n",
        "    loss = custom_loss_test(y_test_dash , y_predict)\n",
        "    test_batch_losses.append(loss.numpy())\n",
        "    ### Testing Accuracy\n",
        "    test_acc_metric.update_state(y_test_dash , y_predict)\n",
        "\n",
        "  ### Time End for Epoch\n",
        "  end_time = time.time()\n",
        "  train_acc = train_acc_metric.result()\n",
        "  test_acc = test_acc_metric.result()\n",
        "  print(\"Training acc: %4.f\" % (float(train_acc),) , end = \" \")\n",
        "  print(\"Test acc: %.4f\" % (float(test_acc),) , end = \" \")\n",
        "  print(\"Training Loss : \" , np.mean(batch_losses) , end = \" \")\n",
        "  print(\"Test Loss : \" , np.mean(test_batch_losses) , end = \" \")\n",
        "  print(\"Time : \" , end_time - start_time )\n",
        "  train_acc_metric.reset_states()\n",
        "  test_acc_metric.reset_states()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Train Shape :  (50000, 32, 32, 3)\n",
            "Y Train Shape : (50000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 1)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 552,874\n",
            "Trainable params: 551,722\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n",
            "X Train Shape :  (50000, 32, 32, 3)\n",
            "Y Train Shape :  (50000, 1)\n",
            "X Label Shape :  (40000, 32, 32, 3)\n",
            "Y Label Shape :  (40000, 1)\n",
            "X UnLabel Shape :  (10000, 32, 32, 3)\n",
            "Y UnLabel Shape :  (10000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 1)\n",
            "Y_Label Shape :  (40000, 10)\n",
            "Y_Test Shape :  (10000, 10)\n",
            "Y Train Shape :  (50000, 10)\n",
            "X Label Shape :  (40000, 32, 32, 3)\n",
            "Y Label Shape :  (40000, 10)\n",
            "X Unlabel Shape :  (10000, 32, 32, 3)\n",
            "Y Unlable Shape :  (10000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 10)\n",
            "Epoch :  1 Training acc:    0 Test acc: 0.1214 Training Loss :  3.8227942 Test Loss :  3.675457 Time :  31.610883951187134\n",
            "Epoch :  2 Training acc:    0 Test acc: 0.1761 Training Loss :  2.130044 Test Loss :  2.5697625 Time :  31.267732620239258\n",
            "Epoch :  3 Training acc:    0 Test acc: 0.2373 Training Loss :  1.982936 Test Loss :  2.3333569 Time :  30.972865343093872\n",
            "Epoch :  4 Training acc:    0 Test acc: 0.2347 Training Loss :  1.7305503 Test Loss :  2.3064103 Time :  31.126566410064697\n",
            "Epoch :  5 Training acc:    0 Test acc: 0.2579 Training Loss :  1.6770327 Test Loss :  2.434078 Time :  30.93067193031311\n",
            "Epoch :  6 Training acc:    0 Test acc: 0.2430 Training Loss :  1.5523516 Test Loss :  2.41684 Time :  31.22252869606018\n",
            "Epoch :  7 Training acc:    0 Test acc: 0.2623 Training Loss :  1.4683717 Test Loss :  2.2529445 Time :  31.051796197891235\n",
            "Epoch :  8 Training acc:    0 Test acc: 0.2779 Training Loss :  1.4190639 Test Loss :  2.2638547 Time :  31.09795331954956\n",
            "Epoch :  9 Training acc:    1 Test acc: 0.2677 Training Loss :  3.4972367 Test Loss :  2.3121939 Time :  31.15723967552185\n",
            "Epoch :  10 Training acc:    1 Test acc: 0.2673 Training Loss :  1.313256 Test Loss :  2.377615 Time :  31.07449436187744\n",
            "Epoch :  11 Training acc:    1 Test acc: 0.2790 Training Loss :  3.4828186 Test Loss :  2.3391986 Time :  30.76962900161743\n",
            "Epoch :  12 Training acc:    1 Test acc: 0.3350 Training Loss :  3.3292549 Test Loss :  2.1474957 Time :  30.80640196800232\n",
            "Epoch :  13 Training acc:    1 Test acc: 0.3631 Training Loss :  2.9250588 Test Loss :  1.974932 Time :  30.70365834236145\n",
            "Epoch :  14 Training acc:    1 Test acc: 0.3692 Training Loss :  3.1079664 Test Loss :  1.8887641 Time :  31.583327293395996\n",
            "Epoch :  15 Training acc:    1 Test acc: 0.4216 Training Loss :  3.1382556 Test Loss :  1.6992207 Time :  32.54752039909363\n",
            "Epoch :  16 Training acc:    1 Test acc: 0.4672 Training Loss :  2.9778929 Test Loss :  1.5403366 Time :  32.366798639297485\n",
            "Epoch :  17 Training acc:    1 Test acc: 0.5113 Training Loss :  3.018395 Test Loss :  1.4555523 Time :  32.62661910057068\n",
            "Epoch :  18 Training acc:    1 Test acc: 0.5059 Training Loss :  3.0054898 Test Loss :  1.3959372 Time :  31.967769384384155\n",
            "Epoch :  19 Training acc:    1 Test acc: 0.5318 Training Loss :  2.9730966 Test Loss :  1.3858417 Time :  32.0359992980957\n",
            "Epoch :  20 Training acc:    1 Test acc: 0.5886 Training Loss :  3.1339138 Test Loss :  1.1931832 Time :  31.884446382522583\n",
            "Epoch :  21 Training acc:    1 Test acc: 0.5989 Training Loss :  2.9236684 Test Loss :  1.1422077 Time :  32.607836961746216\n",
            "Epoch :  22 Training acc:    1 Test acc: 0.6129 Training Loss :  2.8614693 Test Loss :  1.091958 Time :  31.97636914253235\n",
            "Epoch :  23 Training acc:    1 Test acc: 0.6266 Training Loss :  2.981882 Test Loss :  1.053034 Time :  32.015023946762085\n",
            "Epoch :  24 Training acc:    1 Test acc: 0.6452 Training Loss :  3.0362668 Test Loss :  1.0036011 Time :  31.994956254959106\n",
            "Epoch :  25 Training acc:    1 Test acc: 0.6541 Training Loss :  2.9276395 Test Loss :  0.96905166 Time :  32.024524211883545\n",
            "Epoch :  26 Training acc:    1 Test acc: 0.6812 Training Loss :  2.966574 Test Loss :  0.8965105 Time :  31.845904111862183\n",
            "Epoch :  27 Training acc:    1 Test acc: 0.6878 Training Loss :  2.9230084 Test Loss :  0.8733591 Time :  32.205628633499146\n",
            "Epoch :  28 Training acc:    1 Test acc: 0.6702 Training Loss :  2.7847178 Test Loss :  0.93677664 Time :  32.47289490699768\n",
            "Epoch :  29 Training acc:    1 Test acc: 0.6872 Training Loss :  2.9642177 Test Loss :  0.8810657 Time :  32.48792815208435\n",
            "Epoch :  30 Training acc:    1 Test acc: 0.6748 Training Loss :  2.8585963 Test Loss :  0.92321837 Time :  32.32908582687378\n",
            "Epoch :  31 Training acc:    1 Test acc: 0.7149 Training Loss :  2.944047 Test Loss :  0.80256 Time :  32.7267370223999\n",
            "Epoch :  32 Training acc:    1 Test acc: 0.7217 Training Loss :  2.8047962 Test Loss :  0.7860761 Time :  32.41952133178711\n",
            "Epoch :  33 Training acc:    1 Test acc: 0.7195 Training Loss :  2.8461776 Test Loss :  0.78791535 Time :  32.66253662109375\n",
            "Epoch :  34 Training acc:    1 Test acc: 0.7197 Training Loss :  2.8512425 Test Loss :  0.7981999 Time :  32.630990982055664\n",
            "Epoch :  35 Training acc:    1 Test acc: 0.7271 Training Loss :  2.7683632 Test Loss :  0.77644557 Time :  32.607776165008545\n",
            "Epoch :  36 Training acc:    1 Test acc: 0.7170 Training Loss :  2.8310921 Test Loss :  0.80286235 Time :  32.74779987335205\n",
            "Epoch :  37 Training acc:    1 Test acc: 0.7235 Training Loss :  2.898262 Test Loss :  0.7807868 Time :  32.562588930130005\n",
            "Epoch :  38 Training acc:    1 Test acc: 0.7405 Training Loss :  2.8547902 Test Loss :  0.73890144 Time :  32.44455289840698\n",
            "Epoch :  39 Training acc:    1 Test acc: 0.7301 Training Loss :  2.7426205 Test Loss :  0.77511513 Time :  32.53751564025879\n",
            "Epoch :  40 Training acc:    1 Test acc: 0.7383 Training Loss :  2.7937646 Test Loss :  0.7402933 Time :  33.27318549156189\n",
            "Epoch :  41 Training acc:    1 Test acc: 0.7454 Training Loss :  2.6280046 Test Loss :  0.72279704 Time :  32.624980211257935\n",
            "Epoch :  42 Training acc:    1 Test acc: 0.7336 Training Loss :  2.7777941 Test Loss :  0.7666565 Time :  32.6554069519043\n",
            "Epoch :  43 Training acc:    1 Test acc: 0.7408 Training Loss :  2.7763638 Test Loss :  0.7408757 Time :  32.73080921173096\n",
            "Epoch :  44 Training acc:    1 Test acc: 0.7354 Training Loss :  2.7458737 Test Loss :  0.7588026 Time :  32.8813374042511\n",
            "Epoch :  45 Training acc:    1 Test acc: 0.7435 Training Loss :  2.6667788 Test Loss :  0.736937 Time :  32.90608763694763\n",
            "Epoch :  46 Training acc:    1 Test acc: 0.7422 Training Loss :  2.5859544 Test Loss :  0.7328644 Time :  32.98646020889282\n",
            "Epoch :  47 Training acc:    1 Test acc: 0.7499 Training Loss :  2.7130053 Test Loss :  0.7093385 Time :  32.850460052490234\n",
            "Epoch :  48 Training acc:    1 Test acc: 0.7417 Training Loss :  2.6997225 Test Loss :  0.74873435 Time :  32.761127948760986\n",
            "Epoch :  49 Training acc:    1 Test acc: 0.7589 Training Loss :  2.6929293 Test Loss :  0.7050548 Time :  32.70942258834839\n",
            "Epoch :  50 Training acc:    1 Test acc: 0.7596 Training Loss :  2.631746 Test Loss :  0.6841012 Time :  33.161670446395874\n",
            "Epoch :  51 Training acc:    1 Test acc: 0.7558 Training Loss :  2.60309 Test Loss :  0.70523256 Time :  32.926427364349365\n",
            "Epoch :  52 Training acc:    1 Test acc: 0.7573 Training Loss :  2.654045 Test Loss :  0.6815687 Time :  33.15729880332947\n",
            "Epoch :  53 Training acc:    1 Test acc: 0.7462 Training Loss :  2.587093 Test Loss :  0.7347199 Time :  32.962870597839355\n",
            "Epoch :  54 Training acc:    1 Test acc: 0.7681 Training Loss :  2.7316222 Test Loss :  0.660076 Time :  33.01527237892151\n",
            "Epoch :  55 Training acc:    1 Test acc: 0.7637 Training Loss :  2.7540603 Test Loss :  0.67961776 Time :  32.702502727508545\n",
            "Epoch :  56 Training acc:    1 Test acc: 0.7669 Training Loss :  2.6572874 Test Loss :  0.66285914 Time :  32.821537494659424\n",
            "Epoch :  57 Training acc:    1 Test acc: 0.7750 Training Loss :  2.621895 Test Loss :  0.6382245 Time :  32.54220247268677\n",
            "Epoch :  58 Training acc:    1 Test acc: 0.7691 Training Loss :  2.6567266 Test Loss :  0.6699207 Time :  32.85318422317505\n",
            "Epoch :  59 Training acc:    1 Test acc: 0.7775 Training Loss :  2.707915 Test Loss :  0.64801484 Time :  33.20019507408142\n",
            "Epoch :  60 Training acc:    1 Test acc: 0.7660 Training Loss :  2.6244555 Test Loss :  0.68814725 Time :  32.882516384124756\n",
            "Epoch :  61 Training acc:    1 Test acc: 0.7752 Training Loss :  2.6499705 Test Loss :  0.6453808 Time :  32.91100335121155\n",
            "Epoch :  62 Training acc:    1 Test acc: 0.7756 Training Loss :  2.6310062 Test Loss :  0.6386555 Time :  32.7992947101593\n",
            "Epoch :  63 Training acc:    1 Test acc: 0.7567 Training Loss :  2.599101 Test Loss :  0.70793205 Time :  32.9079954624176\n",
            "Epoch :  64 Training acc:    1 Test acc: 0.7289 Training Loss :  2.5695362 Test Loss :  0.8098813 Time :  32.89475607872009\n",
            "Epoch :  65 Training acc:    1 Test acc: 0.7582 Training Loss :  2.5134873 Test Loss :  0.7154461 Time :  32.907435178756714\n",
            "Epoch :  66 Training acc:    1 Test acc: 0.7705 Training Loss :  2.64227 Test Loss :  0.6615863 Time :  32.8748562335968\n",
            "Epoch :  67 Training acc:    1 Test acc: 0.7699 Training Loss :  2.5290318 Test Loss :  0.6742166 Time :  33.04597806930542\n",
            "Epoch :  68 Training acc:    1 Test acc: 0.7826 Training Loss :  2.603515 Test Loss :  0.6127133 Time :  32.911527156829834\n",
            "Epoch :  69 Training acc:    1 Test acc: 0.7849 Training Loss :  2.5025916 Test Loss :  0.61611235 Time :  33.114891052246094\n",
            "Epoch :  70 Training acc:    1 Test acc: 0.7812 Training Loss :  2.5058298 Test Loss :  0.6364734 Time :  33.133286476135254\n",
            "Epoch :  71 Training acc:    1 Test acc: 0.7791 Training Loss :  2.5561805 Test Loss :  0.6494614 Time :  33.15349626541138\n",
            "Epoch :  72 Training acc:    1 Test acc: 0.7937 Training Loss :  2.4973114 Test Loss :  0.5990922 Time :  33.199867486953735\n",
            "Epoch :  73 Training acc:    1 Test acc: 0.7852 Training Loss :  2.5472078 Test Loss :  0.62062144 Time :  33.24324154853821\n",
            "Epoch :  74 Training acc:    1 Test acc: 0.7754 Training Loss :  2.575251 Test Loss :  0.664309 Time :  33.16998648643494\n",
            "Epoch :  75 Training acc:    1 Test acc: 0.7884 Training Loss :  2.568251 Test Loss :  0.62200737 Time :  33.175480365753174\n",
            "Epoch :  76 Training acc:    1 Test acc: 0.7937 Training Loss :  2.4677632 Test Loss :  0.59761786 Time :  32.925029277801514\n",
            "Epoch :  77 Training acc:    1 Test acc: 0.7749 Training Loss :  2.5785155 Test Loss :  0.66794693 Time :  32.87770700454712\n",
            "Epoch :  78 Training acc:    1 Test acc: 0.7956 Training Loss :  2.5005136 Test Loss :  0.5929632 Time :  33.35306167602539\n",
            "Epoch :  79 Training acc:    1 Test acc: 0.7867 Training Loss :  2.5692654 Test Loss :  0.63692206 Time :  32.994874477386475\n",
            "Epoch :  80 Training acc:    1 Test acc: 0.7685 Training Loss :  2.4383545 Test Loss :  0.6974985 Time :  33.20231366157532\n",
            "Epoch :  81 Training acc:    1 Test acc: 0.7969 Training Loss :  2.5690792 Test Loss :  0.58792365 Time :  32.965182304382324\n",
            "Epoch :  82 Training acc:    1 Test acc: 0.8018 Training Loss :  2.5729263 Test Loss :  0.5791742 Time :  33.54941964149475\n",
            "Epoch :  83 Training acc:    1 Test acc: 0.7728 Training Loss :  2.5242214 Test Loss :  0.675098 Time :  34.11252570152283\n",
            "Epoch :  84 Training acc:    1 Test acc: 0.8015 Training Loss :  2.4408247 Test Loss :  0.5908629 Time :  33.97137141227722\n",
            "Epoch :  85 Training acc:    1 Test acc: 0.8011 Training Loss :  2.481745 Test Loss :  0.5770965 Time :  33.41619253158569\n",
            "Epoch :  86 Training acc:    1 Test acc: 0.7984 Training Loss :  2.5209155 Test Loss :  0.6086112 Time :  32.85074543952942\n",
            "Epoch :  87 Training acc:    1 Test acc: 0.7932 Training Loss :  2.5237105 Test Loss :  0.618018 Time :  32.872687578201294\n",
            "Epoch :  88 Training acc:    1 Test acc: 0.7996 Training Loss :  2.4260254 Test Loss :  0.6008936 Time :  32.94972276687622\n",
            "Epoch :  89 Training acc:    1 Test acc: 0.7998 Training Loss :  2.5264406 Test Loss :  0.5809421 Time :  32.8018524646759\n",
            "Epoch :  90 Training acc:    1 Test acc: 0.8066 Training Loss :  2.494154 Test Loss :  0.56759244 Time :  32.700276374816895\n",
            "Epoch :  91 Training acc:    1 Test acc: 0.8089 Training Loss :  2.5349855 Test Loss :  0.5737979 Time :  33.17915105819702\n",
            "Epoch :  92 Training acc:    1 Test acc: 0.7902 Training Loss :  2.4782038 Test Loss :  0.61741126 Time :  33.27279496192932\n",
            "Epoch :  93 Training acc:    1 Test acc: 0.7987 Training Loss :  2.4731598 Test Loss :  0.60137075 Time :  33.002033948898315\n",
            "Epoch :  94 Training acc:    1 Test acc: 0.8044 Training Loss :  2.349492 Test Loss :  0.58606553 Time :  33.079304695129395\n",
            "Epoch :  95 Training acc:    1 Test acc: 0.8044 Training Loss :  2.493262 Test Loss :  0.5807018 Time :  32.90295457839966\n",
            "Epoch :  96 Training acc:    1 Test acc: 0.7983 Training Loss :  2.4771416 Test Loss :  0.61890805 Time :  33.01296544075012\n",
            "Epoch :  97 Training acc:    1 Test acc: 0.8018 Training Loss :  2.3869889 Test Loss :  0.59918004 Time :  33.33380365371704\n",
            "Epoch :  98 Training acc:    1 Test acc: 0.8162 Training Loss :  2.452824 Test Loss :  0.55453026 Time :  33.23825979232788\n",
            "Epoch :  99 Training acc:    1 Test acc: 0.8009 Training Loss :  2.4701564 Test Loss :  0.61126024 Time :  33.106844425201416\n",
            "Epoch :  100 Training acc:    1 Test acc: 0.8132 Training Loss :  2.496862 Test Loss :  0.56077564 Time :  33.306830406188965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOVzQxKRerj2"
      },
      "source": [
        "# Model Training - 2nd\n",
        "Adam , Threshold 0.9 ,  VGG Modified , 0.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3Uuqct9peYg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1426aec-011b-48b8-ebbf-c64b218b9496"
      },
      "source": [
        "def custom_cifar10_data(img_rows, img_cols):\n",
        "\n",
        "    # Load cifar10 training and validation sets\n",
        "    (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
        "\n",
        "    # Resize training images\n",
        "    X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:,:,:,:]])\n",
        "    X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:,:,:,:]])\n",
        "\n",
        "    # Transform targets to keras compatible format\n",
        "    Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
        "    Y_valid = np_utils.to_categorical(Y_valid, num_classes)\n",
        "    \n",
        "    X_train = X_train.astype('float32')\n",
        "    X_valid = X_valid.astype('float32')\n",
        "\n",
        "    # preprocess data\n",
        "    X_train = X_train / 255.0\n",
        "    X_valid = X_valid / 255.0\n",
        "\n",
        "    return X_train, Y_train, X_valid, Y_valid\n",
        "\n",
        "(x_train , y_train) , (x_test , y_test) = cifar10.load_data() \n",
        "print('X Train Shape : ' , x_train.shape)\n",
        "print('Y Train Shape :' , y_train.shape)\n",
        "print('X Test Shape : ' , x_test.shape)\n",
        "print('Y Test Shape : ' , y_test.shape)\n",
        "\n",
        "### Normalize the dataset\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "    \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "    \n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "   \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "x_train , y_train = shuffle(x_train , y_train)\n",
        "x_test , y_test = shuffle(x_test , y_test)\n",
        "x_label , x_unlabel , y_label , y_unlabel = train_test_split(x_train , y_train , test_size = 0.3 , random_state = 42)\n",
        "print(\"X Train Shape : \" , x_train.shape)\n",
        "print(\"Y Train Shape : \" , y_train.shape)\n",
        "print(\"X Label Shape : \" , x_label.shape)\n",
        "print(\"Y Label Shape : \" , y_label.shape)\n",
        "print(\"X UnLabel Shape : \" , x_unlabel.shape)\n",
        "print(\"Y UnLabel Shape : \" , y_unlabel.shape)\n",
        "print(\"X Test Shape : \"  , x_test.shape)\n",
        "print(\"Y Test Shape : \" , y_test.shape)\n",
        "\n",
        "### Label Enocding to One - Hot Encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder_obj = OneHotEncoder(handle_unknown = 'ignore')\n",
        "y_label = encoder_obj.fit_transform(y_label).toarray()\n",
        "print(\"Y_Label Shape : \" , y_label.shape)\n",
        "y_test = encoder_obj.fit_transform(y_test).toarray()\n",
        "print(\"Y_Test Shape : \" , y_test.shape)\n",
        "y_train = encoder_obj.fit_transform(y_train).toarray()\n",
        "print(\"Y Train Shape : \" , y_train.shape)\n",
        "\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "### Random augmentation wrapper\n",
        "def random_rotate_image_strong(image):\n",
        "  randAug = RandAugment(2 , 6)\n",
        "  image = randAug.__call__(array_to_img(image))\n",
        "  image = img_to_array(image)\n",
        "  return image\n",
        "def tf_random_rotate_image_strong(image):\n",
        "  im_shape = image.shape\n",
        "  [image,] = tf.py_function(random_rotate_image_strong, [image], [tf.float32])\n",
        "  image.set_shape(im_shape)\n",
        "  return image/255.0\n",
        "### Weak augmentation wrapper\n",
        "def random_rotate_image_weak(image):\n",
        "  #image = ndimage.rotate(image, np.random.uniform(-30, 30), reshape=False)\n",
        "  weak_aug = WeakAugment(3)\n",
        "  image = weak_aug.__call__(array_to_img(image))\n",
        "  image = img_to_array(image)\n",
        "  return image\n",
        "def tf_random_rotate_image_weak(image):\n",
        "  im_shape = image.shape\n",
        "  [image,] = tf.py_function(random_rotate_image_weak, [image], [tf.float32])\n",
        "  image.set_shape(im_shape)\n",
        "  return image/255.0  \n",
        "\n",
        "model = model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "test_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "### Getting the shape\n",
        "print(\"X Label Shape : \" , x_label.shape)\n",
        "print(\"Y Label Shape : \" , y_label.shape)\n",
        "print(\"X Unlabel Shape : \", x_unlabel.shape)\n",
        "print(\"Y Unlable Shape : \", y_unlabel.shape)\n",
        "print(\"X Test Shape : \", x_test.shape)\n",
        "print(\"Y Test Shape : \", y_test.shape)\n",
        "\n",
        "def custom_loss(y_true , y_pred , y_weak , y_strong) : \n",
        "  alpha = 1 \n",
        "  threshold = 0.9\n",
        "  y_weak_new = []\n",
        "  y_strong_new = []\n",
        "  ### Now getting only the y_weak with greater than threshold \n",
        "  for i in range(len(y_weak)) : \n",
        "    val = np.argmax(y_weak[i])\n",
        "    if  y_weak[i][val] >= threshold :\n",
        "      ### Creating Pseudo Label\n",
        "      val = np.argmax(y_weak[i])\n",
        "      y_pseudo = np.array([0 for j in range(len(y_weak[i]))])\n",
        "      y_pseudo[val] = 1 \n",
        "      ### Appending data to y_weak\n",
        "      y_weak_new.append(y_pseudo)\n",
        "      y_strong_new.append(y_strong[i])\n",
        "\n",
        "  y_weak = np.array(y_weak_new)\n",
        "  y_strong = np.array(y_strong_new)\n",
        "        \n",
        "  cateogrical_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  supervised_loss = cateogrical_cross_entropy(y_true , y_pred)\n",
        "\n",
        "  if y_weak.size !=  0 : \n",
        "    unsupervised_loss = cateogrical_cross_entropy(y_weak , y_strong)\n",
        "    custom_loss = alpha * unsupervised_loss + supervised_loss\n",
        "\n",
        "  else : \n",
        "    custom_loss = supervised_loss\n",
        "\n",
        "  return custom_loss\n",
        "\n",
        "def custom_loss_test(y_true , y_pred) : \n",
        "  cateogrical_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  loss = cateogrical_cross_entropy(y_true , y_pred)\n",
        "  return loss\n",
        "\n",
        "\n",
        "for epoch in range(epochs) : \n",
        "  print(\"Epoch : \" , epoch + 1 , end = \" \")\n",
        "  ### Time \n",
        "  start_time = time.time()\n",
        "  ### Dataset\n",
        "  x_label , y_label = shuffle(x_label , y_label)\n",
        "  x_unlabel = shuffle(x_unlabel)\n",
        "  x_unlabels =  tf.data.Dataset.from_tensor_slices(x_unlabel)\n",
        "  x_unlabels_weak = x_unlabels.map(tf_random_rotate_image_weak)\n",
        "  x_unlabels_strong = x_unlabels.map(tf_random_rotate_image_strong)\n",
        "  labels = tf.data.Dataset.from_tensor_slices((x_label , y_label))\n",
        "  unlabels = tf.data.Dataset.zip((x_unlabels_weak , x_unlabels_strong))\n",
        "  train_dataset = tf.data.Dataset.zip((labels , unlabels)).batch(500)\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices((x_test , y_test)).batch(500)\n",
        "  \n",
        "  for steps  , (labels , unlabels) in enumerate(train_dataset) : \n",
        "    batch_losses = []\n",
        "    with tf.GradientTape() as tape : \n",
        "      logs_labels = model(labels[0] , training = True )\n",
        "      logs_unlabels_weak = model(unlabels[0] , training = False )\n",
        "      logs_unlabels_strong = model(unlabels[1] , training = False )\n",
        "\n",
        "      loss = custom_loss(labels[1] , logs_labels , logs_unlabels_weak , logs_unlabels_strong)\n",
        "      batch_losses.append(loss.numpy())\n",
        "      train_acc_metric.update_state(labels[1] , logs_labels)\n",
        "\n",
        "    \n",
        "    grads = tape.gradient(loss , model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads , model.trainable_variables))\n",
        "    \n",
        "\n",
        "  test_batch_losses = []\n",
        "  for x_test_dash , y_test_dash in test_dataset : \n",
        "    y_predict = model(x_test_dash , training = False )\n",
        "    loss = custom_loss_test(y_test_dash , y_predict)\n",
        "    test_batch_losses.append(loss.numpy())\n",
        "    ### Testing Accuracy\n",
        "    test_acc_metric.update_state(y_test_dash , y_predict)\n",
        "\n",
        "  ### Time End for Epoch\n",
        "  end_time = time.time()\n",
        "  train_acc = train_acc_metric.result()\n",
        "  test_acc = test_acc_metric.result()\n",
        "  print(\"Training acc: %4.f\" % (float(train_acc),) , end = \" \")\n",
        "  print(\"Test acc: %.4f\" % (float(test_acc),) , end = \" \")\n",
        "  print(\"Training Loss : \" , np.mean(batch_losses) , end = \" \")\n",
        "  print(\"Test Loss : \" , np.mean(test_batch_losses) , end = \" \")\n",
        "  print(\"Time : \" , end_time - start_time )\n",
        "  train_acc_metric.reset_states()\n",
        "  test_acc_metric.reset_states()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Train Shape :  (50000, 32, 32, 3)\n",
            "Y Train Shape : (50000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 1)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 552,874\n",
            "Trainable params: 551,722\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n",
            "X Train Shape :  (50000, 32, 32, 3)\n",
            "Y Train Shape :  (50000, 1)\n",
            "X Label Shape :  (35000, 32, 32, 3)\n",
            "Y Label Shape :  (35000, 1)\n",
            "X UnLabel Shape :  (15000, 32, 32, 3)\n",
            "Y UnLabel Shape :  (15000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 1)\n",
            "Y_Label Shape :  (35000, 10)\n",
            "Y_Test Shape :  (10000, 10)\n",
            "Y Train Shape :  (50000, 10)\n",
            "X Label Shape :  (35000, 32, 32, 3)\n",
            "Y Label Shape :  (35000, 10)\n",
            "X Unlabel Shape :  (15000, 32, 32, 3)\n",
            "Y Unlable Shape :  (15000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 10)\n",
            "Epoch :  1 Training acc:    0 Test acc: 0.1983 Training Loss :  2.0753725 Test Loss :  2.24769 Time :  77.85305714607239\n",
            "Epoch :  2 Training acc:    0 Test acc: 0.2019 Training Loss :  1.7581878 Test Loss :  2.389402 Time :  47.30498266220093\n",
            "Epoch :  3 Training acc:    0 Test acc: 0.1579 Training Loss :  1.6489955 Test Loss :  2.6613805 Time :  46.561582803726196\n",
            "Epoch :  4 Training acc:    0 Test acc: 0.1416 Training Loss :  1.4666318 Test Loss :  3.0137584 Time :  46.892082929611206\n",
            "Epoch :  5 Training acc:    0 Test acc: 0.1415 Training Loss :  1.6030025 Test Loss :  3.0563962 Time :  46.644490242004395\n",
            "Epoch :  6 Training acc:    0 Test acc: 0.1520 Training Loss :  3.3016045 Test Loss :  3.019262 Time :  46.673014640808105\n",
            "Epoch :  7 Training acc:    1 Test acc: 0.2261 Training Loss :  1.2863516 Test Loss :  2.4573698 Time :  46.39376139640808\n",
            "Epoch :  8 Training acc:    1 Test acc: 0.2784 Training Loss :  1.2150115 Test Loss :  2.2380402 Time :  46.94521164894104\n",
            "Epoch :  9 Training acc:    1 Test acc: 0.3986 Training Loss :  3.3205338 Test Loss :  1.7677237 Time :  46.668872356414795\n",
            "Epoch :  10 Training acc:    1 Test acc: 0.4168 Training Loss :  3.223754 Test Loss :  1.6594315 Time :  47.239484786987305\n",
            "Epoch :  11 Training acc:    1 Test acc: 0.4822 Training Loss :  3.2115264 Test Loss :  1.448359 Time :  47.03101086616516\n",
            "Epoch :  12 Training acc:    1 Test acc: 0.5040 Training Loss :  2.9660695 Test Loss :  1.3892962 Time :  47.35113286972046\n",
            "Epoch :  13 Training acc:    1 Test acc: 0.5412 Training Loss :  2.980893 Test Loss :  1.2594571 Time :  47.19998025894165\n",
            "Epoch :  14 Training acc:    1 Test acc: 0.5790 Training Loss :  2.987938 Test Loss :  1.1715552 Time :  47.34816908836365\n",
            "Epoch :  15 Training acc:    1 Test acc: 0.6256 Training Loss :  2.819212 Test Loss :  1.0421997 Time :  47.387579917907715\n",
            "Epoch :  16 Training acc:    1 Test acc: 0.6475 Training Loss :  2.8783634 Test Loss :  0.985005 Time :  47.61928629875183\n",
            "Epoch :  17 Training acc:    1 Test acc: 0.6966 Training Loss :  2.8061755 Test Loss :  0.87053025 Time :  47.44930028915405\n",
            "Epoch :  18 Training acc:    1 Test acc: 0.7055 Training Loss :  2.8871057 Test Loss :  0.846841 Time :  47.810296297073364\n",
            "Epoch :  19 Training acc:    1 Test acc: 0.7108 Training Loss :  2.7476828 Test Loss :  0.82925624 Time :  47.89309358596802\n",
            "Epoch :  20 Training acc:    1 Test acc: 0.7264 Training Loss :  2.806042 Test Loss :  0.79130596 Time :  47.75661540031433\n",
            "Epoch :  21 Training acc:    1 Test acc: 0.7220 Training Loss :  2.6922047 Test Loss :  0.8071332 Time :  48.12822985649109\n",
            "Epoch :  22 Training acc:    1 Test acc: 0.7301 Training Loss :  2.756844 Test Loss :  0.76829827 Time :  47.77524924278259\n",
            "Epoch :  23 Training acc:    1 Test acc: 0.7274 Training Loss :  2.8101463 Test Loss :  0.77928615 Time :  48.116013526916504\n",
            "Epoch :  24 Training acc:    1 Test acc: 0.7356 Training Loss :  2.7245314 Test Loss :  0.7509736 Time :  48.35764002799988\n",
            "Epoch :  25 Training acc:    1 Test acc: 0.7388 Training Loss :  2.7721715 Test Loss :  0.7411917 Time :  48.553255796432495\n",
            "Epoch :  26 Training acc:    1 Test acc: 0.7495 Training Loss :  2.7127898 Test Loss :  0.71505314 Time :  48.6485378742218\n",
            "Epoch :  27 Training acc:    1 Test acc: 0.7422 Training Loss :  2.7564273 Test Loss :  0.74633867 Time :  49.019694805145264\n",
            "Epoch :  28 Training acc:    1 Test acc: 0.7480 Training Loss :  2.630451 Test Loss :  0.7332602 Time :  48.781888246536255\n",
            "Epoch :  29 Training acc:    1 Test acc: 0.7514 Training Loss :  2.7727885 Test Loss :  0.7140632 Time :  48.58244872093201\n",
            "Epoch :  30 Training acc:    1 Test acc: 0.7531 Training Loss :  2.6317515 Test Loss :  0.7062718 Time :  48.611721992492676\n",
            "Epoch :  31 Training acc:    1 Test acc: 0.7597 Training Loss :  2.6479473 Test Loss :  0.6862402 Time :  48.88930153846741\n",
            "Epoch :  32 Training acc:    1 Test acc: 0.7636 Training Loss :  2.5573118 Test Loss :  0.68353444 Time :  48.73169445991516\n",
            "Epoch :  33 Training acc:    1 Test acc: 0.7647 Training Loss :  2.6970851 Test Loss :  0.67202 Time :  48.62927556037903\n",
            "Epoch :  34 Training acc:    1 Test acc: 0.7647 Training Loss :  2.5512025 Test Loss :  0.6714066 Time :  48.953391790390015\n",
            "Epoch :  35 Training acc:    1 Test acc: 0.7643 Training Loss :  2.5703926 Test Loss :  0.6811391 Time :  48.756845235824585\n",
            "Epoch :  36 Training acc:    1 Test acc: 0.7593 Training Loss :  2.660019 Test Loss :  0.6861781 Time :  49.060001373291016\n",
            "Epoch :  37 Training acc:    1 Test acc: 0.7580 Training Loss :  2.6454961 Test Loss :  0.71146417 Time :  48.98504281044006\n",
            "Epoch :  38 Training acc:    1 Test acc: 0.7682 Training Loss :  2.6966708 Test Loss :  0.66362727 Time :  49.17609238624573\n",
            "Epoch :  39 Training acc:    1 Test acc: 0.7709 Training Loss :  2.5507042 Test Loss :  0.66608626 Time :  49.12452578544617\n",
            "Epoch :  40 Training acc:    1 Test acc: 0.7758 Training Loss :  2.5906577 Test Loss :  0.6496631 Time :  49.41978693008423\n",
            "Epoch :  41 Training acc:    1 Test acc: 0.7856 Training Loss :  2.7115636 Test Loss :  0.6312667 Time :  49.424248933792114\n",
            "Epoch :  42 Training acc:    1 Test acc: 0.7794 Training Loss :  2.5034778 Test Loss :  0.63674676 Time :  49.19471573829651\n",
            "Epoch :  43 Training acc:    1 Test acc: 0.7712 Training Loss :  2.5327194 Test Loss :  0.6757954 Time :  49.5326452255249\n",
            "Epoch :  44 Training acc:    1 Test acc: 0.7873 Training Loss :  2.4600008 Test Loss :  0.6391051 Time :  50.06219506263733\n",
            "Epoch :  45 Training acc:    1 Test acc: 0.7927 Training Loss :  2.4983563 Test Loss :  0.616256 Time :  50.46371412277222\n",
            "Epoch :  46 Training acc:    1 Test acc: 0.7901 Training Loss :  2.5916018 Test Loss :  0.60994804 Time :  49.95781087875366\n",
            "Epoch :  47 Training acc:    1 Test acc: 0.7906 Training Loss :  2.516817 Test Loss :  0.62018645 Time :  49.53099536895752\n",
            "Epoch :  48 Training acc:    1 Test acc: 0.7979 Training Loss :  2.5516984 Test Loss :  0.6060262 Time :  49.76339340209961\n",
            "Epoch :  49 Training acc:    1 Test acc: 0.7889 Training Loss :  2.5541816 Test Loss :  0.6341244 Time :  49.52837777137756\n",
            "Epoch :  50 Training acc:    1 Test acc: 0.7779 Training Loss :  2.564029 Test Loss :  0.66379154 Time :  49.70277786254883\n",
            "Epoch :  51 Training acc:    1 Test acc: 0.7937 Training Loss :  2.3913476 Test Loss :  0.6075723 Time :  49.63910937309265\n",
            "Epoch :  52 Training acc:    1 Test acc: 0.8001 Training Loss :  2.455635 Test Loss :  0.6125237 Time :  49.71177315711975\n",
            "Epoch :  53 Training acc:    1 Test acc: 0.8058 Training Loss :  2.433814 Test Loss :  0.57673174 Time :  50.25537037849426\n",
            "Epoch :  54 Training acc:    1 Test acc: 0.8046 Training Loss :  2.4194133 Test Loss :  0.59112734 Time :  49.853800535202026\n",
            "Epoch :  55 Training acc:    1 Test acc: 0.8049 Training Loss :  2.5076742 Test Loss :  0.58911324 Time :  49.9809250831604\n",
            "Epoch :  56 Training acc:    1 Test acc: 0.7967 Training Loss :  2.504239 Test Loss :  0.6145335 Time :  50.20632863044739\n",
            "Epoch :  57 Training acc:    1 Test acc: 0.8028 Training Loss :  2.487132 Test Loss :  0.60876405 Time :  49.96053695678711\n",
            "Epoch :  58 Training acc:    1 Test acc: 0.7994 Training Loss :  2.4984221 Test Loss :  0.61124814 Time :  50.202388525009155\n",
            "Epoch :  59 Training acc:    1 Test acc: 0.8040 Training Loss :  2.4474764 Test Loss :  0.60044855 Time :  50.35853958129883\n",
            "Epoch :  60 Training acc:    1 Test acc: 0.8043 Training Loss :  2.5106177 Test Loss :  0.59296876 Time :  50.12792253494263\n",
            "Epoch :  61 Training acc:    1 Test acc: 0.8097 Training Loss :  2.465058 Test Loss :  0.580412 Time :  50.0003981590271\n",
            "Epoch :  62 Training acc:    1 Test acc: 0.7814 Training Loss :  2.3969593 Test Loss :  0.7144493 Time :  50.2868230342865\n",
            "Epoch :  63 Training acc:    1 Test acc: 0.7936 Training Loss :  2.393487 Test Loss :  0.63341475 Time :  50.459352254867554\n",
            "Epoch :  64 Training acc:    1 Test acc: 0.8161 Training Loss :  2.3481493 Test Loss :  0.558978 Time :  50.295764446258545\n",
            "Epoch :  65 Training acc:    1 Test acc: 0.8069 Training Loss :  2.4214034 Test Loss :  0.5927739 Time :  50.588897466659546\n",
            "Epoch :  66 Training acc:    1 Test acc: 0.8162 Training Loss :  2.4744692 Test Loss :  0.5706929 Time :  50.460306882858276\n",
            "Epoch :  67 Training acc:    1 Test acc: 0.7814 Training Loss :  2.4363706 Test Loss :  0.6944324 Time :  50.54368591308594\n",
            "Epoch :  68 Training acc:    1 Test acc: 0.8179 Training Loss :  2.362628 Test Loss :  0.56366175 Time :  50.594051122665405\n",
            "Epoch :  69 Training acc:    1 Test acc: 0.8212 Training Loss :  2.362455 Test Loss :  0.5653077 Time :  50.49548268318176\n",
            "Epoch :  70 Training acc:    1 Test acc: 0.8199 Training Loss :  2.3320906 Test Loss :  0.56695247 Time :  50.49326181411743\n",
            "Epoch :  71 Training acc:    1 Test acc: 0.8153 Training Loss :  2.3813999 Test Loss :  0.5916034 Time :  50.52376961708069\n",
            "Epoch :  72 Training acc:    1 Test acc: 0.8181 Training Loss :  2.4055824 Test Loss :  0.57984114 Time :  50.458646059036255\n",
            "Epoch :  73 Training acc:    1 Test acc: 0.8144 Training Loss :  2.3080077 Test Loss :  0.60196453 Time :  50.27400803565979\n",
            "Epoch :  74 Training acc:    1 Test acc: 0.8096 Training Loss :  2.3641334 Test Loss :  0.60786307 Time :  50.743279695510864\n",
            "Epoch :  75 Training acc:    1 Test acc: 0.8215 Training Loss :  2.3673496 Test Loss :  0.5704759 Time :  50.58012628555298\n",
            "Epoch :  76 Training acc:    1 Test acc: 0.8203 Training Loss :  2.4127798 Test Loss :  0.57918346 Time :  50.42612314224243\n",
            "Epoch :  77 Training acc:    1 Test acc: 0.8125 Training Loss :  2.3189769 Test Loss :  0.60282254 Time :  50.78810429573059\n",
            "Epoch :  78 Training acc:    1 Test acc: 0.8194 Training Loss :  2.3720584 Test Loss :  0.58228207 Time :  50.89403247833252\n",
            "Epoch :  79 Training acc:    1 Test acc: 0.8194 Training Loss :  2.2753203 Test Loss :  0.5823539 Time :  51.3501455783844\n",
            "Epoch :  80 Training acc:    1 Test acc: 0.8177 Training Loss :  2.3840961 Test Loss :  0.5898142 Time :  50.902260065078735\n",
            "Epoch :  81 Training acc:    1 Test acc: 0.8183 Training Loss :  2.4005253 Test Loss :  0.6028638 Time :  50.89993953704834\n",
            "Epoch :  82 Training acc:    1 Test acc: 0.8192 Training Loss :  2.3932648 Test Loss :  0.5948174 Time :  51.10138726234436\n",
            "Epoch :  83 Training acc:    1 Test acc: 0.8266 Training Loss :  2.374504 Test Loss :  0.5671237 Time :  50.56311058998108\n",
            "Epoch :  84 Training acc:    1 Test acc: 0.8161 Training Loss :  2.3828917 Test Loss :  0.5947191 Time :  51.3594765663147\n",
            "Epoch :  85 Training acc:    1 Test acc: 0.8110 Training Loss :  2.3201373 Test Loss :  0.6334899 Time :  50.92235255241394\n",
            "Epoch :  86 Training acc:    1 Test acc: 0.8225 Training Loss :  2.341333 Test Loss :  0.59252805 Time :  51.228726625442505\n",
            "Epoch :  87 Training acc:    1 Test acc: 0.8235 Training Loss :  2.34916 Test Loss :  0.5869756 Time :  50.99744272232056\n",
            "Epoch :  88 Training acc:    1 Test acc: 0.8240 Training Loss :  2.365534 Test Loss :  0.590978 Time :  50.94196033477783\n",
            "Epoch :  89 Training acc:    1 Test acc: 0.8149 Training Loss :  2.2703195 Test Loss :  0.62192166 Time :  51.115807056427\n",
            "Epoch :  90 Training acc:    1 Test acc: 0.8245 Training Loss :  2.320179 Test Loss :  0.5864518 Time :  51.37088131904602\n",
            "Epoch :  91 Training acc:    1 Test acc: 0.8223 Training Loss :  2.4036295 Test Loss :  0.5908102 Time :  51.11036443710327\n",
            "Epoch :  92 Training acc:    1 Test acc: 0.8253 Training Loss :  2.339038 Test Loss :  0.56604207 Time :  50.87339401245117\n",
            "Epoch :  93 Training acc:    1 Test acc: 0.8216 Training Loss :  2.277397 Test Loss :  0.6235187 Time :  50.95375919342041\n",
            "Epoch :  94 Training acc:    1 Test acc: 0.8258 Training Loss :  2.2590017 Test Loss :  0.5803219 Time :  50.98997473716736\n",
            "Epoch :  95 Training acc:    1 Test acc: 0.8269 Training Loss :  2.2510526 Test Loss :  0.5810088 Time :  51.149837493896484\n",
            "Epoch :  96 Training acc:    1 Test acc: 0.8203 Training Loss :  2.3668675 Test Loss :  0.61825573 Time :  51.474876403808594\n",
            "Epoch :  97 Training acc:    1 Test acc: 0.8316 Training Loss :  2.3387198 Test Loss :  0.5732669 Time :  51.22892761230469\n",
            "Epoch :  98 Training acc:    1 Test acc: 0.8216 Training Loss :  2.2853978 Test Loss :  0.6141551 Time :  51.304959535598755\n",
            "Epoch :  99 Training acc:    1 Test acc: 0.8244 Training Loss :  2.2787368 Test Loss :  0.61240315 Time :  50.78307032585144\n",
            "Epoch :  100 Training acc:    1 Test acc: 0.8258 Training Loss :  2.333962 Test Loss :  0.6106385 Time :  51.13757848739624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT2QHFQWbTxQ"
      },
      "source": [
        "# Model Training - 2nd\n",
        "Adam , Threshold 0.9 ,  VGG Modified , 0.4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKfpHI2ObTRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3cff4f-c9da-463f-8db8-2cb8b6edefb6"
      },
      "source": [
        "def custom_cifar10_data(img_rows, img_cols):\n",
        "\n",
        "    # Load cifar10 training and validation sets\n",
        "    (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
        "\n",
        "    # Resize training images\n",
        "    X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:,:,:,:]])\n",
        "    X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:,:,:,:]])\n",
        "\n",
        "    # Transform targets to keras compatible format\n",
        "    Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
        "    Y_valid = np_utils.to_categorical(Y_valid, num_classes)\n",
        "    \n",
        "    X_train = X_train.astype('float32')\n",
        "    X_valid = X_valid.astype('float32')\n",
        "\n",
        "    # preprocess data\n",
        "    X_train = X_train / 255.0\n",
        "    X_valid = X_valid / 255.0\n",
        "\n",
        "    return X_train, Y_train, X_valid, Y_valid\n",
        "\n",
        "(x_train , y_train) , (x_test , y_test) = cifar10.load_data() \n",
        "print('X Train Shape : ' , x_train.shape)\n",
        "print('Y Train Shape :' , y_train.shape)\n",
        "print('X Test Shape : ' , x_test.shape)\n",
        "print('Y Test Shape : ' , y_test.shape)\n",
        "\n",
        "### Normalize the dataset\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "    \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "    \n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "   \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "x_train , y_train = shuffle(x_train , y_train)\n",
        "x_test , y_test = shuffle(x_test , y_test)\n",
        "x_label , x_unlabel , y_label , y_unlabel = train_test_split(x_train , y_train , test_size = 0.4 , random_state = 42)\n",
        "print(\"X Train Shape : \" , x_train.shape)\n",
        "print(\"Y Train Shape : \" , y_train.shape)\n",
        "print(\"X Label Shape : \" , x_label.shape)\n",
        "print(\"Y Label Shape : \" , y_label.shape)\n",
        "print(\"X UnLabel Shape : \" , x_unlabel.shape)\n",
        "print(\"Y UnLabel Shape : \" , y_unlabel.shape)\n",
        "print(\"X Test Shape : \"  , x_test.shape)\n",
        "print(\"Y Test Shape : \" , y_test.shape)\n",
        "\n",
        "### Label Enocding to One - Hot Encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder_obj = OneHotEncoder(handle_unknown = 'ignore')\n",
        "y_label = encoder_obj.fit_transform(y_label).toarray()\n",
        "print(\"Y_Label Shape : \" , y_label.shape)\n",
        "y_test = encoder_obj.fit_transform(y_test).toarray()\n",
        "print(\"Y_Test Shape : \" , y_test.shape)\n",
        "y_train = encoder_obj.fit_transform(y_train).toarray()\n",
        "print(\"Y Train Shape : \" , y_train.shape)\n",
        "\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "### Random augmentation wrapper\n",
        "def random_rotate_image_strong(image):\n",
        "  randAug = RandAugment(2 , 6)\n",
        "  image = randAug.__call__(array_to_img(image))\n",
        "  image = img_to_array(image)\n",
        "  return image\n",
        "def tf_random_rotate_image_strong(image):\n",
        "  im_shape = image.shape\n",
        "  [image,] = tf.py_function(random_rotate_image_strong, [image], [tf.float32])\n",
        "  image.set_shape(im_shape)\n",
        "  return image/255.0\n",
        "### Weak augmentation wrapper\n",
        "def random_rotate_image_weak(image):\n",
        "  #image = ndimage.rotate(image, np.random.uniform(-30, 30), reshape=False)\n",
        "  weak_aug = WeakAugment(3)\n",
        "  image = weak_aug.__call__(array_to_img(image))\n",
        "  image = img_to_array(image)\n",
        "  return image\n",
        "def tf_random_rotate_image_weak(image):\n",
        "  im_shape = image.shape\n",
        "  [image,] = tf.py_function(random_rotate_image_weak, [image], [tf.float32])\n",
        "  image.set_shape(im_shape)\n",
        "  return image/255.0  \n",
        "\n",
        "model = model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "test_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "### Getting the shape\n",
        "print(\"X Label Shape : \" , x_label.shape)\n",
        "print(\"Y Label Shape : \" , y_label.shape)\n",
        "print(\"X Unlabel Shape : \", x_unlabel.shape)\n",
        "print(\"Y Unlable Shape : \", y_unlabel.shape)\n",
        "print(\"X Test Shape : \", x_test.shape)\n",
        "print(\"Y Test Shape : \", y_test.shape)\n",
        "\n",
        "def custom_loss(y_true , y_pred , y_weak , y_strong) : \n",
        "  alpha = 1 \n",
        "  threshold = 0.9\n",
        "  y_weak_new = []\n",
        "  y_strong_new = []\n",
        "  ### Now getting only the y_weak with greater than threshold \n",
        "  for i in range(len(y_weak)) : \n",
        "    val = np.argmax(y_weak[i])\n",
        "    if  y_weak[i][val] >= threshold :\n",
        "      ### Creating Pseudo Label\n",
        "      val = np.argmax(y_weak[i])\n",
        "      y_pseudo = np.array([0 for j in range(len(y_weak[i]))])\n",
        "      y_pseudo[val] = 1 \n",
        "      ### Appending data to y_weak\n",
        "      y_weak_new.append(y_pseudo)\n",
        "      y_strong_new.append(y_strong[i])\n",
        "\n",
        "  y_weak = np.array(y_weak_new)\n",
        "  y_strong = np.array(y_strong_new)\n",
        "        \n",
        "  cateogrical_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  supervised_loss = cateogrical_cross_entropy(y_true , y_pred)\n",
        "\n",
        "  if y_weak.size !=  0 : \n",
        "    unsupervised_loss = cateogrical_cross_entropy(y_weak , y_strong)\n",
        "    custom_loss = alpha * unsupervised_loss + supervised_loss\n",
        "\n",
        "  else : \n",
        "    custom_loss = supervised_loss\n",
        "\n",
        "  return custom_loss\n",
        "\n",
        "def custom_loss_test(y_true , y_pred) : \n",
        "  cateogrical_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  loss = cateogrical_cross_entropy(y_true , y_pred)\n",
        "  return loss\n",
        "\n",
        "\n",
        "for epoch in range(epochs) : \n",
        "  print(\"Epoch : \" , epoch + 1 , end = \" \")\n",
        "  ### Time \n",
        "  start_time = time.time()\n",
        "  ### Dataset\n",
        "  x_label , y_label = shuffle(x_label , y_label)\n",
        "  x_unlabel = shuffle(x_unlabel)\n",
        "  x_unlabels =  tf.data.Dataset.from_tensor_slices(x_unlabel)\n",
        "  x_unlabels_weak = x_unlabels.map(tf_random_rotate_image_weak)\n",
        "  x_unlabels_strong = x_unlabels.map(tf_random_rotate_image_strong)\n",
        "  labels = tf.data.Dataset.from_tensor_slices((x_label , y_label))\n",
        "  unlabels = tf.data.Dataset.zip((x_unlabels_weak , x_unlabels_strong))\n",
        "  train_dataset = tf.data.Dataset.zip((labels , unlabels)).batch(500)\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices((x_test , y_test)).batch(500)\n",
        "  \n",
        "  for steps  , (labels , unlabels) in enumerate(train_dataset) : \n",
        "    batch_losses = []\n",
        "    with tf.GradientTape() as tape : \n",
        "      logs_labels = model(labels[0] , training = True )\n",
        "      logs_unlabels_weak = model(unlabels[0] , training = False )\n",
        "      logs_unlabels_strong = model(unlabels[1] , training = False )\n",
        "\n",
        "      loss = custom_loss(labels[1] , logs_labels , logs_unlabels_weak , logs_unlabels_strong)\n",
        "      batch_losses.append(loss.numpy())\n",
        "      train_acc_metric.update_state(labels[1] , logs_labels)\n",
        "\n",
        "    \n",
        "    grads = tape.gradient(loss , model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads , model.trainable_variables))\n",
        "    \n",
        "\n",
        "  test_batch_losses = []\n",
        "  for x_test_dash , y_test_dash in test_dataset : \n",
        "    y_predict = model(x_test_dash , training = False )\n",
        "    loss = custom_loss_test(y_test_dash , y_predict)\n",
        "    test_batch_losses.append(loss.numpy())\n",
        "    ### Testing Accuracy\n",
        "    test_acc_metric.update_state(y_test_dash , y_predict)\n",
        "\n",
        "  ### Time End for Epoch\n",
        "  end_time = time.time()\n",
        "  train_acc = train_acc_metric.result()\n",
        "  test_acc = test_acc_metric.result()\n",
        "  print(\"Training acc: %4.f\" % (float(train_acc),) , end = \" \")\n",
        "  print(\"Test acc: %.4f\" % (float(test_acc),) , end = \" \")\n",
        "  print(\"Training Loss : \" , np.mean(batch_losses) , end = \" \")\n",
        "  print(\"Test Loss : \" , np.mean(test_batch_losses) , end = \" \")\n",
        "  print(\"Time : \" , end_time - start_time )\n",
        "  train_acc_metric.reset_states()\n",
        "  test_acc_metric.reset_states()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Train Shape :  (50000, 32, 32, 3)\n",
            "Y Train Shape : (50000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 1)\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 552,874\n",
            "Trainable params: 551,722\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n",
            "X Train Shape :  (50000, 32, 32, 3)\n",
            "Y Train Shape :  (50000, 1)\n",
            "X Label Shape :  (30000, 32, 32, 3)\n",
            "Y Label Shape :  (30000, 1)\n",
            "X UnLabel Shape :  (20000, 32, 32, 3)\n",
            "Y UnLabel Shape :  (20000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 1)\n",
            "Y_Label Shape :  (30000, 10)\n",
            "Y_Test Shape :  (10000, 10)\n",
            "Y Train Shape :  (50000, 10)\n",
            "X Label Shape :  (30000, 32, 32, 3)\n",
            "Y Label Shape :  (30000, 10)\n",
            "X Unlabel Shape :  (20000, 32, 32, 3)\n",
            "Y Unlable Shape :  (20000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 10)\n",
            "Epoch :  1 Training acc:    0 Test acc: 0.2048 Training Loss :  1.8920081 Test Loss :  2.1725585 Time :  59.99012613296509\n",
            "Epoch :  2 Training acc:    0 Test acc: 0.2038 Training Loss :  1.680069 Test Loss :  2.521517 Time :  60.410125732421875\n",
            "Epoch :  3 Training acc:    0 Test acc: 0.1816 Training Loss :  1.459384 Test Loss :  2.8302808 Time :  60.76345372200012\n",
            "Epoch :  4 Training acc:    0 Test acc: 0.1771 Training Loss :  1.4045492 Test Loss :  2.9825785 Time :  60.2439501285553\n",
            "Epoch :  5 Training acc:    1 Test acc: 0.2607 Training Loss :  1.3220134 Test Loss :  2.5653977 Time :  60.63565182685852\n",
            "Epoch :  6 Training acc:    1 Test acc: 0.2676 Training Loss :  1.1460267 Test Loss :  2.565806 Time :  61.21362090110779\n",
            "Epoch :  7 Training acc:    1 Test acc: 0.3354 Training Loss :  3.5655136 Test Loss :  2.2677534 Time :  61.62506818771362\n",
            "Epoch :  8 Training acc:    1 Test acc: 0.3733 Training Loss :  3.3438125 Test Loss :  2.089707 Time :  61.38106727600098\n",
            "Epoch :  9 Training acc:    1 Test acc: 0.4905 Training Loss :  3.0494714 Test Loss :  1.5008061 Time :  61.19264554977417\n",
            "Epoch :  10 Training acc:    1 Test acc: 0.4938 Training Loss :  2.945589 Test Loss :  1.5851362 Time :  61.94198966026306\n",
            "Epoch :  11 Training acc:    1 Test acc: 0.5854 Training Loss :  2.9144967 Test Loss :  1.1889579 Time :  62.48489236831665\n",
            "Epoch :  12 Training acc:    1 Test acc: 0.6158 Training Loss :  2.8728986 Test Loss :  1.1129311 Time :  62.677879095077515\n",
            "Epoch :  13 Training acc:    1 Test acc: 0.6619 Training Loss :  2.9704442 Test Loss :  0.9508365 Time :  62.61224937438965\n",
            "Epoch :  14 Training acc:    1 Test acc: 0.6653 Training Loss :  2.8567972 Test Loss :  0.9449202 Time :  63.036837100982666\n",
            "Epoch :  15 Training acc:    1 Test acc: 0.7021 Training Loss :  2.8400095 Test Loss :  0.8439988 Time :  63.312872648239136\n",
            "Epoch :  16 Training acc:    1 Test acc: 0.7151 Training Loss :  2.7906778 Test Loss :  0.82904017 Time :  63.39211559295654\n",
            "Epoch :  17 Training acc:    1 Test acc: 0.7294 Training Loss :  2.6957278 Test Loss :  0.78099495 Time :  63.9385621547699\n",
            "Epoch :  18 Training acc:    1 Test acc: 0.7349 Training Loss :  2.6375022 Test Loss :  0.76181614 Time :  63.96375393867493\n",
            "Epoch :  19 Training acc:    1 Test acc: 0.7260 Training Loss :  2.8130767 Test Loss :  0.78738296 Time :  64.1255214214325\n",
            "Epoch :  20 Training acc:    1 Test acc: 0.7331 Training Loss :  2.7265491 Test Loss :  0.7588857 Time :  64.4355354309082\n",
            "Epoch :  21 Training acc:    1 Test acc: 0.7427 Training Loss :  2.6338947 Test Loss :  0.74053967 Time :  65.07369232177734\n",
            "Epoch :  22 Training acc:    1 Test acc: 0.7523 Training Loss :  2.6184397 Test Loss :  0.717368 Time :  65.39911842346191\n",
            "Epoch :  23 Training acc:    1 Test acc: 0.7410 Training Loss :  2.7235608 Test Loss :  0.75929004 Time :  65.17166519165039\n",
            "Epoch :  24 Training acc:    1 Test acc: 0.7557 Training Loss :  2.572581 Test Loss :  0.705558 Time :  65.08037495613098\n",
            "Epoch :  25 Training acc:    1 Test acc: 0.7674 Training Loss :  2.6429315 Test Loss :  0.67732507 Time :  64.91921043395996\n",
            "Epoch :  26 Training acc:    1 Test acc: 0.7659 Training Loss :  2.6936245 Test Loss :  0.6733785 Time :  65.34679007530212\n",
            "Epoch :  27 Training acc:    1 Test acc: 0.7660 Training Loss :  2.647754 Test Loss :  0.6754055 Time :  65.00155067443848\n",
            "Epoch :  28 Training acc:    1 Test acc: 0.7769 Training Loss :  2.5544863 Test Loss :  0.65279377 Time :  65.72032117843628\n",
            "Epoch :  29 Training acc:    1 Test acc: 0.7701 Training Loss :  2.5223897 Test Loss :  0.692459 Time :  65.63615202903748\n",
            "Epoch :  30 Training acc:    1 Test acc: 0.7802 Training Loss :  2.5545015 Test Loss :  0.6609477 Time :  65.6903715133667\n",
            "Epoch :  31 Training acc:    1 Test acc: 0.7783 Training Loss :  2.488455 Test Loss :  0.6630365 Time :  65.96461200714111\n",
            "Epoch :  32 Training acc:    1 Test acc: 0.7668 Training Loss :  2.4722803 Test Loss :  0.6910505 Time :  66.40945243835449\n",
            "Epoch :  33 Training acc:    1 Test acc: 0.7598 Training Loss :  2.6010315 Test Loss :  0.71132195 Time :  65.88345742225647\n",
            "Epoch :  34 Training acc:    1 Test acc: 0.7937 Training Loss :  2.585392 Test Loss :  0.616666 Time :  66.09707951545715\n",
            "Epoch :  35 Training acc:    1 Test acc: 0.7830 Training Loss :  2.4548025 Test Loss :  0.6598145 Time :  66.04951643943787\n",
            "Epoch :  36 Training acc:    1 Test acc: 0.7909 Training Loss :  2.4153829 Test Loss :  0.6196009 Time :  66.54730582237244\n",
            "Epoch :  37 Training acc:    1 Test acc: 0.8009 Training Loss :  2.497022 Test Loss :  0.5984349 Time :  66.28323936462402\n",
            "Epoch :  38 Training acc:    1 Test acc: 0.7678 Training Loss :  2.4824243 Test Loss :  0.7293793 Time :  66.16368174552917\n",
            "Epoch :  39 Training acc:    1 Test acc: 0.7985 Training Loss :  2.4640517 Test Loss :  0.6086943 Time :  66.44437623023987\n",
            "Epoch :  40 Training acc:    1 Test acc: 0.7986 Training Loss :  2.4391842 Test Loss :  0.6106536 Time :  66.5535249710083\n",
            "Epoch :  41 Training acc:    1 Test acc: 0.8005 Training Loss :  2.3792446 Test Loss :  0.61956483 Time :  66.65192031860352\n",
            "Epoch :  42 Training acc:    1 Test acc: 0.8067 Training Loss :  2.4789677 Test Loss :  0.60814965 Time :  66.40630602836609\n",
            "Epoch :  43 Training acc:    1 Test acc: 0.7854 Training Loss :  2.5082386 Test Loss :  0.66211456 Time :  66.37713170051575\n",
            "Epoch :  44 Training acc:    1 Test acc: 0.7968 Training Loss :  2.3612077 Test Loss :  0.6331066 Time :  66.93973278999329\n",
            "Epoch :  45 Training acc:    1 Test acc: 0.7982 Training Loss :  2.4144669 Test Loss :  0.6341152 Time :  67.1185371875763\n",
            "Epoch :  46 Training acc:    1 Test acc: 0.8060 Training Loss :  2.4707487 Test Loss :  0.61552423 Time :  67.25242805480957\n",
            "Epoch :  47 Training acc:    1 Test acc: 0.8031 Training Loss :  2.4131947 Test Loss :  0.6170391 Time :  67.13795566558838\n",
            "Epoch :  48 Training acc:    1 Test acc: 0.8042 Training Loss :  2.2947187 Test Loss :  0.6188375 Time :  67.2343921661377\n",
            "Epoch :  49 Training acc:    1 Test acc: 0.8052 Training Loss :  2.4462774 Test Loss :  0.6200781 Time :  67.73818922042847\n",
            "Epoch :  50 Training acc:    1 Test acc: 0.8093 Training Loss :  2.3738956 Test Loss :  0.6015748 Time :  68.22454404830933\n",
            "Epoch :  51 Training acc:    1 Test acc: 0.8027 Training Loss :  2.4072168 Test Loss :  0.6117133 Time :  67.65517735481262\n",
            "Epoch :  52 Training acc:    1 Test acc: 0.8102 Training Loss :  2.3566165 Test Loss :  0.61903954 Time :  67.79359078407288\n",
            "Epoch :  53 Training acc:    1 Test acc: 0.8024 Training Loss :  2.402963 Test Loss :  0.6363464 Time :  68.38944482803345\n",
            "Epoch :  54 Training acc:    1 Test acc: 0.8110 Training Loss :  2.4300625 Test Loss :  0.6218435 Time :  68.16580295562744\n",
            "Epoch :  55 Training acc:    1 Test acc: 0.8140 Training Loss :  2.3565 Test Loss :  0.60983294 Time :  68.06034398078918\n",
            "Epoch :  56 Training acc:    1 Test acc: 0.8138 Training Loss :  2.3867755 Test Loss :  0.61342144 Time :  68.06264972686768\n",
            "Epoch :  57 Training acc:    1 Test acc: 0.8150 Training Loss :  2.415515 Test Loss :  0.6104383 Time :  67.7038083076477\n",
            "Epoch :  58 Training acc:    1 Test acc: 0.8025 Training Loss :  2.3811982 Test Loss :  0.65592617 Time :  67.95351028442383\n",
            "Epoch :  59 Training acc:    1 Test acc: 0.8095 Training Loss :  2.3686981 Test Loss :  0.6389108 Time :  68.58744549751282\n",
            "Epoch :  60 Training acc:    1 Test acc: 0.8131 Training Loss :  2.3263078 Test Loss :  0.6419064 Time :  68.09910583496094\n",
            "Epoch :  61 Training acc:    1 Test acc: 0.8145 Training Loss :  2.373519 Test Loss :  0.63050115 Time :  67.84373474121094\n",
            "Epoch :  62 Training acc:    1 Test acc: 0.8122 Training Loss :  2.2902703 Test Loss :  0.6195847 Time :  68.05863308906555\n",
            "Epoch :  63 Training acc:    1 Test acc: 0.7975 Training Loss :  2.334889 Test Loss :  0.6931752 Time :  67.93866181373596\n",
            "Epoch :  64 Training acc:    1 Test acc: 0.8072 Training Loss :  2.3466966 Test Loss :  0.6450036 Time :  68.18332886695862\n",
            "Epoch :  65 Training acc:    1 Test acc: 0.8134 Training Loss :  2.3011947 Test Loss :  0.6477166 Time :  68.82928824424744\n",
            "Epoch :  66 Training acc:    1 Test acc: 0.8180 Training Loss :  2.2863746 Test Loss :  0.61455286 Time :  68.43905520439148\n",
            "Epoch :  67 Training acc:    1 Test acc: 0.8109 Training Loss :  2.2815337 Test Loss :  0.6322003 Time :  68.74857354164124\n",
            "Epoch :  68 Training acc:    1 Test acc: 0.8147 Training Loss :  2.3193138 Test Loss :  0.64831865 Time :  68.73121070861816\n",
            "Epoch :  69 Training acc:    1 Test acc: 0.8167 Training Loss :  2.2936845 Test Loss :  0.6401258 Time :  68.61171650886536\n",
            "Epoch :  70 Training acc:    1 Test acc: 0.8169 Training Loss :  2.2705858 Test Loss :  0.62943786 Time :  68.37148404121399\n",
            "Epoch :  71 Training acc:    1 Test acc: 0.8174 Training Loss :  2.2506526 Test Loss :  0.63242304 Time :  68.58956050872803\n",
            "Epoch :  72 Training acc:    1 Test acc: 0.8178 Training Loss :  2.2757761 Test Loss :  0.626797 Time :  68.9456717967987\n",
            "Epoch :  73 Training acc:    1 Test acc: 0.8153 Training Loss :  2.414526 Test Loss :  0.6462425 Time :  68.85468888282776\n",
            "Epoch :  74 Training acc:    1 Test acc: 0.8132 Training Loss :  2.305082 Test Loss :  0.65039814 Time :  68.913419008255\n",
            "Epoch :  75 Training acc:    1 Test acc: 0.8194 Training Loss :  2.3121998 Test Loss :  0.64923775 Time :  68.85029625892639\n",
            "Epoch :  76 Training acc:    1 Test acc: 0.8187 Training Loss :  2.278208 Test Loss :  0.6502773 Time :  68.8140606880188\n",
            "Epoch :  77 Training acc:    1 Test acc: 0.8198 Training Loss :  2.2216508 Test Loss :  0.6220828 Time :  69.37112140655518\n",
            "Epoch :  78 Training acc:    1 Test acc: 0.8233 Training Loss :  2.201559 Test Loss :  0.62660605 Time :  68.91348218917847\n",
            "Epoch :  79 Training acc:    1 Test acc: 0.8078 Training Loss :  2.3395467 Test Loss :  0.71261626 Time :  69.1639633178711\n",
            "Epoch :  80 Training acc:    1 Test acc: 0.8228 Training Loss :  2.25942 Test Loss :  0.63067466 Time :  69.2061038017273\n",
            "Epoch :  81 Training acc:    1 Test acc: 0.8239 Training Loss :  2.2611046 Test Loss :  0.63810426 Time :  69.02109003067017\n",
            "Epoch :  82 Training acc:    1 Test acc: 0.8123 Training Loss :  2.3082616 Test Loss :  0.6888052 Time :  69.46165060997009\n",
            "Epoch :  83 Training acc:    1 Test acc: 0.8183 Training Loss :  2.360114 Test Loss :  0.6626273 Time :  69.38031125068665\n",
            "Epoch :  84 Training acc:    1 Test acc: 0.8217 Training Loss :  2.3209684 Test Loss :  0.64063746 Time :  69.09971833229065\n",
            "Epoch :  85 Training acc:    1 Test acc: 0.8200 Training Loss :  2.2449596 Test Loss :  0.65404844 Time :  69.10671663284302\n",
            "Epoch :  86 Training acc:    1 Test acc: 0.8205 Training Loss :  2.280565 Test Loss :  0.66128075 Time :  70.90643954277039\n",
            "Epoch :  87 Training acc:    1 Test acc: 0.8215 Training Loss :  2.2733252 Test Loss :  0.66170543 Time :  70.17329430580139\n",
            "Epoch :  88 Training acc:    1 Test acc: 0.8204 Training Loss :  2.257517 Test Loss :  0.67032045 Time :  69.6796019077301\n",
            "Epoch :  89 Training acc:    1 Test acc: 0.8212 Training Loss :  2.26016 Test Loss :  0.66361225 Time :  69.81144094467163\n",
            "Epoch :  90 Training acc:    1 Test acc: 0.8230 Training Loss :  2.2708373 Test Loss :  0.64934146 Time :  69.64670467376709\n",
            "Epoch :  91 Training acc:    1 Test acc: 0.8167 Training Loss :  2.2354522 Test Loss :  0.6754972 Time :  69.73814296722412\n",
            "Epoch :  92 Training acc:    1 Test acc: 0.8237 Training Loss :  2.290575 Test Loss :  0.6518239 Time :  69.36974620819092\n",
            "Epoch :  93 Training acc:    1 Test acc: 0.8217 Training Loss :  2.221981 Test Loss :  0.68357074 Time :  69.87220191955566\n",
            "Epoch :  94 Training acc:    1 Test acc: 0.8285 Training Loss :  2.2681556 Test Loss :  0.66235554 Time :  70.13871788978577\n",
            "Epoch :  95 Training acc:    1 Test acc: 0.8219 Training Loss :  2.185598 Test Loss :  0.6929488 Time :  70.83874011039734\n",
            "Epoch :  96 Training acc:    1 Test acc: 0.8214 Training Loss :  2.2415106 Test Loss :  0.6950294 Time :  70.3060348033905\n",
            "Epoch :  97 Training acc:    1 Test acc: 0.8257 Training Loss :  2.191008 Test Loss :  0.6723652 Time :  70.54883027076721\n",
            "Epoch :  98 Training acc:    1 Test acc: 0.8186 Training Loss :  2.1762853 Test Loss :  0.7179171 Time :  71.63045144081116\n",
            "Epoch :  99 Training acc:    1 Test acc: 0.8238 Training Loss :  2.2193866 Test Loss :  0.65906227 Time :  71.64249968528748\n",
            "Epoch :  100 Training acc:    1 Test acc: 0.8215 Training Loss :  2.216759 Test Loss :  0.6977274 Time :  71.38114285469055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvMIu9ZUbxUe"
      },
      "source": [
        "# Model Training - 2nd\n",
        "Adam , Threshold 0.9 ,  VGG Modified , 0.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQVBZNGvb3ft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e280da9-67fe-42f4-c339-122bf321ece3"
      },
      "source": [
        "def custom_cifar10_data(img_rows, img_cols):\n",
        "\n",
        "    # Load cifar10 training and validation sets\n",
        "    (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
        "\n",
        "    # Resize training images\n",
        "    X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:,:,:,:]])\n",
        "    X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:,:,:,:]])\n",
        "\n",
        "    # Transform targets to keras compatible format\n",
        "    Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
        "    Y_valid = np_utils.to_categorical(Y_valid, num_classes)\n",
        "    \n",
        "    X_train = X_train.astype('float32')\n",
        "    X_valid = X_valid.astype('float32')\n",
        "\n",
        "    # preprocess data\n",
        "    X_train = X_train / 255.0\n",
        "    X_valid = X_valid / 255.0\n",
        "\n",
        "    return X_train, Y_train, X_valid, Y_valid\n",
        "\n",
        "(x_train , y_train) , (x_test , y_test) = cifar10.load_data() \n",
        "print('X Train Shape : ' , x_train.shape)\n",
        "print('Y Train Shape :' , y_train.shape)\n",
        "print('X Test Shape : ' , x_test.shape)\n",
        "print('Y Test Shape : ' , y_test.shape)\n",
        "\n",
        "### Normalize the dataset\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "    \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "    \n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "   \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "x_train , y_train = shuffle(x_train , y_train)\n",
        "x_test , y_test = shuffle(x_test , y_test)\n",
        "x_label , x_unlabel , y_label , y_unlabel = train_test_split(x_train , y_train , test_size = 0.4 , random_state = 42)\n",
        "print(\"X Train Shape : \" , x_train.shape)\n",
        "print(\"Y Train Shape : \" , y_train.shape)\n",
        "print(\"X Label Shape : \" , x_label.shape)\n",
        "print(\"Y Label Shape : \" , y_label.shape)\n",
        "print(\"X UnLabel Shape : \" , x_unlabel.shape)\n",
        "print(\"Y UnLabel Shape : \" , y_unlabel.shape)\n",
        "print(\"X Test Shape : \"  , x_test.shape)\n",
        "print(\"Y Test Shape : \" , y_test.shape)\n",
        "\n",
        "### Label Enocding to One - Hot Encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder_obj = OneHotEncoder(handle_unknown = 'ignore')\n",
        "y_label = encoder_obj.fit_transform(y_label).toarray()\n",
        "print(\"Y_Label Shape : \" , y_label.shape)\n",
        "y_test = encoder_obj.fit_transform(y_test).toarray()\n",
        "print(\"Y_Test Shape : \" , y_test.shape)\n",
        "y_train = encoder_obj.fit_transform(y_train).toarray()\n",
        "print(\"Y Train Shape : \" , y_train.shape)\n",
        "\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "### Random augmentation wrapper\n",
        "def random_rotate_image_strong(image):\n",
        "  randAug = RandAugment(2 , 6)\n",
        "  image = randAug.__call__(array_to_img(image))\n",
        "  image = img_to_array(image)\n",
        "  return image\n",
        "def tf_random_rotate_image_strong(image):\n",
        "  im_shape = image.shape\n",
        "  [image,] = tf.py_function(random_rotate_image_strong, [image], [tf.float32])\n",
        "  image.set_shape(im_shape)\n",
        "  return image/255.0\n",
        "### Weak augmentation wrapper\n",
        "def random_rotate_image_weak(image):\n",
        "  #image = ndimage.rotate(image, np.random.uniform(-30, 30), reshape=False)\n",
        "  weak_aug = WeakAugment(3)\n",
        "  image = weak_aug.__call__(array_to_img(image))\n",
        "  image = img_to_array(image)\n",
        "  return image\n",
        "def tf_random_rotate_image_weak(image):\n",
        "  im_shape = image.shape\n",
        "  [image,] = tf.py_function(random_rotate_image_weak, [image], [tf.float32])\n",
        "  image.set_shape(im_shape)\n",
        "  return image/255.0  \n",
        "\n",
        "model = model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "test_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "### Getting the shape\n",
        "print(\"X Label Shape : \" , x_label.shape)\n",
        "print(\"Y Label Shape : \" , y_label.shape)\n",
        "print(\"X Unlabel Shape : \", x_unlabel.shape)\n",
        "print(\"Y Unlable Shape : \", y_unlabel.shape)\n",
        "print(\"X Test Shape : \", x_test.shape)\n",
        "print(\"Y Test Shape : \", y_test.shape)\n",
        "\n",
        "def custom_loss(y_true , y_pred , y_weak , y_strong) : \n",
        "  alpha = 1 \n",
        "  threshold = 0.9\n",
        "  y_weak_new = []\n",
        "  y_strong_new = []\n",
        "  ### Now getting only the y_weak with greater than threshold \n",
        "  for i in range(len(y_weak)) : \n",
        "    val = np.argmax(y_weak[i])\n",
        "    if  y_weak[i][val] >= threshold :\n",
        "      ### Creating Pseudo Label\n",
        "      val = np.argmax(y_weak[i])\n",
        "      y_pseudo = np.array([0 for j in range(len(y_weak[i]))])\n",
        "      y_pseudo[val] = 1 \n",
        "      ### Appending data to y_weak\n",
        "      y_weak_new.append(y_pseudo)\n",
        "      y_strong_new.append(y_strong[i])\n",
        "\n",
        "  y_weak = np.array(y_weak_new)\n",
        "  y_strong = np.array(y_strong_new)\n",
        "        \n",
        "  cateogrical_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  supervised_loss = cateogrical_cross_entropy(y_true , y_pred)\n",
        "\n",
        "  if y_weak.size !=  0 : \n",
        "    unsupervised_loss = cateogrical_cross_entropy(y_weak , y_strong)\n",
        "    custom_loss = alpha * unsupervised_loss + supervised_loss\n",
        "\n",
        "  else : \n",
        "    custom_loss = supervised_loss\n",
        "\n",
        "  return custom_loss\n",
        "\n",
        "def custom_loss_test(y_true , y_pred) : \n",
        "  cateogrical_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  loss = cateogrical_cross_entropy(y_true , y_pred)\n",
        "  return loss\n",
        "\n",
        "\n",
        "for epoch in range(epochs) : \n",
        "  print(\"Epoch : \" , epoch + 1 , end = \" \")\n",
        "  ### Time \n",
        "  start_time = time.time()\n",
        "  ### Dataset\n",
        "  x_label , y_label = shuffle(x_label , y_label)\n",
        "  x_unlabel = shuffle(x_unlabel)\n",
        "  x_unlabels =  tf.data.Dataset.from_tensor_slices(x_unlabel)\n",
        "  x_unlabels_weak = x_unlabels.map(tf_random_rotate_image_weak)\n",
        "  x_unlabels_strong = x_unlabels.map(tf_random_rotate_image_strong)\n",
        "  labels = tf.data.Dataset.from_tensor_slices((x_label , y_label))\n",
        "  unlabels = tf.data.Dataset.zip((x_unlabels_weak , x_unlabels_strong))\n",
        "  train_dataset = tf.data.Dataset.zip((labels , unlabels)).batch(500)\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices((x_test , y_test)).batch(500)\n",
        "  \n",
        "  for steps  , (labels , unlabels) in enumerate(train_dataset) : \n",
        "    batch_losses = []\n",
        "    with tf.GradientTape() as tape : \n",
        "      logs_labels = model(labels[0] , training = True )\n",
        "      logs_unlabels_weak = model(unlabels[0] , training = False )\n",
        "      logs_unlabels_strong = model(unlabels[1] , training = False )\n",
        "\n",
        "      loss = custom_loss(labels[1] , logs_labels , logs_unlabels_weak , logs_unlabels_strong)\n",
        "      batch_losses.append(loss.numpy())\n",
        "      train_acc_metric.update_state(labels[1] , logs_labels)\n",
        "\n",
        "    \n",
        "    grads = tape.gradient(loss , model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads , model.trainable_variables))\n",
        "    \n",
        "\n",
        "  test_batch_losses = []\n",
        "  for x_test_dash , y_test_dash in test_dataset : \n",
        "    y_predict = model(x_test_dash , training = False )\n",
        "    loss = custom_loss_test(y_test_dash , y_predict)\n",
        "    test_batch_losses.append(loss.numpy())\n",
        "    ### Testing Accuracy\n",
        "    test_acc_metric.update_state(y_test_dash , y_predict)\n",
        "\n",
        "  ### Time End for Epoch\n",
        "  end_time = time.time()\n",
        "  train_acc = train_acc_metric.result()\n",
        "  test_acc = test_acc_metric.result()\n",
        "  print(\"Training acc: %4.f\" % (float(train_acc),) , end = \" \")\n",
        "  print(\"Test acc: %.4f\" % (float(test_acc),) , end = \" \")\n",
        "  print(\"Training Loss : \" , np.mean(batch_losses) , end = \" \")\n",
        "  print(\"Test Loss : \" , np.mean(test_batch_losses) , end = \" \")\n",
        "  print(\"Time : \" , end_time - start_time )\n",
        "  train_acc_metric.reset_states()\n",
        "  test_acc_metric.reset_states()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Train Shape :  (50000, 32, 32, 3)\n",
            "Y Train Shape : (50000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 1)\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 552,874\n",
            "Trainable params: 551,722\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n",
            "X Train Shape :  (50000, 32, 32, 3)\n",
            "Y Train Shape :  (50000, 1)\n",
            "X Label Shape :  (30000, 32, 32, 3)\n",
            "Y Label Shape :  (30000, 1)\n",
            "X UnLabel Shape :  (20000, 32, 32, 3)\n",
            "Y UnLabel Shape :  (20000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 1)\n",
            "Y_Label Shape :  (30000, 10)\n",
            "Y_Test Shape :  (10000, 10)\n",
            "Y Train Shape :  (50000, 10)\n",
            "X Label Shape :  (30000, 32, 32, 3)\n",
            "Y Label Shape :  (30000, 10)\n",
            "X Unlabel Shape :  (20000, 32, 32, 3)\n",
            "Y Unlable Shape :  (20000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 10)\n",
            "Epoch :  1 Training acc:    0 Test acc: 0.1723 Training Loss :  1.938702 Test Loss :  2.5560613 Time :  62.95379900932312\n",
            "Epoch :  2 Training acc:    0 Test acc: 0.1413 Training Loss :  1.7175659 Test Loss :  3.5441298 Time :  62.58513021469116\n",
            "Epoch :  3 Training acc:    0 Test acc: 0.1516 Training Loss :  1.5447816 Test Loss :  3.6307197 Time :  62.34427785873413\n",
            "Epoch :  4 Training acc:    0 Test acc: 0.1813 Training Loss :  1.4026189 Test Loss :  3.5254726 Time :  62.4034423828125\n",
            "Epoch :  5 Training acc:    1 Test acc: 0.2114 Training Loss :  1.2924675 Test Loss :  3.2012124 Time :  62.133607149124146\n",
            "Epoch :  6 Training acc:    1 Test acc: 0.2076 Training Loss :  1.2066197 Test Loss :  3.2216015 Time :  62.123947620391846\n",
            "Epoch :  7 Training acc:    1 Test acc: 0.2344 Training Loss :  3.035533 Test Loss :  2.7751882 Time :  62.257654428482056\n",
            "Epoch :  8 Training acc:    1 Test acc: 0.3370 Training Loss :  2.5996323 Test Loss :  2.1256247 Time :  62.365190267562866\n",
            "Epoch :  9 Training acc:    1 Test acc: 0.4498 Training Loss :  2.759159 Test Loss :  1.6123184 Time :  62.884851694107056\n",
            "Epoch :  10 Training acc:    1 Test acc: 0.5112 Training Loss :  3.0213566 Test Loss :  1.3691509 Time :  63.05518865585327\n",
            "Epoch :  11 Training acc:    1 Test acc: 0.5814 Training Loss :  2.9974985 Test Loss :  1.1839088 Time :  63.212589263916016\n",
            "Epoch :  12 Training acc:    1 Test acc: 0.6249 Training Loss :  2.7659125 Test Loss :  1.0641232 Time :  63.67624235153198\n",
            "Epoch :  13 Training acc:    1 Test acc: 0.6631 Training Loss :  2.756537 Test Loss :  0.9618543 Time :  64.39432382583618\n",
            "Epoch :  14 Training acc:    1 Test acc: 0.6846 Training Loss :  2.8339043 Test Loss :  0.8868092 Time :  64.2474639415741\n",
            "Epoch :  15 Training acc:    1 Test acc: 0.6979 Training Loss :  2.8097346 Test Loss :  0.86791515 Time :  64.54303336143494\n",
            "Epoch :  16 Training acc:    1 Test acc: 0.6972 Training Loss :  2.7769153 Test Loss :  0.8612323 Time :  64.71277523040771\n",
            "Epoch :  17 Training acc:    1 Test acc: 0.7239 Training Loss :  2.8070583 Test Loss :  0.79297614 Time :  65.21742868423462\n",
            "Epoch :  18 Training acc:    1 Test acc: 0.7247 Training Loss :  2.6999092 Test Loss :  0.78614676 Time :  65.37931799888611\n",
            "Epoch :  19 Training acc:    1 Test acc: 0.7281 Training Loss :  2.7918289 Test Loss :  0.76977044 Time :  65.34322714805603\n",
            "Epoch :  20 Training acc:    1 Test acc: 0.7052 Training Loss :  2.6846077 Test Loss :  0.8425503 Time :  65.19066762924194\n",
            "Epoch :  21 Training acc:    1 Test acc: 0.7457 Training Loss :  2.68366 Test Loss :  0.7265408 Time :  65.18951654434204\n",
            "Epoch :  22 Training acc:    1 Test acc: 0.7477 Training Loss :  2.688002 Test Loss :  0.7335523 Time :  65.48376631736755\n",
            "Epoch :  23 Training acc:    1 Test acc: 0.7538 Training Loss :  2.7226446 Test Loss :  0.6979936 Time :  66.13938021659851\n",
            "Epoch :  24 Training acc:    1 Test acc: 0.7473 Training Loss :  2.6611435 Test Loss :  0.7360505 Time :  66.44973111152649\n",
            "Epoch :  25 Training acc:    1 Test acc: 0.7546 Training Loss :  2.5899372 Test Loss :  0.7018148 Time :  66.19699931144714\n",
            "Epoch :  26 Training acc:    1 Test acc: 0.7609 Training Loss :  2.6182394 Test Loss :  0.7017698 Time :  66.396803855896\n",
            "Epoch :  27 Training acc:    1 Test acc: 0.7621 Training Loss :  2.5808127 Test Loss :  0.69725245 Time :  66.9349114894867\n",
            "Epoch :  28 Training acc:    1 Test acc: 0.7611 Training Loss :  2.6796656 Test Loss :  0.7174097 Time :  67.26876902580261\n",
            "Epoch :  29 Training acc:    1 Test acc: 0.7629 Training Loss :  2.5266852 Test Loss :  0.70208794 Time :  67.02844071388245\n",
            "Epoch :  30 Training acc:    1 Test acc: 0.7637 Training Loss :  2.445249 Test Loss :  0.691713 Time :  66.65228915214539\n",
            "Epoch :  31 Training acc:    1 Test acc: 0.7779 Training Loss :  2.583364 Test Loss :  0.65183145 Time :  66.78330445289612\n",
            "Epoch :  32 Training acc:    1 Test acc: 0.7766 Training Loss :  2.5004528 Test Loss :  0.6640964 Time :  66.55956625938416\n",
            "Epoch :  33 Training acc:    1 Test acc: 0.7786 Training Loss :  2.584771 Test Loss :  0.65747845 Time :  67.07798981666565\n",
            "Epoch :  34 Training acc:    1 Test acc: 0.7744 Training Loss :  2.5250769 Test Loss :  0.6770546 Time :  67.4083366394043\n",
            "Epoch :  35 Training acc:    1 Test acc: 0.7875 Training Loss :  2.4455967 Test Loss :  0.6308762 Time :  66.81571578979492\n",
            "Epoch :  36 Training acc:    1 Test acc: 0.7868 Training Loss :  2.4944181 Test Loss :  0.6227555 Time :  67.41162848472595\n",
            "Epoch :  37 Training acc:    1 Test acc: 0.7908 Training Loss :  2.5095515 Test Loss :  0.6215183 Time :  67.5934407711029\n",
            "Epoch :  38 Training acc:    1 Test acc: 0.7865 Training Loss :  2.4595318 Test Loss :  0.63092315 Time :  67.4963231086731\n",
            "Epoch :  39 Training acc:    1 Test acc: 0.7857 Training Loss :  2.5202284 Test Loss :  0.6656991 Time :  67.2412621974945\n",
            "Epoch :  40 Training acc:    1 Test acc: 0.7949 Training Loss :  2.4569392 Test Loss :  0.6143587 Time :  67.15682363510132\n",
            "Epoch :  41 Training acc:    1 Test acc: 0.7953 Training Loss :  2.5001795 Test Loss :  0.63531864 Time :  67.15963101387024\n",
            "Epoch :  42 Training acc:    1 Test acc: 0.7912 Training Loss :  2.440689 Test Loss :  0.6215104 Time :  67.65057635307312\n",
            "Epoch :  43 Training acc:    1 Test acc: 0.8002 Training Loss :  2.4824924 Test Loss :  0.6010672 Time :  67.1598596572876\n",
            "Epoch :  44 Training acc:    1 Test acc: 0.7978 Training Loss :  2.3869703 Test Loss :  0.6181985 Time :  67.47301197052002\n",
            "Epoch :  45 Training acc:    1 Test acc: 0.8006 Training Loss :  2.4979599 Test Loss :  0.61343545 Time :  67.40779042243958\n",
            "Epoch :  46 Training acc:    1 Test acc: 0.7947 Training Loss :  2.445989 Test Loss :  0.64480615 Time :  67.73381853103638\n",
            "Epoch :  47 Training acc:    1 Test acc: 0.7897 Training Loss :  2.398809 Test Loss :  0.6545969 Time :  67.93139362335205\n",
            "Epoch :  48 Training acc:    1 Test acc: 0.8061 Training Loss :  2.4734862 Test Loss :  0.59771633 Time :  67.70138788223267\n",
            "Epoch :  49 Training acc:    1 Test acc: 0.8025 Training Loss :  2.4559166 Test Loss :  0.62399894 Time :  67.88286066055298\n",
            "Epoch :  50 Training acc:    1 Test acc: 0.8036 Training Loss :  2.3755834 Test Loss :  0.6223596 Time :  67.72979974746704\n",
            "Epoch :  51 Training acc:    1 Test acc: 0.8043 Training Loss :  2.3964744 Test Loss :  0.6107453 Time :  68.33296966552734\n",
            "Epoch :  52 Training acc:    1 Test acc: 0.8057 Training Loss :  2.4011543 Test Loss :  0.60848224 Time :  68.3595814704895\n",
            "Epoch :  53 Training acc:    1 Test acc: 0.8074 Training Loss :  2.507051 Test Loss :  0.60716236 Time :  68.12637066841125\n",
            "Epoch :  54 Training acc:    1 Test acc: 0.8095 Training Loss :  2.4173388 Test Loss :  0.6063111 Time :  68.17930507659912\n",
            "Epoch :  55 Training acc:    1 Test acc: 0.8108 Training Loss :  2.314611 Test Loss :  0.6227894 Time :  68.88388681411743\n",
            "Epoch :  56 Training acc:    1 Test acc: 0.8138 Training Loss :  2.3697689 Test Loss :  0.5920148 Time :  68.79678964614868\n",
            "Epoch :  57 Training acc:    1 Test acc: 0.8086 Training Loss :  2.3946342 Test Loss :  0.6228439 Time :  68.35409784317017\n",
            "Epoch :  58 Training acc:    1 Test acc: 0.8151 Training Loss :  2.3753343 Test Loss :  0.5996984 Time :  68.61410403251648\n",
            "Epoch :  59 Training acc:    1 Test acc: 0.8107 Training Loss :  2.385389 Test Loss :  0.6133262 Time :  68.85635089874268\n",
            "Epoch :  60 Training acc:    1 Test acc: 0.8104 Training Loss :  2.3725917 Test Loss :  0.647053 Time :  69.20018172264099\n",
            "Epoch :  61 Training acc:    1 Test acc: 0.8069 Training Loss :  2.4214854 Test Loss :  0.6412865 Time :  68.6921660900116\n",
            "Epoch :  62 Training acc:    1 Test acc: 0.7949 Training Loss :  2.350328 Test Loss :  0.69515 Time :  68.55075526237488\n",
            "Epoch :  63 Training acc:    1 Test acc: 0.8190 Training Loss :  2.384919 Test Loss :  0.6084331 Time :  69.08657383918762\n",
            "Epoch :  64 Training acc:    1 Test acc: 0.8063 Training Loss :  2.3988562 Test Loss :  0.6449042 Time :  70.15563726425171\n",
            "Epoch :  65 Training acc:    1 Test acc: 0.8112 Training Loss :  2.3270636 Test Loss :  0.62176365 Time :  69.65334177017212\n",
            "Epoch :  66 Training acc:    1 Test acc: 0.8171 Training Loss :  2.3345134 Test Loss :  0.61405027 Time :  69.63160109519958\n",
            "Epoch :  67 Training acc:    1 Test acc: 0.8178 Training Loss :  2.2974107 Test Loss :  0.61698383 Time :  69.60618042945862\n",
            "Epoch :  68 Training acc:    1 Test acc: 0.8208 Training Loss :  2.2834835 Test Loss :  0.61147964 Time :  69.70647764205933\n",
            "Epoch :  69 Training acc:    1 Test acc: 0.8241 Training Loss :  2.3487756 Test Loss :  0.6023537 Time :  69.39285087585449\n",
            "Epoch :  70 Training acc:    1 Test acc: 0.8229 Training Loss :  2.317494 Test Loss :  0.6028899 Time :  69.32211136817932\n",
            "Epoch :  71 Training acc:    1 Test acc: 0.8078 Training Loss :  2.2303557 Test Loss :  0.65739805 Time :  69.58879971504211\n",
            "Epoch :  72 Training acc:    1 Test acc: 0.8229 Training Loss :  2.319669 Test Loss :  0.6095661 Time :  69.62527847290039\n",
            "Epoch :  73 Training acc:    1 Test acc: 0.8142 Training Loss :  2.302088 Test Loss :  0.6658861 Time :  69.50945496559143\n",
            "Epoch :  74 Training acc:    1 Test acc: 0.8206 Training Loss :  2.3698997 Test Loss :  0.6400577 Time :  70.18649959564209\n",
            "Epoch :  75 Training acc:    1 Test acc: 0.8189 Training Loss :  2.2634077 Test Loss :  0.6333163 Time :  69.84359502792358\n",
            "Epoch :  76 Training acc:    1 Test acc: 0.8170 Training Loss :  2.2551394 Test Loss :  0.62734306 Time :  69.6372447013855\n",
            "Epoch :  77 Training acc:    1 Test acc: 0.8183 Training Loss :  2.2588663 Test Loss :  0.64236987 Time :  70.26342415809631\n",
            "Epoch :  78 Training acc:    1 Test acc: 0.8036 Training Loss :  2.3636458 Test Loss :  0.6991289 Time :  70.11070990562439\n",
            "Epoch :  79 Training acc:    1 Test acc: 0.8207 Training Loss :  2.4349568 Test Loss :  0.6365932 Time :  69.65256810188293\n",
            "Epoch :  80 Training acc:    1 Test acc: 0.8229 Training Loss :  2.3225884 Test Loss :  0.6379925 Time :  69.96024084091187\n",
            "Epoch :  81 Training acc:    1 Test acc: 0.8190 Training Loss :  2.2594488 Test Loss :  0.64472514 Time :  70.11414527893066\n",
            "Epoch :  82 Training acc:    1 Test acc: 0.8191 Training Loss :  2.358485 Test Loss :  0.6384257 Time :  69.93606901168823\n",
            "Epoch :  83 Training acc:    1 Test acc: 0.8160 Training Loss :  2.2778773 Test Loss :  0.6482799 Time :  70.57120490074158\n",
            "Epoch :  84 Training acc:    1 Test acc: 0.8221 Training Loss :  2.2567654 Test Loss :  0.63798094 Time :  69.92817568778992\n",
            "Epoch :  85 Training acc:    1 Test acc: 0.8278 Training Loss :  2.3422956 Test Loss :  0.62307966 Time :  70.35017704963684\n",
            "Epoch :  86 Training acc:    1 Test acc: 0.8229 Training Loss :  2.244646 Test Loss :  0.6466919 Time :  70.23068499565125\n",
            "Epoch :  87 Training acc:    1 Test acc: 0.8159 Training Loss :  2.275533 Test Loss :  0.6650898 Time :  70.14241933822632\n",
            "Epoch :  88 Training acc:    1 Test acc: 0.8229 Training Loss :  2.3091416 Test Loss :  0.64765424 Time :  69.62972235679626\n",
            "Epoch :  89 Training acc:    1 Test acc: 0.8240 Training Loss :  2.2255476 Test Loss :  0.6574163 Time :  70.09531116485596\n",
            "Epoch :  90 Training acc:    1 Test acc: 0.8129 Training Loss :  2.2638655 Test Loss :  0.677647 Time :  69.97030282020569\n",
            "Epoch :  91 Training acc:    1 Test acc: 0.8251 Training Loss :  2.2877784 Test Loss :  0.65286255 Time :  70.17343997955322\n",
            "Epoch :  92 Training acc:    1 Test acc: 0.8203 Training Loss :  2.2902398 Test Loss :  0.6485702 Time :  70.7096905708313\n",
            "Epoch :  93 Training acc:    1 Test acc: 0.8289 Training Loss :  2.2786562 Test Loss :  0.64873946 Time :  70.64634370803833\n",
            "Epoch :  94 Training acc:    1 Test acc: 0.8257 Training Loss :  2.3675246 Test Loss :  0.63529 Time :  70.88687014579773\n",
            "Epoch :  95 Training acc:    1 Test acc: 0.8262 Training Loss :  2.2228916 Test Loss :  0.6394224 Time :  70.4599142074585\n",
            "Epoch :  96 Training acc:    1 Test acc: 0.8230 Training Loss :  2.2063675 Test Loss :  0.65111446 Time :  70.97675061225891\n",
            "Epoch :  97 Training acc:    1 Test acc: 0.8171 Training Loss :  2.251602 Test Loss :  0.7110113 Time :  70.5009994506836\n",
            "Epoch :  98 Training acc:    1 Test acc: 0.8245 Training Loss :  2.3014746 Test Loss :  0.6524802 Time :  70.15862369537354\n",
            "Epoch :  99 Training acc:    1 Test acc: 0.8167 Training Loss :  2.3076746 Test Loss :  0.70773196 Time :  70.58308911323547\n",
            "Epoch :  100 Training acc:    1 Test acc: 0.8227 Training Loss :  2.2411418 Test Loss :  0.6563415 Time :  71.01175713539124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQz8vrMeu2MG"
      },
      "source": [
        "# Model Training - 2nd\n",
        "Adam , Threshold 0.9 ,  VGG Modified , 0.95"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krrT1yK3u0T2",
        "outputId": "c2b83901-9116-4e44-c909-03e019ee5ce7"
      },
      "source": [
        "def custom_cifar10_data(img_rows, img_cols):\n",
        "\n",
        "    # Load cifar10 training and validation sets\n",
        "    (X_train, Y_train), (X_valid, Y_valid) = cifar10.load_data()\n",
        "\n",
        "    # Resize training images\n",
        "    X_train = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_train[:,:,:,:]])\n",
        "    X_valid = np.array([cv2.resize(img, (img_rows,img_cols)) for img in X_valid[:,:,:,:]])\n",
        "\n",
        "    # Transform targets to keras compatible format\n",
        "    Y_train = np_utils.to_categorical(Y_train, num_classes)\n",
        "    Y_valid = np_utils.to_categorical(Y_valid, num_classes)\n",
        "    \n",
        "    X_train = X_train.astype('float32')\n",
        "    X_valid = X_valid.astype('float32')\n",
        "\n",
        "    # preprocess data\n",
        "    X_train = X_train / 255.0\n",
        "    X_valid = X_valid / 255.0\n",
        "\n",
        "    return X_train, Y_train, X_valid, Y_valid\n",
        "\n",
        "(x_train , y_train) , (x_test , y_test) = cifar10.load_data() \n",
        "print('X Train Shape : ' , x_train.shape)\n",
        "print('Y Train Shape :' , y_train.shape)\n",
        "print('X Test Shape : ' , x_test.shape)\n",
        "print('Y Test Shape : ' , y_test.shape)\n",
        "\n",
        "### Normalize the dataset\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "    \n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        "    \n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.4))\n",
        "   \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "x_train , y_train = shuffle(x_train , y_train)\n",
        "x_test , y_test = shuffle(x_test , y_test)\n",
        "x_label , x_unlabel , y_label , y_unlabel = train_test_split(x_train , y_train , test_size = 0.95 , random_state = 42)\n",
        "print(\"X Train Shape : \" , x_train.shape)\n",
        "print(\"Y Train Shape : \" , y_train.shape)\n",
        "print(\"X Label Shape : \" , x_label.shape)\n",
        "print(\"Y Label Shape : \" , y_label.shape)\n",
        "print(\"X UnLabel Shape : \" , x_unlabel.shape)\n",
        "print(\"Y UnLabel Shape : \" , y_unlabel.shape)\n",
        "print(\"X Test Shape : \"  , x_test.shape)\n",
        "print(\"Y Test Shape : \" , y_test.shape)\n",
        "\n",
        "### Label Enocding to One - Hot Encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder_obj = OneHotEncoder(handle_unknown = 'ignore')\n",
        "y_label = encoder_obj.fit_transform(y_label).toarray()\n",
        "print(\"Y_Label Shape : \" , y_label.shape)\n",
        "y_test = encoder_obj.fit_transform(y_test).toarray()\n",
        "print(\"Y_Test Shape : \" , y_test.shape)\n",
        "y_train = encoder_obj.fit_transform(y_train).toarray()\n",
        "print(\"Y Train Shape : \" , y_train.shape)\n",
        "\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "### Random augmentation wrapper\n",
        "def random_rotate_image_strong(image):\n",
        "  randAug = RandAugment(2 , 6)\n",
        "  image = randAug.__call__(array_to_img(image))\n",
        "  image = img_to_array(image)\n",
        "  return image\n",
        "def tf_random_rotate_image_strong(image):\n",
        "  im_shape = image.shape\n",
        "  [image,] = tf.py_function(random_rotate_image_strong, [image], [tf.float32])\n",
        "  image.set_shape(im_shape)\n",
        "  return image/255.0\n",
        "### Weak augmentation wrapper\n",
        "def random_rotate_image_weak(image):\n",
        "  #image = ndimage.rotate(image, np.random.uniform(-30, 30), reshape=False)\n",
        "  weak_aug = WeakAugment(3)\n",
        "  image = weak_aug.__call__(array_to_img(image))\n",
        "  image = img_to_array(image)\n",
        "  return image\n",
        "def tf_random_rotate_image_weak(image):\n",
        "  im_shape = image.shape\n",
        "  [image,] = tf.py_function(random_rotate_image_weak, [image], [tf.float32])\n",
        "  image.set_shape(im_shape)\n",
        "  return image/255.0  \n",
        "\n",
        "model = model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "train_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "test_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "epochs = 200\n",
        "\n",
        "\n",
        "### Getting the shape\n",
        "print(\"X Label Shape : \" , x_label.shape)\n",
        "print(\"Y Label Shape : \" , y_label.shape)\n",
        "print(\"X Unlabel Shape : \", x_unlabel.shape)\n",
        "print(\"Y Unlable Shape : \", y_unlabel.shape)\n",
        "print(\"X Test Shape : \", x_test.shape)\n",
        "print(\"Y Test Shape : \", y_test.shape)\n",
        "\n",
        "def custom_loss(y_true , y_pred , y_weak , y_strong) : \n",
        "  alpha = 1 \n",
        "  threshold = 0.9\n",
        "  y_weak_new = []\n",
        "  y_strong_new = []\n",
        "  ### Now getting only the y_weak with greater than threshold \n",
        "  for i in range(len(y_weak)) : \n",
        "    val = np.argmax(y_weak[i])\n",
        "    if  y_weak[i][val] >= threshold :\n",
        "      ### Creating Pseudo Label\n",
        "      val = np.argmax(y_weak[i])\n",
        "      y_pseudo = np.array([0 for j in range(len(y_weak[i]))])\n",
        "      y_pseudo[val] = 1 \n",
        "      ### Appending data to y_weak\n",
        "      y_weak_new.append(y_pseudo)\n",
        "      y_strong_new.append(y_strong[i])\n",
        "\n",
        "  y_weak = np.array(y_weak_new)\n",
        "  y_strong = np.array(y_strong_new)\n",
        "        \n",
        "  cateogrical_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  supervised_loss = cateogrical_cross_entropy(y_true , y_pred)\n",
        "\n",
        "  if y_weak.size !=  0 : \n",
        "    unsupervised_loss = cateogrical_cross_entropy(y_weak , y_strong)\n",
        "    custom_loss = alpha * unsupervised_loss + supervised_loss\n",
        "\n",
        "  else : \n",
        "    custom_loss = supervised_loss\n",
        "\n",
        "  return custom_loss\n",
        "\n",
        "def custom_loss_test(y_true , y_pred) : \n",
        "  cateogrical_cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  loss = cateogrical_cross_entropy(y_true , y_pred)\n",
        "  return loss\n",
        "\n",
        "\n",
        "for epoch in range(epochs) : \n",
        "  print(\"Epoch : \" , epoch + 1 , end = \" \")\n",
        "  ### Time \n",
        "  start_time = time.time()\n",
        "  ### Dataset\n",
        "  x_label , y_label = shuffle(x_label , y_label)\n",
        "  x_unlabel = shuffle(x_unlabel)\n",
        "  x_unlabels =  tf.data.Dataset.from_tensor_slices(x_unlabel)\n",
        "  x_unlabels_weak = x_unlabels.map(tf_random_rotate_image_weak)\n",
        "  x_unlabels_strong = x_unlabels.map(tf_random_rotate_image_strong)\n",
        "  labels = tf.data.Dataset.from_tensor_slices((x_label , y_label))\n",
        "  unlabels = tf.data.Dataset.zip((x_unlabels_weak , x_unlabels_strong))\n",
        "  train_dataset = tf.data.Dataset.zip((labels , unlabels)).batch(500)\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices((x_test , y_test)).batch(500)\n",
        "  \n",
        "  for steps  , (labels , unlabels) in enumerate(train_dataset) : \n",
        "    batch_losses = []\n",
        "    with tf.GradientTape() as tape : \n",
        "      logs_labels = model(labels[0] , training = True )\n",
        "      logs_unlabels_weak = model(unlabels[0] , training = False )\n",
        "      logs_unlabels_strong = model(unlabels[1] , training = True )\n",
        "\n",
        "      loss = custom_loss(labels[1] , logs_labels , logs_unlabels_weak , logs_unlabels_strong)\n",
        "      batch_losses.append(loss.numpy())\n",
        "      train_acc_metric.update_state(labels[1] , logs_labels)\n",
        "\n",
        "    \n",
        "    grads = tape.gradient(loss , model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads , model.trainable_variables))\n",
        "    \n",
        "\n",
        "  test_batch_losses = []\n",
        "  for x_test_dash , y_test_dash in test_dataset : \n",
        "    y_predict = model(x_test_dash , training = False )\n",
        "    loss = custom_loss_test(y_test_dash , y_predict)\n",
        "    test_batch_losses.append(loss.numpy())\n",
        "    ### Testing Accuracy\n",
        "    test_acc_metric.update_state(y_test_dash , y_predict)\n",
        "\n",
        "  ### Time End for Epoch\n",
        "  end_time = time.time()\n",
        "  train_acc = train_acc_metric.result()\n",
        "  test_acc = test_acc_metric.result()\n",
        "  print(\"Training acc: %4.f\" % (float(train_acc),) , end = \" \")\n",
        "  print(\"Test acc: %.4f\" % (float(test_acc),) , end = \" \")\n",
        "  print(\"Training Loss : \" , np.mean(batch_losses) , end = \" \")\n",
        "  print(\"Test Loss : \" , np.mean(test_batch_losses) , end = \" \")\n",
        "  print(\"Time : \" , end_time - start_time )\n",
        "  train_acc_metric.reset_states()\n",
        "  test_acc_metric.reset_states()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Train Shape :  (50000, 32, 32, 3)\n",
            "Y Train Shape : (50000, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 1)\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               262272    \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 552,874\n",
            "Trainable params: 551,722\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n",
            "X Train Shape :  (50000, 32, 32, 3)\n",
            "Y Train Shape :  (50000, 1)\n",
            "X Label Shape :  (2500, 32, 32, 3)\n",
            "Y Label Shape :  (2500, 1)\n",
            "X UnLabel Shape :  (47500, 32, 32, 3)\n",
            "Y UnLabel Shape :  (47500, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 1)\n",
            "Y_Label Shape :  (2500, 10)\n",
            "Y_Test Shape :  (10000, 10)\n",
            "Y Train Shape :  (50000, 10)\n",
            "X Label Shape :  (2500, 32, 32, 3)\n",
            "Y Label Shape :  (2500, 10)\n",
            "X Unlabel Shape :  (47500, 32, 32, 3)\n",
            "Y Unlable Shape :  (47500, 1)\n",
            "X Test Shape :  (10000, 32, 32, 3)\n",
            "Y Test Shape :  (10000, 10)\n",
            "Epoch :  1 Training acc:    0 Test acc: 0.1013 Training Loss :  3.0083039 Test Loss :  3.0615811 Time :  10.87312650680542\n",
            "Epoch :  2 Training acc:    0 Test acc: 0.1156 Training Loss :  2.6647446 Test Loss :  2.8452566 Time :  10.353801488876343\n",
            "Epoch :  3 Training acc:    0 Test acc: 0.1573 Training Loss :  2.4033089 Test Loss :  2.4747488 Time :  10.421356201171875\n",
            "Epoch :  4 Training acc:    0 Test acc: 0.1190 Training Loss :  2.1524522 Test Loss :  2.5965118 Time :  10.253112554550171\n",
            "Epoch :  5 Training acc:    0 Test acc: 0.1123 Training Loss :  2.1668828 Test Loss :  2.6758966 Time :  10.246065378189087\n",
            "Epoch :  6 Training acc:    0 Test acc: 0.1424 Training Loss :  2.010967 Test Loss :  2.344483 Time :  10.31541657447815\n",
            "Epoch :  7 Training acc:    0 Test acc: 0.1732 Training Loss :  1.8679365 Test Loss :  2.2880394 Time :  10.28292989730835\n",
            "Epoch :  8 Training acc:    0 Test acc: 0.1909 Training Loss :  1.887099 Test Loss :  2.29224 Time :  10.214084386825562\n",
            "Epoch :  9 Training acc:    0 Test acc: 0.1910 Training Loss :  1.7780122 Test Loss :  2.3136468 Time :  10.165454387664795\n",
            "Epoch :  10 Training acc:    0 Test acc: 0.1874 Training Loss :  1.6765468 Test Loss :  2.3253417 Time :  10.220752000808716\n",
            "Epoch :  11 Training acc:    0 Test acc: 0.1924 Training Loss :  1.6423484 Test Loss :  2.3078017 Time :  10.271769046783447\n",
            "Epoch :  12 Training acc:    0 Test acc: 0.2136 Training Loss :  1.5339612 Test Loss :  2.233199 Time :  10.244036436080933\n",
            "Epoch :  13 Training acc:    0 Test acc: 0.1930 Training Loss :  1.5413554 Test Loss :  2.3770375 Time :  10.243208646774292\n",
            "Epoch :  14 Training acc:    0 Test acc: 0.1978 Training Loss :  1.5313064 Test Loss :  2.379892 Time :  10.170616626739502\n",
            "Epoch :  15 Training acc:    0 Test acc: 0.1822 Training Loss :  1.5184345 Test Loss :  2.5714095 Time :  10.256618976593018\n",
            "Epoch :  16 Training acc:    0 Test acc: 0.1945 Training Loss :  1.5179914 Test Loss :  2.5459888 Time :  10.260376453399658\n",
            "Epoch :  17 Training acc:    1 Test acc: 0.1861 Training Loss :  1.4052888 Test Loss :  2.7246127 Time :  10.150729894638062\n",
            "Epoch :  18 Training acc:    1 Test acc: 0.2000 Training Loss :  1.3479307 Test Loss :  2.5963576 Time :  10.13921570777893\n",
            "Epoch :  19 Training acc:    1 Test acc: 0.2104 Training Loss :  1.3356204 Test Loss :  2.6258645 Time :  10.176570653915405\n",
            "Epoch :  20 Training acc:    1 Test acc: 0.2207 Training Loss :  1.2840294 Test Loss :  2.5591567 Time :  10.215821981430054\n",
            "Epoch :  21 Training acc:    1 Test acc: 0.2100 Training Loss :  1.3981744 Test Loss :  2.6093626 Time :  10.089807748794556\n",
            "Epoch :  22 Training acc:    1 Test acc: 0.2256 Training Loss :  1.296764 Test Loss :  2.6688542 Time :  10.20569396018982\n",
            "Epoch :  23 Training acc:    1 Test acc: 0.2333 Training Loss :  1.259619 Test Loss :  2.7133765 Time :  10.187981128692627\n",
            "Epoch :  24 Training acc:    1 Test acc: 0.2227 Training Loss :  1.1894559 Test Loss :  2.7522101 Time :  10.217870235443115\n",
            "Epoch :  25 Training acc:    1 Test acc: 0.2317 Training Loss :  1.1909796 Test Loss :  2.7396162 Time :  10.137688875198364\n",
            "Epoch :  26 Training acc:    1 Test acc: 0.2285 Training Loss :  3.4909973 Test Loss :  2.7693574 Time :  10.182933568954468\n",
            "Epoch :  27 Training acc:    1 Test acc: 0.2286 Training Loss :  1.2106674 Test Loss :  2.8053777 Time :  10.156893253326416\n",
            "Epoch :  28 Training acc:    1 Test acc: 0.2201 Training Loss :  1.0968479 Test Loss :  2.8083966 Time :  10.096784591674805\n",
            "Epoch :  29 Training acc:    1 Test acc: 0.2321 Training Loss :  1.1532279 Test Loss :  2.698749 Time :  10.19466233253479\n",
            "Epoch :  30 Training acc:    1 Test acc: 0.2348 Training Loss :  1.107993 Test Loss :  2.7104704 Time :  10.167312383651733\n",
            "Epoch :  31 Training acc:    1 Test acc: 0.2323 Training Loss :  0.93266225 Test Loss :  2.7351587 Time :  10.138391733169556\n",
            "Epoch :  32 Training acc:    1 Test acc: 0.2322 Training Loss :  3.3046107 Test Loss :  2.7139275 Time :  10.13607144355774\n",
            "Epoch :  33 Training acc:    1 Test acc: 0.2254 Training Loss :  1.1009533 Test Loss :  2.7687273 Time :  10.11496615409851\n",
            "Epoch :  34 Training acc:    1 Test acc: 0.2413 Training Loss :  3.1406696 Test Loss :  2.6863375 Time :  10.148499488830566\n",
            "Epoch :  35 Training acc:    1 Test acc: 0.2451 Training Loss :  2.7718601 Test Loss :  2.6411564 Time :  10.204015016555786\n",
            "Epoch :  36 Training acc:    1 Test acc: 0.2365 Training Loss :  0.94958866 Test Loss :  2.676142 Time :  10.076706409454346\n",
            "Epoch :  37 Training acc:    1 Test acc: 0.2298 Training Loss :  3.1357625 Test Loss :  2.7042375 Time :  10.146137475967407\n",
            "Epoch :  38 Training acc:    1 Test acc: 0.2358 Training Loss :  2.8516855 Test Loss :  2.6866968 Time :  10.23583436012268\n",
            "Epoch :  39 Training acc:    1 Test acc: 0.2300 Training Loss :  2.6852055 Test Loss :  2.681888 Time :  10.198168277740479\n",
            "Epoch :  40 Training acc:    1 Test acc: 0.2384 Training Loss :  2.7214427 Test Loss :  2.673579 Time :  10.14634370803833\n",
            "Epoch :  41 Training acc:    1 Test acc: 0.2634 Training Loss :  3.0703256 Test Loss :  2.6206963 Time :  10.009462356567383\n",
            "Epoch :  42 Training acc:    1 Test acc: 0.2448 Training Loss :  2.6640763 Test Loss :  2.6506705 Time :  10.209213733673096\n",
            "Epoch :  43 Training acc:    1 Test acc: 0.2637 Training Loss :  2.6382773 Test Loss :  2.547851 Time :  10.148239850997925\n",
            "Epoch :  44 Training acc:    1 Test acc: 0.2731 Training Loss :  2.5124974 Test Loss :  2.5063643 Time :  10.172361612319946\n",
            "Epoch :  45 Training acc:    1 Test acc: 0.2685 Training Loss :  3.061933 Test Loss :  2.5039043 Time :  10.204345226287842\n",
            "Epoch :  46 Training acc:    1 Test acc: 0.2642 Training Loss :  2.7866764 Test Loss :  2.5975337 Time :  10.312875032424927\n",
            "Epoch :  47 Training acc:    1 Test acc: 0.2829 Training Loss :  2.8211775 Test Loss :  2.48347 Time :  10.1479332447052\n",
            "Epoch :  48 Training acc:    1 Test acc: 0.2774 Training Loss :  2.5940533 Test Loss :  2.5250344 Time :  10.085663080215454\n",
            "Epoch :  49 Training acc:    1 Test acc: 0.2713 Training Loss :  2.7431579 Test Loss :  2.6092448 Time :  10.1917085647583\n",
            "Epoch :  50 Training acc:    1 Test acc: 0.3078 Training Loss :  2.578688 Test Loss :  2.4663148 Time :  10.1878662109375\n",
            "Epoch :  51 Training acc:    1 Test acc: 0.2944 Training Loss :  2.7402227 Test Loss :  2.516481 Time :  10.173203229904175\n",
            "Epoch :  52 Training acc:    1 Test acc: 0.3109 Training Loss :  2.4561837 Test Loss :  2.395525 Time :  10.213592529296875\n",
            "Epoch :  53 Training acc:    1 Test acc: 0.3063 Training Loss :  2.768417 Test Loss :  2.3888018 Time :  10.241862773895264\n",
            "Epoch :  54 Training acc:    1 Test acc: 0.3294 Training Loss :  2.4732766 Test Loss :  2.264934 Time :  10.116558313369751\n",
            "Epoch :  55 Training acc:    1 Test acc: 0.3420 Training Loss :  2.5407944 Test Loss :  2.207198 Time :  10.271296739578247\n",
            "Epoch :  56 Training acc:    1 Test acc: 0.3422 Training Loss :  2.6875818 Test Loss :  2.1952133 Time :  10.383005380630493\n",
            "Epoch :  57 Training acc:    1 Test acc: 0.3139 Training Loss :  2.5612376 Test Loss :  2.389079 Time :  10.184134483337402\n",
            "Epoch :  58 Training acc:    1 Test acc: 0.3305 Training Loss :  2.6219044 Test Loss :  2.2616022 Time :  10.345467805862427\n",
            "Epoch :  59 Training acc:    1 Test acc: 0.3171 Training Loss :  2.7099643 Test Loss :  2.3447316 Time :  10.248886108398438\n",
            "Epoch :  60 Training acc:    1 Test acc: 0.3205 Training Loss :  2.6398187 Test Loss :  2.4249458 Time :  10.256381750106812\n",
            "Epoch :  61 Training acc:    1 Test acc: 0.3580 Training Loss :  2.484435 Test Loss :  2.1964788 Time :  10.289116859436035\n",
            "Epoch :  62 Training acc:    1 Test acc: 0.3508 Training Loss :  2.693266 Test Loss :  2.2303493 Time :  10.372135162353516\n",
            "Epoch :  63 Training acc:    1 Test acc: 0.3545 Training Loss :  2.628706 Test Loss :  2.2154784 Time :  10.269308090209961\n",
            "Epoch :  64 Training acc:    1 Test acc: 0.3546 Training Loss :  2.6199217 Test Loss :  2.2719264 Time :  10.289722919464111\n",
            "Epoch :  65 Training acc:    1 Test acc: 0.3635 Training Loss :  2.4463503 Test Loss :  2.2047346 Time :  10.342485427856445\n",
            "Epoch :  66 Training acc:    1 Test acc: 0.3737 Training Loss :  2.4134746 Test Loss :  2.2255356 Time :  10.335840225219727\n",
            "Epoch :  67 Training acc:    1 Test acc: 0.3717 Training Loss :  2.5353594 Test Loss :  2.2648146 Time :  10.402847290039062\n",
            "Epoch :  68 Training acc:    1 Test acc: 0.3921 Training Loss :  2.5916982 Test Loss :  2.1542652 Time :  10.5009925365448\n",
            "Epoch :  69 Training acc:    1 Test acc: 0.3904 Training Loss :  2.6164777 Test Loss :  2.1779695 Time :  10.380078315734863\n",
            "Epoch :  70 Training acc:    1 Test acc: 0.4084 Training Loss :  2.4561572 Test Loss :  2.1066623 Time :  10.55179238319397\n",
            "Epoch :  71 Training acc:    1 Test acc: 0.4144 Training Loss :  2.4697073 Test Loss :  2.1004062 Time :  10.580151081085205\n",
            "Epoch :  72 Training acc:    1 Test acc: 0.4334 Training Loss :  2.4896202 Test Loss :  2.0062604 Time :  10.405559778213501\n",
            "Epoch :  73 Training acc:    1 Test acc: 0.4296 Training Loss :  2.515884 Test Loss :  2.0507426 Time :  10.586088418960571\n",
            "Epoch :  74 Training acc:    1 Test acc: 0.4130 Training Loss :  2.4587467 Test Loss :  2.100076 Time :  10.631526947021484\n",
            "Epoch :  75 Training acc:    1 Test acc: 0.4334 Training Loss :  2.4113064 Test Loss :  1.9812899 Time :  10.464524030685425\n",
            "Epoch :  76 Training acc:    1 Test acc: 0.4467 Training Loss :  2.4222953 Test Loss :  1.9806421 Time :  10.76629090309143\n",
            "Epoch :  77 Training acc:    1 Test acc: 0.4567 Training Loss :  2.520957 Test Loss :  1.8775551 Time :  10.441553115844727\n",
            "Epoch :  78 Training acc:    1 Test acc: 0.4484 Training Loss :  2.459136 Test Loss :  2.0711887 Time :  10.526577949523926\n",
            "Epoch :  79 Training acc:    1 Test acc: 0.4640 Training Loss :  2.3783057 Test Loss :  1.9222174 Time :  10.605270624160767\n",
            "Epoch :  80 Training acc:    1 Test acc: 0.4677 Training Loss :  2.4438224 Test Loss :  1.9124094 Time :  10.604070663452148\n",
            "Epoch :  81 Training acc:    1 Test acc: 0.4782 Training Loss :  2.4442303 Test Loss :  1.846482 Time :  10.556044340133667\n",
            "Epoch :  82 Training acc:    1 Test acc: 0.4802 Training Loss :  2.433794 Test Loss :  1.8809506 Time :  10.594218492507935\n",
            "Epoch :  83 Training acc:    1 Test acc: 0.4785 Training Loss :  2.3716364 Test Loss :  1.8706524 Time :  10.691655397415161\n",
            "Epoch :  84 Training acc:    1 Test acc: 0.4907 Training Loss :  2.3762774 Test Loss :  1.8466345 Time :  10.688621282577515\n",
            "Epoch :  85 Training acc:    1 Test acc: 0.5027 Training Loss :  2.4706 Test Loss :  1.8011764 Time :  10.778345823287964\n",
            "Epoch :  86 Training acc:    1 Test acc: 0.5075 Training Loss :  2.4706612 Test Loss :  1.7780653 Time :  10.655459880828857\n",
            "Epoch :  87 Training acc:    1 Test acc: 0.4984 Training Loss :  2.4047947 Test Loss :  1.8935843 Time :  10.729736566543579\n",
            "Epoch :  88 Training acc:    1 Test acc: 0.4951 Training Loss :  2.3513923 Test Loss :  1.9288113 Time :  10.731626272201538\n",
            "Epoch :  89 Training acc:    1 Test acc: 0.5172 Training Loss :  2.3385472 Test Loss :  1.7468643 Time :  10.69018268585205\n",
            "Epoch :  90 Training acc:    1 Test acc: 0.5197 Training Loss :  2.3625338 Test Loss :  1.7489836 Time :  10.838138818740845\n",
            "Epoch :  91 Training acc:    1 Test acc: 0.5377 Training Loss :  2.368915 Test Loss :  1.7070621 Time :  10.766286611557007\n",
            "Epoch :  92 Training acc:    1 Test acc: 0.5450 Training Loss :  2.3206377 Test Loss :  1.6865238 Time :  10.748346328735352\n",
            "Epoch :  93 Training acc:    1 Test acc: 0.5438 Training Loss :  2.411789 Test Loss :  1.6999922 Time :  10.769607543945312\n",
            "Epoch :  94 Training acc:    1 Test acc: 0.5539 Training Loss :  2.3482225 Test Loss :  1.6894159 Time :  10.806228399276733\n",
            "Epoch :  95 Training acc:    1 Test acc: 0.5621 Training Loss :  2.3802395 Test Loss :  1.6557512 Time :  10.87966012954712\n",
            "Epoch :  96 Training acc:    1 Test acc: 0.5609 Training Loss :  2.316724 Test Loss :  1.6234405 Time :  10.907115936279297\n",
            "Epoch :  97 Training acc:    1 Test acc: 0.5527 Training Loss :  2.3064976 Test Loss :  1.6999668 Time :  10.779415607452393\n",
            "Epoch :  98 Training acc:    1 Test acc: 0.5490 Training Loss :  2.3783746 Test Loss :  1.7457647 Time :  10.708822250366211\n",
            "Epoch :  99 Training acc:    1 Test acc: 0.5530 Training Loss :  2.3252223 Test Loss :  1.7321875 Time :  10.838636875152588\n",
            "Epoch :  100 Training acc:    1 Test acc: 0.5474 Training Loss :  2.3266377 Test Loss :  1.7708406 Time :  10.84074854850769\n",
            "Epoch :  101 Training acc:    1 Test acc: 0.5441 Training Loss :  2.3772879 Test Loss :  1.7515147 Time :  10.857750415802002\n",
            "Epoch :  102 Training acc:    1 Test acc: 0.5499 Training Loss :  2.3926263 Test Loss :  1.7346704 Time :  10.72627568244934\n",
            "Epoch :  103 Training acc:    1 Test acc: 0.5577 Training Loss :  2.3581262 Test Loss :  1.7035601 Time :  10.782836675643921\n",
            "Epoch :  104 Training acc:    1 Test acc: 0.5489 Training Loss :  2.3717864 Test Loss :  1.788538 Time :  10.879840612411499\n",
            "Epoch :  105 Training acc:    1 Test acc: 0.5560 Training Loss :  2.3622727 Test Loss :  1.7560244 Time :  11.061814785003662\n",
            "Epoch :  106 Training acc:    1 Test acc: 0.5570 Training Loss :  2.322501 Test Loss :  1.7648427 Time :  10.978459358215332\n",
            "Epoch :  107 Training acc:    1 Test acc: 0.5494 Training Loss :  2.3212252 Test Loss :  1.8168137 Time :  10.892000675201416\n",
            "Epoch :  108 Training acc:    1 Test acc: 0.5544 Training Loss :  2.3119383 Test Loss :  1.7975304 Time :  10.983113050460815\n",
            "Epoch :  109 Training acc:    1 Test acc: 0.5335 Training Loss :  2.2573187 Test Loss :  2.0145006 Time :  10.861191511154175\n",
            "Epoch :  110 Training acc:    1 Test acc: 0.5579 Training Loss :  2.19864 Test Loss :  1.8264071 Time :  10.876403331756592\n",
            "Epoch :  111 Training acc:    1 Test acc: 0.5629 Training Loss :  2.2998478 Test Loss :  1.783857 Time :  10.794627666473389\n",
            "Epoch :  112 Training acc:    1 Test acc: 0.5491 Training Loss :  2.2367563 Test Loss :  1.8736273 Time :  10.99193286895752\n",
            "Epoch :  113 Training acc:    1 Test acc: 0.5494 Training Loss :  2.2582788 Test Loss :  1.9036219 Time :  11.040944814682007\n",
            "Epoch :  114 Training acc:    1 Test acc: 0.5519 Training Loss :  2.2568269 Test Loss :  1.9387188 Time :  11.016392469406128\n",
            "Epoch :  115 Training acc:    1 Test acc: 0.5430 Training Loss :  2.3168762 Test Loss :  1.994333 Time :  11.002540588378906\n",
            "Epoch :  116 Training acc:    1 Test acc: 0.5241 Training Loss :  2.2103176 Test Loss :  2.2640264 Time :  11.076253652572632\n",
            "Epoch :  117 Training acc:    1 Test acc: 0.5278 Training Loss :  2.2197986 Test Loss :  2.2392442 Time :  11.09404993057251\n",
            "Epoch :  118 Training acc:    1 Test acc: 0.5264 Training Loss :  2.2495928 Test Loss :  2.276642 Time :  11.186789989471436\n",
            "Epoch :  119 Training acc:    1 Test acc: 0.5540 Training Loss :  2.3049614 Test Loss :  2.0000312 Time :  10.980992794036865\n",
            "Epoch :  120 Training acc:    1 Test acc: 0.5700 Training Loss :  2.2686548 Test Loss :  1.8498452 Time :  11.095682621002197\n",
            "Epoch :  121 Training acc:    1 Test acc: 0.5599 Training Loss :  2.30823 Test Loss :  1.8878276 Time :  11.039867639541626\n",
            "Epoch :  122 Training acc:    1 Test acc: 0.5781 Training Loss :  2.2702353 Test Loss :  1.8119094 Time :  11.145233392715454\n",
            "Epoch :  123 Training acc:    1 Test acc: 0.5719 Training Loss :  2.23026 Test Loss :  1.8267062 Time :  11.025511503219604\n",
            "Epoch :  124 Training acc:    1 Test acc: 0.5817 Training Loss :  2.2339604 Test Loss :  1.7753786 Time :  10.973908185958862\n",
            "Epoch :  125 Training acc:    1 Test acc: 0.5832 Training Loss :  2.2146854 Test Loss :  1.802664 Time :  11.006469964981079\n",
            "Epoch :  126 Training acc:    1 Test acc: 0.5733 Training Loss :  2.291488 Test Loss :  1.8987528 Time :  11.014544486999512\n",
            "Epoch :  127 Training acc:    1 Test acc: 0.5816 Training Loss :  2.2500618 Test Loss :  1.8571737 Time :  11.012806177139282\n",
            "Epoch :  128 Training acc:    1 Test acc: 0.5703 Training Loss :  2.2763555 Test Loss :  1.8208008 Time :  11.053343772888184\n",
            "Epoch :  129 Training acc:    1 Test acc: 0.5795 Training Loss :  2.2841554 Test Loss :  1.7946522 Time :  11.07453465461731\n",
            "Epoch :  130 Training acc:    1 Test acc: 0.5762 Training Loss :  2.217903 Test Loss :  1.851497 Time :  10.941762685775757\n",
            "Epoch :  131 Training acc:    1 Test acc: 0.5739 Training Loss :  2.2572727 Test Loss :  1.8885876 Time :  11.022564888000488\n",
            "Epoch :  132 Training acc:    1 Test acc: 0.5879 Training Loss :  2.2298687 Test Loss :  1.8106852 Time :  11.103116512298584\n",
            "Epoch :  133 Training acc:    1 Test acc: 0.5913 Training Loss :  2.2296262 Test Loss :  1.7873961 Time :  11.222554922103882\n",
            "Epoch :  134 Training acc:    1 Test acc: 0.5810 Training Loss :  2.2063427 Test Loss :  1.8323848 Time :  11.053120374679565\n",
            "Epoch :  135 Training acc:    1 Test acc: 0.5907 Training Loss :  2.2724254 Test Loss :  1.7973652 Time :  11.115716934204102\n",
            "Epoch :  136 Training acc:    1 Test acc: 0.5943 Training Loss :  2.3045452 Test Loss :  1.792428 Time :  11.045132398605347\n",
            "Epoch :  137 Training acc:    1 Test acc: 0.5951 Training Loss :  2.257909 Test Loss :  1.7759339 Time :  11.138227939605713\n",
            "Epoch :  138 Training acc:    1 Test acc: 0.5935 Training Loss :  2.281254 Test Loss :  1.7993841 Time :  11.128237962722778\n",
            "Epoch :  139 Training acc:    1 Test acc: 0.5913 Training Loss :  2.264501 Test Loss :  1.8645996 Time :  11.258432865142822\n",
            "Epoch :  140 Training acc:    1 Test acc: 0.5963 Training Loss :  2.2413898 Test Loss :  1.8161533 Time :  11.160935401916504\n",
            "Epoch :  141 Training acc:    1 Test acc: 0.5913 Training Loss :  2.2645297 Test Loss :  1.7977715 Time :  11.176789999008179\n",
            "Epoch :  142 Training acc:    1 Test acc: 0.5945 Training Loss :  2.3025758 Test Loss :  1.8316813 Time :  11.13882565498352\n",
            "Epoch :  143 Training acc:    1 Test acc: 0.5874 Training Loss :  2.2804632 Test Loss :  1.8895957 Time :  11.135070085525513\n",
            "Epoch :  144 Training acc:    1 Test acc: 0.5894 Training Loss :  2.2177243 Test Loss :  1.8646663 Time :  11.058860063552856\n",
            "Epoch :  145 Training acc:    1 Test acc: 0.5945 Training Loss :  2.2700381 Test Loss :  1.8459327 Time :  11.185829877853394\n",
            "Epoch :  146 Training acc:    1 Test acc: 0.5972 Training Loss :  2.2073286 Test Loss :  1.8477551 Time :  11.340547323226929\n",
            "Epoch :  147 Training acc:    1 Test acc: 0.5931 Training Loss :  2.2459779 Test Loss :  1.9076059 Time :  11.160220623016357\n",
            "Epoch :  148 Training acc:    1 Test acc: 0.5904 Training Loss :  2.3023593 Test Loss :  1.9203237 Time :  11.163415431976318\n",
            "Epoch :  149 Training acc:    1 Test acc: 0.5819 Training Loss :  2.1933877 Test Loss :  2.0328605 Time :  11.233820915222168\n",
            "Epoch :  150 Training acc:    1 Test acc: 0.5756 Training Loss :  2.2390614 Test Loss :  2.0279157 Time :  11.362470626831055\n",
            "Epoch :  151 Training acc:    1 Test acc: 0.5923 Training Loss :  2.2693722 Test Loss :  1.8722664 Time :  11.259421348571777\n",
            "Epoch :  152 Training acc:    1 Test acc: 0.5819 Training Loss :  2.2649932 Test Loss :  1.9350774 Time :  11.27193307876587\n",
            "Epoch :  153 Training acc:    1 Test acc: 0.5999 Training Loss :  2.1971848 Test Loss :  1.8481897 Time :  11.249678134918213\n",
            "Epoch :  154 Training acc:    1 Test acc: 0.5869 Training Loss :  2.1823244 Test Loss :  1.9975526 Time :  11.232940912246704\n",
            "Epoch :  155 Training acc:    1 Test acc: 0.5658 Training Loss :  2.222672 Test Loss :  2.1162336 Time :  11.234083890914917\n",
            "Epoch :  156 Training acc:    1 Test acc: 0.5862 Training Loss :  2.2454445 Test Loss :  1.9976447 Time :  11.222166776657104\n",
            "Epoch :  157 Training acc:    1 Test acc: 0.5957 Training Loss :  2.2632537 Test Loss :  1.9083173 Time :  11.22487735748291\n",
            "Epoch :  158 Training acc:    1 Test acc: 0.5978 Training Loss :  2.2606823 Test Loss :  1.837277 Time :  11.217815160751343\n",
            "Epoch :  159 Training acc:    1 Test acc: 0.5970 Training Loss :  2.2279716 Test Loss :  1.8484783 Time :  11.26254153251648\n",
            "Epoch :  160 Training acc:    1 Test acc: 0.5955 Training Loss :  2.2379677 Test Loss :  1.9017357 Time :  11.426457643508911\n",
            "Epoch :  161 Training acc:    1 Test acc: 0.5880 Training Loss :  2.2568634 Test Loss :  2.0178607 Time :  11.555274963378906\n",
            "Epoch :  162 Training acc:    1 Test acc: 0.5976 Training Loss :  2.2310147 Test Loss :  1.9548544 Time :  11.241397857666016\n",
            "Epoch :  163 Training acc:    1 Test acc: 0.5983 Training Loss :  2.2671964 Test Loss :  1.9043789 Time :  11.317453384399414\n",
            "Epoch :  164 Training acc:    1 Test acc: 0.5941 Training Loss :  2.255965 Test Loss :  1.9135926 Time :  11.341887712478638\n",
            "Epoch :  165 Training acc:    1 Test acc: 0.5915 Training Loss :  2.2516031 Test Loss :  1.928333 Time :  11.293105363845825\n",
            "Epoch :  166 Training acc:    1 Test acc: 0.5928 Training Loss :  2.2187588 Test Loss :  1.8902721 Time :  11.344019412994385\n",
            "Epoch :  167 Training acc:    1 Test acc: 0.5897 Training Loss :  2.2060802 Test Loss :  1.8925436 Time :  11.251642227172852\n",
            "Epoch :  168 Training acc:    1 Test acc: 0.5933 Training Loss :  2.209869 Test Loss :  1.8767831 Time :  11.168307304382324\n",
            "Epoch :  169 Training acc:    1 Test acc: 0.5901 Training Loss :  2.1981623 Test Loss :  1.9278075 Time :  11.180212020874023\n",
            "Epoch :  170 Training acc:    1 Test acc: 0.5903 Training Loss :  2.2006998 Test Loss :  1.9310808 Time :  11.310442924499512\n",
            "Epoch :  171 Training acc:    1 Test acc: 0.5894 Training Loss :  2.22221 Test Loss :  1.9225609 Time :  11.317752599716187\n",
            "Epoch :  172 Training acc:    1 Test acc: 0.5845 Training Loss :  2.2084048 Test Loss :  1.9659802 Time :  11.385432481765747\n",
            "Epoch :  173 Training acc:    1 Test acc: 0.5974 Training Loss :  2.1816654 Test Loss :  1.977274 Time :  11.399600505828857\n",
            "Epoch :  174 Training acc:    1 Test acc: 0.5811 Training Loss :  2.2198408 Test Loss :  2.135735 Time :  11.336457252502441\n",
            "Epoch :  175 Training acc:    1 Test acc: 0.5837 Training Loss :  2.2265508 Test Loss :  2.085423 Time :  11.382368803024292\n",
            "Epoch :  176 Training acc:    1 Test acc: 0.5903 Training Loss :  2.2260628 Test Loss :  2.0248513 Time :  11.414897918701172\n",
            "Epoch :  177 Training acc:    1 Test acc: 0.5897 Training Loss :  2.215023 Test Loss :  2.0725536 Time :  11.370110750198364\n",
            "Epoch :  178 Training acc:    1 Test acc: 0.5905 Training Loss :  2.1993916 Test Loss :  2.0591094 Time :  11.408737182617188\n",
            "Epoch :  179 Training acc:    1 Test acc: 0.5967 Training Loss :  2.2587109 Test Loss :  1.948452 Time :  11.343338012695312\n",
            "Epoch :  180 Training acc:    1 Test acc: 0.5945 Training Loss :  2.2233467 Test Loss :  1.9363298 Time :  11.368915557861328\n",
            "Epoch :  181 Training acc:    1 Test acc: 0.6013 Training Loss :  2.2503061 Test Loss :  1.9524553 Time :  11.438868522644043\n",
            "Epoch :  182 Training acc:    1 Test acc: 0.6014 Training Loss :  2.2380784 Test Loss :  1.9535096 Time :  11.372058629989624\n",
            "Epoch :  183 Training acc:    1 Test acc: 0.5972 Training Loss :  2.2555861 Test Loss :  1.9111483 Time :  11.289867401123047\n",
            "Epoch :  184 Training acc:    1 Test acc: 0.6015 Training Loss :  2.20289 Test Loss :  1.9201593 Time :  11.349554777145386\n",
            "Epoch :  185 Training acc:    1 Test acc: 0.5903 Training Loss :  2.2413118 Test Loss :  2.0222661 Time :  11.463043212890625\n",
            "Epoch :  186 Training acc:    1 Test acc: 0.5884 Training Loss :  2.2229595 Test Loss :  2.0514083 Time :  11.377766609191895\n",
            "Epoch :  187 Training acc:    1 Test acc: 0.5935 Training Loss :  2.2566056 Test Loss :  1.9860579 Time :  11.249847650527954\n",
            "Epoch :  188 Training acc:    1 Test acc: 0.5940 Training Loss :  2.2024152 Test Loss :  2.007632 Time :  11.465576887130737\n",
            "Epoch :  189 Training acc:    1 Test acc: 0.5911 Training Loss :  2.1800046 Test Loss :  2.0311568 Time :  11.56131100654602\n",
            "Epoch :  190 Training acc:    1 Test acc: 0.5878 Training Loss :  2.2050612 Test Loss :  2.036851 Time :  11.400685548782349\n",
            "Epoch :  191 Training acc:    1 Test acc: 0.5887 Training Loss :  2.227513 Test Loss :  2.0530632 Time :  11.325873851776123\n",
            "Epoch :  192 Training acc:    1 Test acc: 0.5727 Training Loss :  2.1705813 Test Loss :  2.2278745 Time :  11.396824598312378\n",
            "Epoch :  193 Training acc:    1 Test acc: 0.5738 Training Loss :  2.1927807 Test Loss :  2.319418 Time :  11.453832626342773\n",
            "Epoch :  194 Training acc:    1 Test acc: 0.5836 Training Loss :  2.2969232 Test Loss :  2.2031095 Time :  11.495033502578735\n",
            "Epoch :  195 Training acc:    1 Test acc: 0.5780 Training Loss :  2.2141523 Test Loss :  2.2568634 Time :  11.308812379837036\n",
            "Epoch :  196 Training acc:    1 Test acc: 0.5391 Training Loss :  2.2378957 Test Loss :  2.703321 Time :  11.393160581588745\n",
            "Epoch :  197 Training acc:    1 Test acc: 0.5626 Training Loss :  2.1439438 Test Loss :  2.4443016 Time :  11.539212703704834\n",
            "Epoch :  198 Training acc:    1 Test acc: 0.5647 Training Loss :  2.1991522 Test Loss :  2.3491845 Time :  11.536876440048218\n",
            "Epoch :  199 Training acc:    1 Test acc: 0.5779 Training Loss :  2.2020493 Test Loss :  2.1933873 Time :  11.32747507095337\n",
            "Epoch :  200 Training acc:    1 Test acc: 0.5818 Training Loss :  2.1887262 Test Loss :  2.1893103 Time :  11.562788724899292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQjhcvZCfLfd"
      },
      "source": [
        "# Stopping Colab from Runtime\n",
        "\n",
        "Write in Console\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFpzZe-hfQpw"
      },
      "source": [
        "function ClickConnect(){\n",
        "  console.log(\"Connnect Clicked - Start\"); \n",
        "  document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n",
        "  console.log(\"Connnect Clicked - End\"); \n",
        "};\n",
        "setInterval(ClickConnect, 60000)\n",
        "\n",
        "ClickConnect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1JxQYbwG4MS"
      },
      "source": [
        "# Results\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-c6PnOBHi5H"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG1ivos4H0Ij"
      },
      "source": [
        "![Screenshot (382).png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Foxo3SzfIlUR"
      },
      "source": [
        ""
      ]
    }
  ]
}